{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sweety-sweety/Python_Arabov/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22Lecture_3_%D0%9F%D1%80%D0%B8%D0%BA%D0%BB%D0%B0%D0%B4%D0%BD%D0%B0%D1%8F_%D0%A1%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0_%D0%BD%D0%B0_Python_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### 1. Основы Python для статистики\n",
        "  - **Основные Темы**:\n",
        "     1. Введение в Python:\n",
        "        - Переменные, типы данных (числа, строки, списки, словари).\n",
        "        - Основные операторы и конструкции управления (`if`, `for`, `while`).\n",
        "     2. Работа с файлами:\n",
        "        - Чтение и запись текстовых файлов.\n",
        "        - Работа с CSV-файлами.\n",
        "     3. Функции и модули:\n",
        "        - Создание функций.\n",
        "        - Импорт стандартных модулей (например, `math`, `random`).\n",
        "     4. Списковые включения:\n",
        "        - Удобный способ создания и преобразования списков.\n",
        "     5. Работа с Google Colab:\n",
        "        - Введение в Google Colab.\n",
        "        - Загрузка и сохранение файлов.\n",
        "        - Базовые команды для работы с файловой системой.\n",
        "\n",
        "\n",
        "\n",
        "#### 2.Библиотеки Python для статистики и визуализации\"\n",
        "   - **Основные Темы**:\n",
        "     1. NumPy:\n",
        "        - Работа с массивами.\n",
        "        - Математические операции.\n",
        "        - Генерация случайных чисел.\n",
        "     2. Pandas:\n",
        "        - Работа с DataFrame.\n",
        "        - Чтение и запись данных (CSV, Excel).\n",
        "        - Обработка пропущенных значений.\n",
        "        - Агрегация и группировка данных.\n",
        "     3. Matplotlib и Seaborn:\n",
        "        - Построение графиков (гистограммы, диаграммы рассеяния, boxplot).\n",
        "        - Настройка параметров графиков.\n",
        "     4. SciPy:\n",
        "        - Статистические тесты.\n",
        "        - Работа с распределениями.\n",
        "     5. Statsmodels:\n",
        "        - Линейная регрессия.\n",
        "        - Доверительные интервалы.\n",
        "        - Проверка гипотез.\n",
        "     6. Scikit-learn:\n",
        "        - Основы машинного обучения.\n",
        "        - Кластеризация.\n",
        "     7. Plotly и Bokeh:\n",
        "        - Интерактивная визуализация данных.\n",
        "      8. Polars: Более быстрый аналог Pandas.\n",
        "\n",
        "\n",
        "\n",
        "## **3. Визуализация данных на Python**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Гистограммы и Ядерные Оценки Плотности**.\n",
        "2. **Boxplot (ящик с усами)**.\n",
        "3. **Диаграммы рассеяния (Scatter plots)**.\n",
        "4. **Heatmaps (тепловые карты)**.\n",
        "5. **Q-Q Plot**:\n",
        "   - Для проверки нормальности распределения.\n",
        "6. **Интерактивные графики**:\n",
        "   - Библиотеки `plotly` и `bokeh`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **4. Дескриптивная (Описательная) Статистика**\n",
        "\n",
        "\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Вариационный Ряд**\n",
        "   - Отсортированная последовательность наблюдений.\n",
        "   - Минимальное ($x_{(1)}$) и максимальное ($x_{(n)}$) значения.\n",
        "   - Размах выборки: $x_{(n)} - x_{(1)}$.\n",
        "2. **Частоты и Относительные Частоты**\n",
        "   - Частота ($\\nu$): количество повторений каждого значения.\n",
        "   - Относительная частота: $\\frac{\\nu}{n}$, где $n$ — объем выборки.\n",
        "3. **Среднее Значение**\n",
        "   - Формула: $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$.\n",
        "   - Точка минимума функции суммы квадратов отклонений.\n",
        "4. **Выборочная Дисперсия**\n",
        "   - Формула: $Var(x) = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2$.\n",
        "   - Мера разброса данных относительно среднего значения.\n",
        "5. **Выборочная Ковариация**\n",
        "   - Формула: $Cov(x, y) = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})$.\n",
        "   - Характеристика связи между двумя выборками.\n",
        "6. **Коэффициент Корреляции**\n",
        "   - Формула: $\\rho(x, y) = \\frac{Cov(x, y)}{\\sqrt{Var(x) Var(y)}}$.\n",
        "   - Нормированная мера связи между величинами $x$ и $y$.\n",
        "   - Диапазон значений: $-1 \\leq \\rho(x, y) \\leq 1$.\n",
        "7. **Квантили и Процентили**\n",
        "   - Определение квантилей (медиана, квартили, децили, перцентили).\n",
        "8. **Мода**\n",
        "   - Определение моды для дискретных и непрерывных данных.\n",
        "9. **Асимметрия**\n",
        "   - Формула: $ \\text{Асимметрия} = \\frac{\\mathbb{E}[(X - \\mu)^3]}{\\sigma^3} $.\n",
        "   - Интерпретация значений.\n",
        "10. **Эксцесс (островершинность)**\n",
        "    - Формула: $ \\text{Эксцесс} = \\frac{\\mathbb{E}[(X - \\mu)^4]}{\\sigma^4} - 3 $.\n",
        "    - Характеристика формы распределения.\n",
        "\n",
        "\n",
        "\n",
        "## **5. Случайные Величины и Их Распределения**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Случайная Величина**\n",
        "   - Формальное определение случайной величины.\n",
        "   - Отображение пространства элементарных событий $\\Omega$ в числовую ось $\\mathbb{R}$.\n",
        "2. **Функция Распределения**\n",
        "   - Определение функции распределения $F_\\xi(x) = P\\{\\xi \\leq x\\}$.\n",
        "   - Свойства функции распределения:\n",
        "     - Неубывающая функция.\n",
        "     - $F_\\xi(-\\infty) = 0$, $F_\\xi(+\\infty) = 1$.\n",
        "     - Непрерывность справа.\n",
        "3. **Дискретные Случайные Величины**\n",
        "   - Значения случайной величины принимаются из конечного или счетного множества.\n",
        "   - Вероятностная функция $P(\\xi = x_i)$.\n",
        "   - Примеры: биномиальное, пуассоновское распределения.\n",
        "4. **Непрерывные Случайные Величины**\n",
        "   - Значения случайной величины принимаются из интервала вещественных чисел.\n",
        "   - Плотность распределения $f_\\xi(x)$: $F_\\xi(x) = \\int_{-\\infty}^x f_\\xi(t) dt$.\n",
        "   - Примеры: нормальное, экспоненциальное распределения.\n",
        "5. **Характеристики Случайных Величин**\n",
        "   - Математическое ожидание ($E[\\xi]$).\n",
        "   - Дисперсия ($Var(\\xi)$).\n",
        "   - Стандартное отклонение ($\\sigma = \\sqrt{Var(\\xi)}$).\n",
        "6. **Смешанные Случайные Величины**\n",
        "   - Комбинация дискретных и непрерывных компонент.\n",
        "7. **Условное Распределение**\n",
        "   - Определение условной функции распределения.\n",
        "   - Примеры вычисления условных вероятностей.\n",
        "8. **Независимость Случайных Величин**\n",
        "   - Критерии независимости.\n",
        "   - Проверка на практике.\n",
        "9. **Распределения с несколькими параметрами**\n",
        "   - Примеры: двупараметрическое нормальное распределение, гамма-распределение.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **6. Практика Точечного Оценивания на Python**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Метод Максимального Правдоподобия (ММП)**\n",
        "   - Теоретические основы.\n",
        "   - Реализация на Python для различных распределений.\n",
        "2. **Метод Моментов**\n",
        "   - Теоретические основы.\n",
        "   - Реализация на Python для различных распределений.\n",
        "3. **Сравнение Методов**\n",
        "   - Анализ эффективности и точности оценок.\n",
        "4. **Байесовские Оценки**\n",
        "   - Введение в байесовское оценивание.\n",
        "   - Примеры использования априорных распределений.\n",
        "5. **Оценка Эффективности Оценок**\n",
        "   - Несмещенность, состоятельность, эффективность.\n",
        "   - Практические примеры сравнения оценок.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **7. Практика Интервального Оценивания на Python**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Доверительный Интервал для Среднего Нормального Распределения (Известная Дисперсия)**\n",
        "2. **Доверительный Интервал для Дисперсии Нормального Распределения**\n",
        "3. **Доверительный Интервал для Среднего Нормального Распределения (Неизвестная Дисперсия)**\n",
        "4. **Доверительный Интервал для Доли (Вероятности Успеха)**\n",
        "5. **Доверительные Интервалы для Медианы**\n",
        "   - Бутстреп-методы для несимметричных распределений.\n",
        "6. **Доверительные Интервалы для Доли с Корректировкой**\n",
        "   - Метод Уилсона для малых выборок.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **8. Практика Проверки Статистических Гипотез на Python**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Проверка гипотез о среднем значении нормального распределения (известная дисперсия).**\n",
        "2. **Проверка гипотез о среднем значении нормального распределения (неизвестная дисперсия).**\n",
        "3. **Проверка гипотез о дисперсии нормального распределения.**\n",
        "4. **Сравнение двух выборок: проверка равенства средних и дисперсий.**\n",
        "5. **Множественные Проверки Гипотез**\n",
        "   - Корректировка уровня значимости (Bonferroni, FDR).\n",
        "6. **Парные Сравнения**\n",
        "   - Проверка гипотез для зависимых выборок.\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "## **9. Практика Критериев Согласия и Независимости на Python**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Критерий согласия $\\chi^2$:**\n",
        "   - Проверка гипотез о виде распределения.\n",
        "   - Вычисление статистики $\\chi^2$.\n",
        "   - Определение критического значения из таблицы $\\chi^2$-распределения.\n",
        "2. **Проверка независимости признаков по критерию $\\chi^2$:**\n",
        "   - Анализ взаимосвязи между категориальными переменными.\n",
        "   - Построение таблицы сопряженности (контингенции).\n",
        "3. **Критерий Колмогорова:**\n",
        "   - Проверка гипотезы о соответствии выборки заданному распределению.\n",
        "   - Вычисление статистики $D_n = \\sup_{x \\in \\mathbb{R}} |F(x) - F_n(x)|$.\n",
        "4. **Критерий Шапиро-Уилка**\n",
        "   - Проверка нормальности распределения.\n",
        "5. **Критерий Андерсена-Дарлинга**\n",
        "   - Альтернатива критерию Колмогорова для проверки согласия.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **10. Практика Однофакторной Линейной Регрессии на Python**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Однофакторная линейная регрессия**:\n",
        "   - Модель: $ Y = \\theta_0 + \\theta_1 x + \\varepsilon $.\n",
        "   - Оценка параметров $\\theta_0$ и $\\theta_1$ методом максимального правдоподобия.\n",
        "2. **Статистические свойства оценок**:\n",
        "   - Несмещенность оценок $\\hat{\\theta}_0$ и $\\hat{\\theta}_1$.\n",
        "   - Распределение оценок.\n",
        "3. **Проверка гипотезы о значимости коэффициента регрессии ($\\theta_1 = 0$)**:\n",
        "   - Использование распределения Стьюдента.\n",
        "4. **Коэффициент детерминации ($R^2$)**:\n",
        "   - Измерение качества модели.\n",
        "   - Вычисление через сумму квадратов (TSS, ESS, RSS).\n",
        "5. **Диагностика Модели**\n",
        "   - Анализ остатков (гомосcedasticity, нормальность, автокорреляция).\n",
        "6. **Прогнозирование с Доверительными Интервалами**\n",
        "   - Вычисление доверительных интервалов для прогнозов.\n",
        "\n",
        "\n",
        "\n",
        "## **11. Практика Множественной Линейной Регрессии на Python**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Модель множественной линейной регрессии**:\n",
        "   - Формула: $ y = w_0 + w_1 x_1 + \\dots + w_d x_d + \\varepsilon $.\n",
        "   - Оценка параметров $ w_0, w_1, \\dots, w_d $.\n",
        "2. **Метод Наименьших Квадратов**:\n",
        "   - Минимизация суммы квадратов ошибок.\n",
        "   - Формула для параметров: $ \\hat{w} = (X^T X)^{-1} X^T Y $.\n",
        "3. **Качество Модели**:\n",
        "   - Коэффициент детерминации $ R^2 $.\n",
        "   - Анализ остатков.\n",
        "4. **Мультиколлинеарность**\n",
        "   - Определение и способы диагностики (VIF).\n",
        "   - Методы устранения.\n",
        "\n",
        "\n",
        "## **12. Практика Нелинейной Регрессии и Линеаризации на Python**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Нелинейная Регрессия**:\n",
        "   - Преобразование переменных для линеаризации.\n",
        "   - Примеры различных нелинейных моделей.\n",
        "2. **Полиномиальная Регрессия**:\n",
        "   - Метод наименьших квадратов для полиномов.\n",
        "   - Реализация полиномиальной регрессии.\n",
        "3. **Экспоненциальная Регрессия**:\n",
        "   - Логарифмическое преобразование.\n",
        "   - Оценка параметров через метод наименьших квадратов.\n",
        "4. **Степенная Регрессия**:\n",
        "   - Логарифмическая линеаризация.\n",
        "   - Вычисление коэффициентов.\n",
        "5. **Другие Модели**:\n",
        "   - Логистическая, гиперболическая, дробно-линейная регрессии.\n",
        "6. **Нелинейная Оптимизация**:\n",
        "   - Методы минимизации ошибок (например, Levenberg-Marquardt).\n",
        "\n",
        "\n",
        "\n",
        "## **13. Практика Коэффициента Корреляции и Проверки Гипотез на Python**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Коэффициент Корреляции**:\n",
        "   - Формула для вычисления коэффициента корреляции.\n",
        "   - Статистическая оценка коэффициента корреляции для выборки.\n",
        "2. **Проверка Гипотезы о Равенстве Нулю Коэффициента Корреляции**:\n",
        "   - Использование распределения Стьюдента для проверки гипотезы $ H_0: \\rho = 0 $.\n",
        "3. **Проверка Независимости Величин по Критерию $\\chi^2$**:\n",
        "   - Построение таблицы сопряженности.\n",
        "   - Вычисление статистики $\\chi^2$.\n",
        "4. **Критерий Знаков**:\n",
        "   - Для малого и большого количества наблюдений.\n",
        "5. **Частичная Корреляция**:\n",
        "   - Учет влияния третьей переменной.\n",
        "6. **Корреляция Спирмена и Кендалла**:\n",
        "   - Для ранговых данных.\n",
        "\n",
        "\n",
        "\n",
        "## **14. Непараметрические методы**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Критерий Манна-Уитни**:\n",
        "   - Сравнение двух независимых выборок.\n",
        "2. **Критерий Вилкоксона**:\n",
        "   - Сравнение двух связанных выборок.\n",
        "3. **Критерий Краскела-Уоллиса**:\n",
        "   - Обобщение критерия Манна-Уитни для нескольких выборок.\n",
        "4. **Критерий Кендалла**:\n",
        "   - Для проверки связи между ранговыми переменными.\n",
        "5. **Непараметрическая регрессия**:\n",
        "   - Ядерная регрессия.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **15. Байесовская статистика**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Основы байесовского подхода**:\n",
        "   - Априорные и апостериорные распределения.\n",
        "2. **Байесовские методы для оценки параметров**:\n",
        "   - Примеры использования априорных распределений.\n",
        "3. **Метод Метropolis-Hastings**:\n",
        "   - Для оценки posterior распределений.\n",
        "\n",
        "\n",
        "\n",
        "## **16. Многомерный анализ данных**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Метод главных компонент (PCA)**:\n",
        "   - Снижение размерности.\n",
        "   - Интерпретация главных компонент.\n",
        "2. **Кластерный анализ**:\n",
        "   - Метод k-средних.\n",
        "   - Иерархическая кластеризация.\n",
        "   - Дендрограммы.\n",
        "3. **MANOVA**:\n",
        "   - Многомерный дисперсионный анализ.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **17. Бутстреп и методы повторной выборки**\n",
        "\n",
        "### **Основные Темы**\n",
        "1. **Бутстреп-методы**:\n",
        "   - Теоретические основы.\n",
        "   - Оценка стандартных ошибок и доверительных интервалов.\n",
        "   - Реализация на Python.\n",
        "2. **Перестановочные тесты**:\n",
        "   - Проверка гипотез без предположений о распределении.\n",
        "   - Примеры использования для сравнения выборок.\n",
        "3. **Джекнайф-метод**:\n",
        "   - Альтернатива бутстрепу.\n"
      ],
      "metadata": {
        "id": "Rvjlh_JyaFyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 1. Основы Python для статистики\n",
        "#### Введение\n",
        "\n",
        "Python — это мощный и гибкий язык программирования, который широко используется в различных областях, включая анализ данных, машинное обучение, научные вычисления и автоматизацию процессов. Его популярность обусловлена простотой синтаксиса, богатой экосистемой библиотек и активным сообществом разработчиков. В этом учебном пособии мы рассмотрим ключевые концепции Python, необходимые для работы со статистическими данными.\n",
        "\n",
        "\n",
        "\n",
        "### 1.1 Введение в Python\n",
        "\n",
        "Python — это высокоуровневый язык программирования общего назначения, который подходит как для начинающих, так и для опытных программистов. Его основные преимущества включают:\n",
        "\n",
        "- **Простота:** Читаемый и понятный синтаксис.\n",
        "- **Гибкость:** Поддержка различных парадигм программирования (процедурное, объектно-ориентированное, функциональное).\n",
        "- **Богатая библиотека:** Стандартная библиотека Python содержит множество готовых решений.\n",
        "- **Активное сообщество:** Широкая поддержка и множество сторонних библиотек.\n",
        "\n",
        "Python особенно популярен в области анализа данных благодаря таким библиотекам, как NumPy, Pandas, Matplotlib, SciPy и StatsModels.\n",
        "\n",
        "\n",
        "\n",
        "### 1.1.1 Переменные и типы данных\n",
        "\n",
        "**Переменная** — это именованная область памяти, которая хранит данные. В Python переменные создаются путем присвоения значения. Тип переменной определяется автоматически на основе этого значения.\n",
        "\n",
        "#### Основные типы данных в Python:\n",
        "\n",
        "1. **Числовые типы:**\n",
        "   - `int` — целые числа (например, `42`, `-7`).\n",
        "   - `float` — числа с плавающей точкой (например, `3.14`, `-0.5`).\n",
        "   ```python\n",
        "   x = 10  # Целое число\n",
        "   y = 3.14  # Число с плавающей точкой\n",
        "   ```\n",
        "\n",
        "2. **Строки (`str`):** Последовательности символов, заключенные в одинарные (`'`) или двойные (`\"`) кавычки.\n",
        "   ```python\n",
        "   name = \"Виктория\"\n",
        "   greeting = 'Привет!'\n",
        "   ```\n",
        "\n",
        "3. **Списки (`list`):** Упорядоченные коллекции элементов, которые могут содержать значения разных типов. Элементы списка можно изменять.\n",
        "   ```python\n",
        "   grades = [90, 85, 78]  # Список оценок\n",
        "   mixed_list = [1, \"Python\", 3.14]  # Список с разными типами данных\n",
        "   ```\n",
        "\n",
        "4. **Кортежи (`tuple`):** Похожи на списки, но являются неизменяемыми (immutable).\n",
        "   ```python\n",
        "   coordinates = (10, 20)  # Кортеж из двух чисел\n",
        "   ```\n",
        "\n",
        "5. **Словари (`dict`):** Коллекции пар ключ-значение, где каждый ключ уникален. Доступ к значениям осуществляется через ключ.\n",
        "\n"
      ],
      "metadata": {
        "id": "RuKSzuEDaMek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person = {\"имя\": \"Виктория\", \"возраст\": 25}\n",
        "print(person[\"имя\"])"
      ],
      "metadata": {
        "id": "ScINJRpnOllP",
        "outputId": "c0b7a02f-35a0-4d98-9936-00c68f64d071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Виктория\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "6. **Множества (`set`):** Неупорядоченные коллекции уникальных элементов.\n",
        "   ```python\n",
        "   unique_numbers = {1, 2, 3, 4, 5}\n",
        "   ```\n",
        "\n",
        "**Пример создания переменных разных типов:**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fxvNkW0-Oiyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "age = 25  # Целое число\n",
        "name = \"Виктория\"  # Строка\n",
        "grades = [90, 85, 78]  # Список\n",
        "person = {\"имя\": \"Виктория\", \"возраст\": 25}  # Словарь\n",
        "coordinates = (10, 20)  # Кортеж\n",
        "unique_values = {1, 2, 3, 4, 5}  # Множество"
      ],
      "metadata": {
        "id": "sK-PpfI1OzG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 1.1.2 Основные операторы и конструкции управления\n",
        "\n",
        "**Операторы** — это символы или слова, которые выполняют определенные действия над данными. В Python существует несколько групп операторов:\n",
        "\n",
        "#### 1. Арифметические операторы:\n",
        "Используются для выполнения математических операций.\n",
        "- `+` — сложение\n",
        "- `-` — вычитание\n",
        "- `*` — умножение\n",
        "- `/` — деление\n",
        "- `//` — целочисленное деление\n",
        "- `%` — остаток от деления\n",
        "- `**` — возведение в степень\n",
        "\n"
      ],
      "metadata": {
        "id": "6fLQ8Pr3OzPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 10\n",
        "b = 3\n",
        "print(a + b)  # Сложение: 13\n",
        "print(a / b)  # Деление: 3.3333333333333335\n",
        "print(a // b)  # Целочисленное деление: 3\n",
        "print(a % b)  # Остаток от деления: 1\n",
        "print(a ** b)  # Возведение в степень: 1000"
      ],
      "metadata": {
        "id": "_uVwDHjrO8E4",
        "outputId": "333262e3-c437-43c9-9e9c-51940176cf71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "3.3333333333333335\n",
            "3\n",
            "1\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 2. Операторы сравнения:\n",
        "Используются для сравнения значений. Результатом является логическое значение `True` или `False`.\n",
        "- `==` — равно\n",
        "- `!=` — не равно\n",
        "- `<` — меньше\n",
        "- `>` — больше\n",
        "- `<=` — меньше или равно\n",
        "- `>=` — больше или равно\n",
        "\n"
      ],
      "metadata": {
        "id": "U0dbe8olO8Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 10\n",
        "b = 3\n",
        "print(a > b)  # True\n",
        "print(a == b)  # False\n",
        "print(a != b)  # True"
      ],
      "metadata": {
        "id": "VFY0Y1upPCXj",
        "outputId": "f191cc7c-812a-435e-d74d-4b150f2a7d84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Логические операторы:\n",
        "Используются для объединения или изменения условий.\n",
        "- `and` — логическое \"И\"\n",
        "- `or` — логическое \"ИЛИ\"\n",
        "- `not` — логическое отрицание"
      ],
      "metadata": {
        "id": "8ifwmTNdPI7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = True\n",
        "y = False\n",
        "print(x and y)  # False\n",
        "print(x or y)  # True\n",
        "print(not x)  # False"
      ],
      "metadata": {
        "id": "0BwZqd0APJdW",
        "outputId": "a02ea188-43ba-48e4-bd8b-26cf6569f922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### 1.2 Конструкции управления потоком программы\n",
        "\n",
        "Конструкции управления потоком программы позволяют выполнять код в зависимости от условий или многократно повторять определенные действия. В Python используются условные конструкции и циклы.\n",
        "\n",
        "\n",
        "\n",
        "#### Условные конструкции (`if`, `elif`, `else`)\n",
        "\n",
        "Условные конструкции позволяют выполнять различные блоки кода в зависимости от выполнения определенных условий. Основные ключевые слова: `if`, `elif` (сокращение от \"else if\") и `else`.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "if условие1:\n",
        "    # Блок кода, если условие1 истинно\n",
        "elif условие2:\n",
        "    # Блок кода, если условие2 истинно\n",
        "else:\n",
        "    # Блок кода, если ни одно из условий не истинно\n",
        "```\n",
        "\n",
        "**Пример: Определение температуры**\n"
      ],
      "metadata": {
        "id": "xyboQE_9PPk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 25\n",
        "if temperature > 30:\n",
        "    print(\"Жарко.\")\n",
        "elif temperature >= 20:\n",
        "    print(\"Тепло.\")\n",
        "else:\n",
        "    print(\"Холодно.\")"
      ],
      "metadata": {
        "id": "jhT0UMhePR0s",
        "outputId": "86cec733-da69-428d-c0ec-1f6c1bebc75a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тепло.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример демонстрирует использование условных операторов для определения текущей температуры.\n",
        "- Если температура больше 30, программа выведет \"Жарко.\"\n",
        "- Если температура находится в диапазоне от 20 до 30, программа выведет \"Тепло.\"\n",
        "- Во всех остальных случаях программа выведет \"Холодно.\"\n",
        "\n",
        "\n",
        "\n",
        "#### Циклы (`for`, `while`)\n",
        "\n",
        "Циклы позволяют повторять выполнение блока кода несколько раз. В Python используются два типа циклов: `for` и `while`.\n",
        "\n",
        "**Цикл `for`:**\n",
        "Цикл `for` используется для перебора элементов последовательности (например, списка, строки или диапазона).\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "for элемент in последовательность:\n",
        "    # Блок кода, выполняемый для каждого элемента\n",
        "```\n",
        "\n",
        "**Пример: Перебор элементов списка**\n"
      ],
      "metadata": {
        "id": "g66eJRRuPWb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fruits = [\"яблоко\", \"банан\", \"вишня\"]\n",
        "for fruit in fruits:\n",
        "    print(fruit)"
      ],
      "metadata": {
        "id": "wl7DXYDSPYfE",
        "outputId": "de5d1fdf-d62e-45d1-d263-42c058f13efb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "яблоко\n",
            "банан\n",
            "вишня\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример показывает, как использовать цикл `for` для перебора элементов списка.\n",
        "- Программа перебирает каждый элемент списка `fruits` и выводит его на экран.\n",
        "\n",
        "**Цикл `while`:**\n",
        "Цикл `while` выполняет блок кода до тех пор, пока условие истинно.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "while условие:\n",
        "    # Блок кода, выполняемый, пока условие истинно\n",
        "```\n",
        "\n",
        "**Пример: Подсчет попыток**\n"
      ],
      "metadata": {
        "id": "QM3H-aEmPdZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "while count < 3:\n",
        "    print(f\"Попытка {count + 1}\")\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "JfrGiDGCPfoi",
        "outputId": "c6cc56f2-6d8d-4690-b73b-3735a5e86b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Попытка 1\n",
            "Попытка 2\n",
            "Попытка 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Объяснение:**\n",
        "- Этот пример демонстрирует использование цикла `while` для подсчета попыток.\n",
        "- Программа выводит сообщение \"Попытка 1\", \"Попытка 2\" и \"Попытка 3\", после чего цикл завершается, так как условие `count < 3` становится ложным.\n",
        "\n",
        "\n",
        "\n",
        "### 1.3 Работа с файлами\n",
        "\n",
        "В процессе анализа данных часто требуется работать с файлами для загрузки или сохранения информации. Python предоставляет удобные инструменты для чтения и записи данных.\n",
        "\n",
        "\n",
        "\n",
        "#### Чтение текстовых файлов\n",
        "\n",
        "Для чтения текстовых файлов используется функция `open()` с режимом `\"r\"` (read). Для удобства рекомендуется использовать конструкцию `with`, которая автоматически закрывает файл после завершения работы.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "with open(\"имя_файла\", \"r\", encoding=\"utf-8\") as file:\n",
        "    содержимое = file.read()  # Чтение всего содержимого файла\n",
        "```\n",
        "\n",
        "**Пример: Чтение содержимого файла**\n"
      ],
      "metadata": {
        "id": "QwttP2XPPjoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    content = file.read()\n",
        "    print(content)"
      ],
      "metadata": {
        "id": "vZq1ovOrPlrh",
        "outputId": "ede870ab-4cb9-4c2a-85c3-027462920449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Привет, Вика!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Объяснение:**\n",
        "- Этот пример показывает, как читать содержимое текстового файла.\n",
        "- Файл `data.txt` открывается для чтения.\n",
        "- Метод `read()` считывает всё содержимое файла в переменную `content`.\n",
        "- После завершения работы с файлом он автоматически закрывается.\n",
        "\n",
        "\n",
        "\n",
        "#### Запись текстовых файлов\n",
        "\n",
        "Для записи данных в текстовый файл используется режим `\"w\"` (write). Если файл не существует, он будет создан. Если файл уже существует, его содержимое будет перезаписано.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "with open(\"имя_файла\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(\"Текст для записи\")\n",
        "```\n",
        "\n",
        "**Пример: Запись текста в файл**\n"
      ],
      "metadata": {
        "id": "aEoDpXRBP3cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(\"Это новый текстовый файл.\")"
      ],
      "metadata": {
        "id": "CchoGFUsP5Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример демонстрирует, как записать текст в файл.\n",
        "- Файл `output.txt` открывается для записи.\n",
        "- Метод `write()` записывает строку в файл.\n",
        "- После завершения работы файл автоматически закрывается.\n",
        "\n",
        "\n",
        "\n",
        "#### Работа с CSV-файлами\n",
        "\n",
        "CSV (Comma-Separated Values) — это формат, часто используемый для хранения табличных данных. Для работы с CSV-файлами используется стандартный модуль `csv`.\n",
        "\n",
        "**Чтение CSV-файла:**\n",
        "```python\n",
        "import csv\n",
        "\n",
        "with open(\"имя_файла.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        print(row)\n",
        "```\n",
        "\n",
        "\n",
        "**Пример: Чтение данных из CSV-файла**"
      ],
      "metadata": {
        "id": "0br524BBQKKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open(\"data.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        print(row)"
      ],
      "metadata": {
        "id": "2DUERQURQTcO",
        "outputId": "d600a221-a87d-4763-f70e-7f9e5643dc6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Имя', 'Возраст']\n",
            "['Виктория', '25']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример показывает, как читать данные из CSV-файла.\n",
        "- Файл `data.csv` открывается для чтения.\n",
        "- Объект `csv.reader` позволяет построчно читать данные из файла.\n",
        "- Каждая строка файла возвращается в виде списка значений.\n",
        "\n",
        "**Запись в CSV-файл:**\n",
        "```python\n",
        "import csv\n",
        "\n",
        "with open(\"имя_файла.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Заголовок1\", \"Заголовок2\"])  # Запись заголовка\n",
        "    writer.writerow([\"Данные1\", \"Данные2\"])       # Запись данных\n",
        "```\n",
        "\n",
        "**Пример: Запись данных в CSV-файл**"
      ],
      "metadata": {
        "id": "o8XKLeG_QXf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open(\"output.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Имя\", \"Возраст\"])\n",
        "    writer.writerow([\"Виктория\", 25])"
      ],
      "metadata": {
        "id": "q7uisOpTQe98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Объяснение:**\n",
        "- Этот пример демонстрирует, как записать данные в CSV-файл.\n",
        "- Файл `output.csv` открывается для записи.\n",
        "- Объект `csv.writer` позволяет записывать данные в файл.\n",
        "- Метод `writerow()` записывает строку данных в файл.\n",
        "\n",
        "\n",
        "\n",
        "### 1.4 Практические примеры\n",
        "\n",
        "#### Пример 1: Чтение и обработка данных из файла\n",
        "```python\n",
        "with open(\"data.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()  # Чтение всех строк файла\n",
        "    for line in lines:\n",
        "        print(line.strip())  # Удаление лишних пробелов и переносов строк\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример показывает, как читать и обрабатывать данные из текстового файла.\n",
        "- Метод `readlines()` считывает все строки файла в список.\n",
        "- Метод `strip()` удаляет лишние пробелы и символы переноса строк.\n",
        "\n",
        "#### Пример 2: Запись данных в файл с использованием цикла\n",
        "```python\n",
        "data = [\"Первая строка\", \"Вторая строка\", \"Третья строка\"]\n",
        "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    for line in data:\n",
        "        file.write(line + \"\\n\")  # Запись каждой строки с переносом\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример демонстрирует, как записать несколько строк в файл с использованием цикла.\n",
        "- Каждая строка из списка `data` записывается в файл с добавлением символа переноса строки.\n",
        "\n",
        "#### Пример 3: Работа с CSV-файлом\n",
        "```python\n",
        "import csv\n",
        "\n",
        "# Чтение CSV-файла и вывод данных\n",
        "with open(\"data.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    reader = csv.DictReader(file)  # Чтение данных в виде словаря\n",
        "    for row in reader:\n",
        "        print(f\"Имя: {row['Имя']}, Возраст: {row['Возраст']}\")\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример показывает, как читать данные из CSV-файла с использованием `csv.DictReader`.\n",
        "- Каждая строка файла возвращается в виде словаря, что позволяет обращаться к данным по ключам.\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "### 1.3 Функции и модули\n",
        "\n",
        "Функции и модули — это ключевые элементы Python, которые помогают организовать код, сделать его более читаемым и переиспользуемым.\n",
        "\n",
        "\n",
        "\n",
        "#### Функции\n",
        "\n",
        "Функции — это блоки кода, которые выполняют определенную задачу и могут быть вызваны многократно. Они помогают избежать дублирования кода и упрощают его поддержку.\n",
        "\n",
        "**Синтаксис создания функции:**\n",
        "```python\n",
        "def имя_функции(параметры):\n",
        "    \"\"\"Документация функции (описание).\"\"\"\n",
        "    # Тело функции\n",
        "    return результат\n",
        "```\n",
        "\n",
        "**Пример: Функция для вычисления среднего значения**\n",
        "```python\n",
        "def calculate_average(numbers):\n",
        "    \"\"\"Вычисляет среднее значение списка чисел.\"\"\"\n",
        "    total = sum(numbers)  # Сумма всех элементов списка\n",
        "    count = len(numbers)  # Количество элементов в списке\n",
        "    return total / count  # Возвращаем среднее значение\n",
        "\n",
        "grades = [90, 85, 78]  # Список оценок\n",
        "average = calculate_average(grades)  # Вызов функции\n",
        "print(f\"Средний балл: {average}\")  # Вывод результата\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример демонстрирует создание функции `calculate_average`, которая вычисляет среднее значение списка чисел.\n",
        "- Функция принимает список чисел в качестве аргумента, вычисляет их сумму и делит на количество элементов.\n",
        "- Результат возвращается с помощью ключевого слова `return`.\n",
        "\n",
        "\n",
        "\n",
        "#### Модули\n",
        "\n",
        "Модули — это файлы, содержащие набор функций, классов и переменных, которые можно использовать в других программах. Python предоставляет множество стандартных модулей, таких как `math`, `random`, `os` и другие.\n",
        "\n",
        "**Синтаксис импорта модуля:**\n",
        "```python\n",
        "import имя_модуля\n",
        "```\n",
        "\n",
        "**Пример использования модулей `math` и `random`:**\n",
        "```python\n",
        "import math\n",
        "import random\n",
        "\n",
        "# Использование функции sqrt из модуля math\n",
        "sqrt_value = math.sqrt(16)  # Вычисление квадратного корня\n",
        "print(f\"Квадратный корень из 16: {sqrt_value}\")\n",
        "\n",
        "# Использование функции randint из модуля random\n",
        "random_number = random.randint(1, 10)  # Генерация случайного числа от 1 до 10\n",
        "print(f\"Случайное число: {random_number}\")\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- Модуль `math` предоставляет математические функции, такие как `sqrt` (квадратный корень).\n",
        "- Модуль `random` позволяет генерировать случайные числа, например, с помощью функции `randint`.\n",
        "\n",
        "\n",
        "\n",
        "### 1.4 Списковые включения\n",
        "\n",
        "Списковые включения — это компактный и удобный способ создания списков на основе существующих коллекций данных. Они объединяют цикл и условия в одну строку, что делает код более читаемым.\n",
        "\n",
        "**Синтаксис спискового включения:**\n",
        "```python\n",
        "[выражение for элемент in последовательность if условие]\n",
        "```\n",
        "\n",
        "**Пример 1: Создание списка квадратов чисел**\n",
        "```python\n",
        "squares = [x**2 for x in range(1, 6)]  # Квадраты чисел от 1 до 5\n",
        "print(squares)  # Вывод: [1, 4, 9, 16, 25]\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример создает список квадратов чисел от 1 до 5.\n",
        "- Выражение `x**2` вычисляет квадрат каждого числа, а `range(1, 6)` задает диапазон чисел.\n",
        "\n",
        "**Пример 2: Создание списка четных чисел**\n",
        "```python\n",
        "even_numbers = [x for x in range(1, 11) if x % 2 == 0]  # Четные числа от 1 до 10\n",
        "print(even_numbers)  # Вывод: [2, 4, 6, 8, 10]\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот пример создает список четных чисел от 1 до 10.\n",
        "- Условие `if x % 2 == 0` проверяет, является ли число четным.\n",
        "\n",
        "\n",
        "### 1.5 Работа с Google Colab\n",
        "\n",
        "Google Colab — это облачная платформа для выполнения кода Python, которая позволяет работать с файлами, библиотеками и данными без необходимости установки дополнительного программного обеспечения. Она особенно полезна для анализа данных и машинного обучения. Colab предоставляет доступ к вычислительным ресурсам, включая GPU и TPU, что делает его идеальным инструментом для выполнения ресурсоемких задач.\n",
        "\n",
        "\n",
        "\n",
        "#### Как получить доступ к Google Colab?\n",
        "\n",
        "Google Colab доступен бесплатно через браузер. Для начала работы выполните следующие шаги:\n",
        "\n",
        "1. **Перейдите на сайт Google Colab:**\n",
        "   - Откройте браузер и перейдите по ссылке: [Google Colab](https://colab.research.google.com/).\n",
        "\n",
        "2. **Войдите в Google-аккаунт:**\n",
        "   - Если у вас есть Google-аккаунт (например, Gmail), войдите в него. Если нет, создайте новый аккаунт.\n",
        "\n",
        "3. **Создайте новый блокнот:**\n",
        "   - На главной странице Colab нажмите на кнопку **\"Новый блокнот\"** (или выберите один из примеров, предоставленных Google).\n",
        "\n",
        "4. **Начните писать код:**\n",
        "   - После создания блокнота вы можете писать и выполнять код Python в ячейках, как в Jupyter Notebook.\n",
        "\n",
        "\n",
        "\n",
        "#### Базовые команды для работы с файловой системой\n",
        "\n",
        "Google Colab поддерживает команды терминала, которые можно выполнять с помощью префикса `!`. Это позволяет управлять файлами и директориями прямо из блокнота.\n",
        "\n",
        "**Примеры команд:**\n",
        "```bash\n",
        "# Просмотр содержимого текущей директории\n",
        "!ls\n",
        "\n",
        "# Создание новой директории\n",
        "!mkdir my_folder\n",
        "\n",
        "# Копирование файла\n",
        "!cp data.txt my_folder/\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- `!ls` — показывает содержимое текущей директории.\n",
        "- `!mkdir my_folder` — создает новую директорию с именем `my_folder`.\n",
        "- `!cp data.txt my_folder/` — копирует файл `data.txt` в директорию `my_folder`.\n",
        "\n",
        "\n",
        "\n",
        "#### Загрузка и скачивание файлов\n",
        "\n",
        "Google Colab предоставляет удобные инструменты для загрузки и скачивания файлов. Это особенно полезно, если вам нужно работать с данными, хранящимися на вашем компьютере, или сохранить результаты работы в Colab.\n",
        "\n",
        "**Пример загрузки файла:**\n",
        "```python\n",
        "from google.colab import files\n",
        "\n",
        "# Загрузка файла с компьютера\n",
        "uploaded = files.upload()\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот код позволяет загрузить файл с локального компьютера в среду Google Colab.\n",
        "- После выполнения кода появится интерфейс для выбора файла. Выберите файл, и он будет загружен в текущую директорию Colab.\n",
        "\n",
        "**Пример скачивания файла:**\n",
        "```python\n",
        "from google.colab import files\n",
        "\n",
        "# Создание и сохранение файла\n",
        "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(\"Это тестовый файл.\")\n",
        "\n",
        "# Скачивание файла\n",
        "files.download(\"output.txt\")\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- Этот код создает текстовый файл `output.txt` и записывает в него строку.\n",
        "- Функция `files.download()` позволяет скачать файл на локальный компьютер. После выполнения кода браузер предложит сохранить файл.\n",
        "\n",
        "\n",
        "\n",
        "#### Подключение Google Drive\n",
        "\n",
        "Google Colab позволяет подключать Google Drive для работы с файлами, хранящимися в облаке. Это особенно полезно, если у вас есть большие наборы данных или проекты, которые вы хотите сохранить.\n",
        "\n",
        "**Пример подключения Google Drive:**\n",
        "```python\n",
        "from google.colab import drive\n",
        "\n",
        "# Подключение Google Drive\n",
        "drive.mount('/content/drive')\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- После выполнения этого кода появится ссылка для авторизации. Перейдите по ней, выберите Google-аккаунт и разрешите доступ.\n",
        "- После авторизации ваш Google Drive будет подключен к Colab, и вы сможете работать с файлами, хранящимися в Drive, как с локальными файлами.\n",
        "\n",
        "**Пример работы с файлами в Google Drive:**\n",
        "```python\n",
        "# Чтение файла из Google Drive\n",
        "with open('/content/drive/My Drive/data.txt', 'r') as file:\n",
        "    content = file.read()\n",
        "    print(content)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "#### Использование GPU и TPU\n",
        "\n",
        "Google Colab предоставляет доступ к GPU и TPU, что ускоряет выполнение задач, связанных с машинным обучением и глубоким обучением.\n",
        "\n",
        "**Как включить GPU/TPU:**\n",
        "1. Перейдите в меню **\"Среда выполнения\"** (Runtime) в верхней части экрана.\n",
        "2. Выберите **\"Изменить тип среды выполнения\"** (Change runtime type).\n",
        "3. В разделе **\"Аппаратный ускоритель\"** (Hardware accelerator) выберите **GPU** или **TPU**.\n",
        "4. Нажмите **\"Сохранить\"**.\n",
        "\n",
        "**Проверка доступности GPU:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Khf_qh8kPCgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Проверка, используется ли GPU\n",
        "print(\"GPU доступен:\", tf.test.is_gpu_available())"
      ],
      "metadata": {
        "id": "8zORHHHAQB4-",
        "outputId": "ccc724a1-af0b-49f1-c2a0-75a04bf75b84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tmp/ipython-input-13-2205930555.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU доступен: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопросы для самопроверки\n",
        "1. Что такое Python и где он применяется?\n",
        "2. Какие основные преимущества языка Python?\n",
        "3. Назовите три популярные библиотеки Python для анализа данных.\n",
        "4. Что делает Python подходящим для начинающих программистов?\n",
        "5. Чем обусловлена популярность Python в области анализа данных?\n",
        "6. Что такое переменная в Python?\n",
        "7. Как создаются переменные в Python? Приведите пример.\n",
        "8. Как определяется тип данных переменной в Python?\n",
        "9. Назовите числовые типы данных в Python.\n",
        "10. Что такое строки (`str`) в Python? Приведите пример.\n",
        "11. Как создать список в Python? Приведите пример.\n",
        "12. Чем отличаются списки от кортежей в Python?\n",
        "13. Что такое словарь (`dict`) в Python? Приведите пример.\n",
        "14. Что такое множество (`set`) и как его создать?\n",
        "15. Можно ли изменять элементы кортежа после создания? Почему?\n",
        "16. Назовите основные арифметические операторы в Python.\n",
        "17. Что делает оператор `//` в Python? Приведите пример.\n",
        "18. Что делает оператор `%` в Python? Приведите пример.\n",
        "19. Назовите операторы сравнения в Python.\n",
        "20. Что делают логические операторы `and`, `or`, `not`?\n",
        "21. Приведите пример использования условного оператора `if-elif-else`.\n",
        "22. Что такое цикл `for` в Python? Приведите пример.\n",
        "23. Что такое цикл `while` в Python? Приведите пример.\n",
        "24. Как выйти из бесконечного цикла в Python?\n",
        "25. Как использовать конструкцию `break` внутри цикла?\n",
        "26. Как прочитать содержимое текстового файла в Python?\n",
        "27. Как записать данные в текстовый файл в Python?\n",
        "28. Что такое CSV-файл и как его читать в Python?\n",
        "29. Как записать данные в CSV-файл в Python?\n",
        "30. Какая функция используется для автоматического закрытия файла после работы с ним?"
      ],
      "metadata": {
        "id": "B4K3YgzfupHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Библиотеки Python для статистики и визуализации\n",
        "\n",
        "В этой главе мы рассмотрим основные библиотеки Python, которые используются для статистического анализа и визуализации данных. Эти инструменты помогут вам эффективно работать с данными, проводить анализ и представлять результаты в наглядной форме. Мы начнем с базовых библиотек, таких как NumPy и Pandas, а затем перейдем к более специализированным инструментам, таким как SciPy, Statsmodels и Scikit-learn. Также мы познакомимся с библиотеками для визуализации, такими как Matplotlib, Seaborn, Plotly и Bokeh.\n",
        "\n",
        "\n",
        "### 2.1 NumPy\n",
        "\n",
        "NumPy (Numerical Python) — это одна из самых важных библиотек в экосистеме Python для научных вычислений. Она предоставляет мощные инструменты для работы с многомерными массивами и матрицами, а также для выполнения математических операций. NumPy лежит в основе многих других библиотек, таких как Pandas, SciPy и Scikit-learn, благодаря своей производительности и удобству.\n",
        "\n",
        "\n",
        "\n",
        "#### Основные возможности NumPy\n",
        "\n",
        "1. **Работа с массивами**\n",
        "\n",
        "Массивы NumPy — это основная структура данных в библиотеке. Они позволяют хранить и обрабатывать большие объемы данных эффективно. В отличие от списков Python, массивы NumPy имеют фиксированный тип данных, что делает их более быстрыми и удобными для математических операций.\n",
        "\n",
        "**Создание массива:**\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Создание одномерного массива\n",
        "array = np.array([1, 2, 3, 4, 5])\n",
        "print(array)\n",
        "```\n",
        "**Вывод:**\n",
        "```\n",
        "[1 2 3 4 5]\n",
        "```\n",
        "\n",
        "**Создание многомерного массива:**\n",
        "```python\n",
        "# Создание двумерного массива (матрицы)\n",
        "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(matrix)\n",
        "```\n",
        "**Вывод:**\n",
        "```\n",
        "[[1 2 3]\n",
        " [4 5 6]]\n",
        "```\n",
        "\n",
        "**Основные свойства массива:**\n",
        "```python\n",
        "print(\"Размерность массива:\", array.ndim)  # Размерность (1 для одномерного массива)\n",
        "print(\"Форма массива:\", array.shape)       # Форма (количество элементов по каждой оси)\n",
        "print(\"Тип данных:\", array.dtype)          # Тип данных элементов массива\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "2. **Математические операции**\n",
        "\n",
        "NumPy поддерживает широкий спектр математических операций, которые выполняются поэлементно. Это делает библиотеку идеальной для научных вычислений.\n",
        "\n",
        "**Примеры математических операций:**\n",
        "```python\n",
        "array1 = np.array([1, 2, 3])\n",
        "array2 = np.array([4, 5, 6])\n",
        "\n",
        "# Сложение\n",
        "print(\"Сложение:\", array1 + array2)  # [5 7 9]\n",
        "\n",
        "# Поэлементное умножение\n",
        "print(\"Поэлементное умножение:\", array1 * array2)  # [4 10 18]\n",
        "\n",
        "# Скалярное произведение (dot product)\n",
        "print(\"Скалярное произведение:\", np.dot(array1, array2))  # 32\n",
        "```\n",
        "\n",
        "**Математические функции:**\n",
        "NumPy также предоставляет множество встроенных математических функций, таких как синус, косинус, экспонента и логарифм.\n",
        "```python\n",
        "# Вычисление синуса\n",
        "angles = np.array([0, 30, 45, 60, 90])\n",
        "radians = np.deg2rad(angles)  # Преобразование градусов в радианы\n",
        "print(\"Синус углов:\", np.sin(radians))\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "3. **Генерация случайных чисел**\n",
        "\n",
        "NumPy предоставляет мощные инструменты для генерации случайных чисел, что полезно для моделирования, статистических экспериментов и машинного обучения.\n",
        "\n",
        "**Примеры генерации случайных чисел:**\n",
        "```python\n",
        "# Генерация 5 случайных чисел от 0 до 1\n",
        "random_numbers = np.random.rand(5)\n",
        "print(\"Случайные числа:\", random_numbers)\n",
        "\n",
        "# Генерация случайных целых чисел\n",
        "random_integers = np.random.randint(1, 10, size=5)  # 5 чисел от 1 до 9\n",
        "print(\"Случайные целые числа:\", random_integers)\n",
        "\n",
        "# Генерация случайных чисел из нормального распределения\n",
        "normal_distribution = np.random.normal(loc=0, scale=1, size=5)  # loc - среднее, scale - стандартное отклонение\n",
        "print(\"Нормальное распределение:\", normal_distribution)\n",
        "```\n",
        "\n",
        "**Пример использования в статистике:**\n",
        "```python\n",
        "# Генерация выборки из 1000 значений с нормальным распределением\n",
        "sample = np.random.normal(loc=0, scale=1, size=1000)\n",
        "\n",
        "# Вычисление среднего и стандартного отклонения\n",
        "mean = np.mean(sample)\n",
        "std_dev = np.std(sample)\n",
        "print(f\"Среднее: {mean}, Стандартное отклонение: {std_dev}\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "4. **Индексирование и срезы**\n",
        "\n",
        "NumPy позволяет эффективно работать с подмножествами массивов с помощью индексов и срезов.\n",
        "\n",
        "**Примеры:**\n",
        "```python\n",
        "array = np.array([10, 20, 30, 40, 50])\n",
        "\n",
        "# Получение элемента по индексу\n",
        "print(\"Элемент с индексом 2:\", array[2])  # 30\n",
        "\n",
        "# Срез массива\n",
        "print(\"Срез массива:\", array[1:4])  # [20 30 40]\n",
        "\n",
        "# Индексирование в многомерных массивах\n",
        "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(\"Элемент матрицы:\", matrix[1, 2])  # 6 (строка 1, столбец 2)\n",
        "print(\"Срез матрицы:\\n\", matrix[:2, 1:])  # Первые две строки, начиная со второго столбца\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "5. **Трансформация массивов**\n",
        "\n",
        "NumPy предоставляет функции для изменения формы массивов, что полезно при подготовке данных для анализа.\n",
        "\n",
        "**Примеры:**\n",
        "```python\n",
        "array = np.array([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# Изменение формы массива\n",
        "reshaped = array.reshape(2, 3)  # Преобразование в матрицу 2x3\n",
        "print(\"Измененная форма:\\n\", reshaped)\n",
        "\n",
        "# Транспонирование матрицы\n",
        "transposed = reshaped.T\n",
        "print(\"Транспонированная матрица:\\n\", transposed)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "6. **Агрегатные функции**\n",
        "\n",
        "NumPy предоставляет функции для вычисления статистик по массивам, таких как сумма, среднее, минимум и максимум.\n",
        "\n",
        "**Примеры:**\n",
        "```python\n",
        "array = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "# Сумма элементов\n",
        "print(\"Сумма:\", np.sum(array))\n",
        "\n",
        "# Среднее значение\n",
        "print(\"Среднее:\", np.mean(array))\n",
        "\n",
        "# Минимум и максимум\n",
        "print(\"Минимум:\", np.min(array))\n",
        "print(\"Максимум:\", np.max(array))\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### 2.2 Pandas\n",
        "\n",
        "Pandas — это одна из самых популярных библиотек Python для работы с табличными данными. Она предоставляет мощные инструменты для манипуляции, анализа и очистки данных. Основная структура данных в Pandas — это **DataFrame**, который представляет собой двумерную таблицу, похожую на таблицу в Excel или базу данных SQL. Pandas также поддерживает работу с одномерными данными через структуру **Series**.\n",
        "\n",
        "\n",
        "#### Основные возможности Pandas\n",
        "\n",
        "1. **Работа с DataFrame**\n",
        "\n",
        "DataFrame — это таблица, состоящая из строк и столбцов. Каждый столбец может содержать данные разных типов (числа, строки, даты и т.д.). DataFrame позволяет легко манипулировать данными, фильтровать, сортировать и агрегировать их.\n",
        "\n",
        "**Создание DataFrame:**\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Создание DataFrame из словаря\n",
        "data = {'Имя': ['Алекс', 'Мария', 'Иван'],\n",
        "        'Возраст': [25, 30, 22],\n",
        "        'Город': ['Москва', 'Санкт-Петербург', 'Новосибирск']}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "```\n",
        "    Имя  Возраст           Город\n",
        "0  Алекс       25          Москва\n",
        "1  Мария       30  Санкт-Петербург\n",
        "2   Иван       22      Новосибирск\n",
        "```\n",
        "\n",
        "**Основные свойства DataFrame:**\n",
        "```python\n",
        "print(\"Столбцы:\", df.columns)  # Названия столбцов\n",
        "print(\"Индексы:\", df.index)     # Индексы строк\n",
        "print(\"Форма данных:\", df.shape)  # Количество строк и столбцов\n",
        "print(\"Типы данных:\\n\", df.dtypes)  # Типы данных в каждом столбце\n",
        "```\n",
        "\n",
        "\n",
        "2. **Чтение и запись данных**\n",
        "\n",
        "Pandas поддерживает чтение и запись данных в различных форматах, таких как CSV, Excel, JSON, SQL и другие. Это делает её универсальным инструментом для работы с данными.\n",
        "\n",
        "**Чтение данных из CSV:**\n",
        "```python\n",
        "# Чтение данных из CSV-файла\n",
        "df = pd.read_csv('data.csv')\n",
        "print(df.head())  # Вывод первых 5 строк\n",
        "```\n",
        "\n",
        "**Запись данных в CSV:**\n",
        "```python\n",
        "# Запись данных в CSV-файл\n",
        "df.to_csv('output.csv', index=False)  # index=False исключает запись индексов\n",
        "```\n",
        "\n",
        "**Чтение данных из Excel:**\n",
        "```python\n",
        "# Чтение данных из Excel-файла\n",
        "df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
        "```\n",
        "\n",
        "**Запись данных в Excel:**\n",
        "```python\n",
        "# Запись данных в Excel-файл\n",
        "df.to_excel('output.xlsx', sheet_name='Sheet1', index=False)\n",
        "```\n",
        "\n",
        "\n",
        "3. **Обработка пропущенных значений**\n",
        "\n",
        "Пропущенные значения (NaN) часто встречаются в реальных данных. Pandas предоставляет удобные методы для их обработки.\n",
        "\n",
        "**Пример данных с пропущенными значениями:**\n",
        "```python\n",
        "data = {'Имя': ['Алекс', 'Мария', None],\n",
        "        'Возраст': [25, None, 22],\n",
        "        'Город': ['Москва', 'Санкт-Петербург', None]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "```\n",
        "    Имя  Возраст           Город\n",
        "0  Алекс     25.0          Москва\n",
        "1  Мария      NaN  Санкт-Петербург\n",
        "2   None     22.0             None\n",
        "```\n",
        "\n",
        "**Удаление строк с пропущенными значениями:**\n",
        "```python\n",
        "df_cleaned = df.dropna()  # Удаление строк с NaN\n",
        "print(df_cleaned)\n",
        "```\n",
        "\n",
        "**Заполнение пропущенных значений:**\n",
        "```python\n",
        "# Заполнение NaN нулями\n",
        "df_filled = df.fillna(0)\n",
        "print(df_filled)\n",
        "\n",
        "# Заполнение NaN средним значением\n",
        "df['Возраст'].fillna(df['Возраст'].mean(), inplace=True)\n",
        "print(df)\n",
        "```\n",
        "\n",
        "\n",
        "4. **Агрегация и группировка данных**\n",
        "\n",
        "Pandas позволяет группировать данные и выполнять агрегатные операции, такие как сумма, среднее, минимум, максимум и т.д.\n",
        "\n",
        "**Пример данных:**\n",
        "```python\n",
        "data = {'Имя': ['Алекс', 'Мария', 'Иван', 'Алекс', 'Мария'],\n",
        "        'Возраст': [25, 30, 22, 25, 30],\n",
        "        'Зарплата': [50000, 60000, 45000, 55000, 62000]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Группировка данных:**\n",
        "```python\n",
        "# Группировка по столбцу 'Имя' и вычисление среднего\n",
        "grouped = df.groupby('Имя').mean()\n",
        "print(grouped)\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "```\n",
        "       Возраст  Зарплата\n",
        "Имя                     \n",
        "Алекс     25.0   52500.0\n",
        "Иван      22.0   45000.0\n",
        "Мария     30.0   61000.0\n",
        "```\n",
        "\n",
        "**Агрегатные функции:**\n",
        "```python\n",
        "# Применение нескольких агрегатных функций\n",
        "agg_result = df.groupby('Имя').agg({'Возраст': 'mean', 'Зарплата': ['min', 'max']})\n",
        "print(agg_result)\n",
        "```\n",
        "\n",
        "\n",
        "5. **Фильтрация и сортировка данных**\n",
        "\n",
        "Pandas позволяет легко фильтровать и сортировать данные.\n",
        "\n",
        "**Фильтрация данных:**\n",
        "```python\n",
        "# Фильтрация строк, где Возраст больше 25\n",
        "filtered_df = df[df['Возраст'] > 25]\n",
        "print(filtered_df)\n",
        "```\n",
        "\n",
        "**Сортировка данных:**\n",
        "```python\n",
        "# Сортировка по столбцу 'Зарплата' по убыванию\n",
        "sorted_df = df.sort_values(by='Зарплата', ascending=False)\n",
        "print(sorted_df)\n",
        "```\n",
        "\n",
        "\n",
        "6. **Добавление и удаление столбцов**\n",
        "\n",
        "Pandas позволяет легко добавлять и удалять столбцы в DataFrame.\n",
        "\n",
        "**Добавление столбца:**\n",
        "```python\n",
        "# Добавление нового столбца\n",
        "df['Премия'] = [1000, 1500, 800, 1200, 2000]\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Удаление столбца:**\n",
        "```python\n",
        "# Удаление столбца 'Премия'\n",
        "df.drop(columns=['Премия'], inplace=True)\n",
        "print(df)\n",
        "```\n",
        "\n",
        "\n",
        "7. **Объединение данных**\n",
        "\n",
        "Pandas поддерживает операции объединения данных, такие как слияние (merge) и конкатенация (concat).\n",
        "\n",
        "**Пример слияния:**\n",
        "```python\n",
        "# Создание второго DataFrame\n",
        "data2 = {'Имя': ['Алекс', 'Иван'],\n",
        "         'Отдел': ['Маркетинг', 'Разработка']}\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Слияние по столбцу 'Имя'\n",
        "merged_df = pd.merge(df, df2, on='Имя')\n",
        "print(merged_df)\n",
        "```\n",
        "\n",
        "**Пример конкатенации:**\n",
        "```python\n",
        "# Конкатенация двух DataFrame\n",
        "concatenated_df = pd.concat([df, df2], axis=0)  # axis=0 для объединения по строкам\n",
        "print(concatenated_df)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### 2.3 Matplotlib и Seaborn\n",
        "\n",
        "Matplotlib и Seaborn — это две основные библиотеки Python для визуализации данных. Они позволяют создавать широкий спектр графиков, от простых линейных графиков до сложных многомерных визуализаций. Matplotlib является более низкоуровневой библиотекой и предоставляет полный контроль над каждым элементом графика. Seaborn, построенная на основе Matplotlib, предлагает более высокоуровневые функции и упрощает создание красивых и информативных графиков.\n",
        "\n",
        "\n",
        "\n",
        "#### Основные возможности Matplotlib\n",
        "\n",
        "Matplotlib — это фундаментальная библиотека для построения графиков в Python. Она позволяет создавать практически любые типы визуализаций, настраивать их внешний вид и добавлять аннотации.\n",
        "\n",
        "1. **Построение простых графиков:**\n",
        "\n",
        "   Matplotlib позволяет строить линейные графики, гистограммы, диаграммы рассеяния и многое другое.\n",
        "\n",
        "   **Пример линейного графика:**\n",
        "   ```python\n",
        "   import matplotlib.pyplot as plt\n",
        "\n",
        "   # Данные\n",
        "   x = [1, 2, 3, 4]\n",
        "   y = [10, 20, 25, 30]\n",
        "\n",
        "   # Построение графика\n",
        "   plt.plot(x, y, marker='o', linestyle='-', color='b', label='Линия 1')\n",
        "   plt.xlabel('Ось X')  # Подпись оси X\n",
        "   plt.ylabel('Ось Y')  # Подпись оси Y\n",
        "   plt.title('Пример линейного графика')  # Заголовок графика\n",
        "   plt.legend()  # Добавление легенды\n",
        "   plt.grid(True)  # Включение сетки\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   **Объяснение:**\n",
        "   - `plt.plot()` — функция для построения линейного графика.\n",
        "   - `marker='o'` — задает маркеры для точек.\n",
        "   - `linestyle='-'` — задает стиль линии (сплошная линия).\n",
        "   - `color='b'` — задает цвет линии (синий).\n",
        "   - `label='Линия 1'` — добавляет метку для легенды.\n",
        "\n",
        "2. **Гистограммы:**\n",
        "\n",
        "   Гистограммы используются для визуализации распределения данных.\n",
        "\n",
        "   **Пример гистограммы:**\n",
        "   ```python\n",
        "   import numpy as np\n",
        "\n",
        "   # Генерация случайных данных\n",
        "   data = np.random.normal(0, 1, 1000)\n",
        "\n",
        "   # Построение гистограммы\n",
        "   plt.hist(data, bins=30, color='green', alpha=0.7)\n",
        "   plt.xlabel('Значения')\n",
        "   plt.ylabel('Частота')\n",
        "   plt.title('Гистограмма распределения')\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   **Объяснение:**\n",
        "   - `plt.hist()` — функция для построения гистограммы.\n",
        "   - `bins=30` — количество интервалов (столбцов).\n",
        "   - `alpha=0.7` — прозрачность столбцов.\n",
        "\n",
        "3. **Диаграммы рассеяния:**\n",
        "\n",
        "   Диаграммы рассеяния используются для визуализации взаимосвязи между двумя переменными.\n",
        "\n",
        "   **Пример диаграммы рассеяния:**\n",
        "   ```python\n",
        "   # Данные\n",
        "   x = np.random.rand(50)\n",
        "   y = np.random.rand(50)\n",
        "\n",
        "   # Построение диаграммы рассеяния\n",
        "   plt.scatter(x, y, color='red', marker='x')\n",
        "   plt.xlabel('Ось X')\n",
        "   plt.ylabel('Ось Y')\n",
        "   plt.title('Диаграмма рассеяния')\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   **Объяснение:**\n",
        "   - `plt.scatter()` — функция для построения диаграммы рассеяния.\n",
        "   - `marker='x'` — задает маркеры для точек.\n",
        "\n",
        "\n",
        "\n",
        "#### Основные возможности Seaborn\n",
        "\n",
        "Seaborn — это библиотека для создания статистических графиков. Она предоставляет более высокоуровневые функции, которые упрощают создание сложных визуализаций.\n",
        "\n",
        "1. **Диаграммы рассеяния:**\n",
        "\n",
        "   Seaborn позволяет строить диаграммы рассеяния с дополнительной информацией, такой как группировка по категориям.\n",
        "\n",
        "   **Пример диаграммы рассеяния:**\n",
        "   ```python\n",
        "   import seaborn as sns\n",
        "\n",
        "   # Данные\n",
        "   df = sns.load_dataset('iris')  # Загрузка встроенного набора данных\n",
        "\n",
        "   # Построение диаграммы рассеяния\n",
        "   sns.scatterplot(x='sepal_length', y='sepal_width', hue='species', data=df)\n",
        "   plt.title('Диаграмма рассеяния с группировкой')\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   **Объяснение:**\n",
        "   - `hue='species'` — группировка точек по категориям (виды ирисов).\n",
        "   - `data=df` — данные для построения графика.\n",
        "\n",
        "2. **Гистограммы и распределения:**\n",
        "\n",
        "   Seaborn предоставляет удобные функции для визуализации распределений.\n",
        "\n",
        "   **Пример гистограммы с ядерной оценкой плотности:**\n",
        "   ```python\n",
        "   sns.histplot(df['sepal_length'], kde=True, color='blue')\n",
        "   plt.title('Гистограмма с ядерной оценкой плотности')\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   **Объяснение:**\n",
        "   - `kde=True` — добавляет ядерную оценку плотности (Kernel Density Estimation).\n",
        "\n",
        "3. **Boxplot:**\n",
        "\n",
        "   Boxplot (ящик с усами) используется для визуализации распределения данных и выбросов.\n",
        "\n",
        "   **Пример Boxplot:**\n",
        "   ```python\n",
        "   sns.boxplot(x='species', y='sepal_length', data=df)\n",
        "   plt.title('Boxplot для длины чашелистика по видам')\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   **Объяснение:**\n",
        "   - `x='species'` — категории по оси X.\n",
        "   - `y='sepal_length'` — значения по оси Y.\n",
        "\n",
        "4. **Heatmap:**\n",
        "\n",
        "   Heatmap (тепловая карта) используется для визуализации матричных данных, например, корреляций.\n",
        "\n",
        "   **Пример Heatmap:**\n",
        "   ```python\n",
        "   # Вычисление корреляционной матрицы\n",
        "   corr = df.corr()\n",
        "\n",
        "   # Построение тепловой карты\n",
        "   sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "   plt.title('Тепловая карта корреляций')\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   **Объяснение:**\n",
        "   - `annot=True` — отображает значения в ячейках.\n",
        "   - `cmap='coolwarm'` — цветовая схема.\n",
        "\n",
        "\n",
        "\n",
        "#### Настройка графиков\n",
        "\n",
        "Обе библиотеки позволяют настраивать внешний вид графиков, добавлять заголовки, подписи осей, легенды и изменять цветовые схемы.\n",
        "\n",
        "**Пример настройки графика в Matplotlib:**\n",
        "```python\n",
        "plt.figure(figsize=(8, 6))  # Размер графика\n",
        "plt.plot(x, y, label='Данные')\n",
        "plt.title('Настроенный график', fontsize=16)\n",
        "plt.xlabel('Ось X', fontsize=14)\n",
        "plt.ylabel('Ось Y', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Пример настройки графика в Seaborn:**\n",
        "```python\n",
        "sns.set(style='whitegrid')  # Установка стиля\n",
        "sns.scatterplot(x='sepal_length', y='sepal_width', hue='species', data=df, palette='Set2')\n",
        "plt.title('Настроенный график в Seaborn', fontsize=16)\n",
        "plt.xlabel('Длина чашелистика', fontsize=14)\n",
        "plt.ylabel('Ширина чашелистика', fontsize=14)\n",
        "plt.legend(title='Вид', fontsize=12)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### 2.4 Plotly и Bokeh\n",
        "\n",
        "Plotly и Bokeh — это две мощные библиотеки для создания интерактивных графиков в Python. Они позволяют создавать динамические визуализации, которые можно использовать в веб-приложениях, аналитических панелях (dashboards) и интерактивных отчетах. Обе библиотеки поддерживают широкий спектр типов графиков и предоставляют возможности для настройки и взаимодействия с данными.\n",
        "\n",
        "\n",
        "\n",
        "#### Основные возможности Plotly\n",
        "\n",
        "Plotly — это библиотека для создания интерактивных графиков, которая поддерживает множество типов визуализаций, включая диаграммы рассеяния, линейные графики, гистограммы, тепловые карты и 3D-графики. Plotly также интегрируется с Dash, что позволяет создавать полноценные веб-приложения.\n",
        "\n",
        "1. **Интерактивная визуализация данных:**\n",
        "\n",
        "   Plotly позволяет создавать интерактивные графики, которые можно масштабировать, перемещать и исследовать.\n",
        "\n",
        "   **Пример диаграммы рассеяния:**\n",
        "   ```python\n",
        "   import plotly.express as px\n",
        "\n",
        "   # Данные\n",
        "   df = px.data.iris()  # Встроенный набор данных\n",
        "\n",
        "   # Создание интерактивного графика\n",
        "   fig = px.scatter(df, x='sepal_width', y='sepal_length', color='species', title='Диаграмма рассеяния')\n",
        "   fig.show()\n",
        "   ```\n",
        "\n",
        "   **Объяснение:**\n",
        "   - `px.scatter()` — функция для создания диаграммы рассеяния.\n",
        "   - `x='sepal_width'` и `y='sepal_length'` — оси X и Y.\n",
        "   - `color='species'` — группировка точек по категориям (виды ирисов).\n",
        "   - `fig.show()` — отображение графика.\n",
        "\n",
        "2. **Линейные графики:**\n",
        "\n",
        "   Plotly позволяет создавать интерактивные линейные графики.\n",
        "\n",
        "   **Пример линейного графика:**\n",
        "   ```python\n",
        "   import plotly.express as px\n",
        "\n",
        "   # Данные\n",
        "   x = [1, 2, 3, 4]\n",
        "   y = [10, 20, 25, 30]\n",
        "\n",
        "   # Создание линейного графика\n",
        "   fig = px.line(x=x, y=y, title='Линейный график', labels={'x': 'Ось X', 'y': 'Ось Y'})\n",
        "   fig.show()\n",
        "   ```\n",
        "\n",
        "3. **Гистограммы:**\n",
        "\n",
        "   Plotly поддерживает создание интерактивных гистограмм.\n",
        "\n",
        "   **Пример гистограммы:**\n",
        "   ```python\n",
        "   import plotly.express as px\n",
        "\n",
        "   # Данные\n",
        "   df = px.data.tips()  # Встроенный набор данных\n",
        "\n",
        "   # Создание гистограммы\n",
        "   fig = px.histogram(df, x='total_bill', nbins=30, title='Гистограмма суммы счета')\n",
        "   fig.show()\n",
        "   ```\n",
        "\n",
        "4. **3D-графики:**\n",
        "\n",
        "   Plotly позволяет создавать трехмерные графики.\n",
        "\n",
        "   **Пример 3D-графика:**\n",
        "   ```python\n",
        "   import plotly.express as px\n",
        "\n",
        "   # Данные\n",
        "   df = px.data.iris()\n",
        "\n",
        "   # Создание 3D-графика\n",
        "   fig = px.scatter_3d(df, x='sepal_length', y='sepal_width', z='petal_length', color='species')\n",
        "   fig.show()\n",
        "   ```\n",
        "\n",
        "\n",
        "\n",
        "#### Основные возможности Bokeh\n",
        "\n",
        "Bokeh — это библиотека для создания интерактивных графиков, которые можно встраивать в веб-приложения. Bokeh предоставляет низкоуровневый API для полного контроля над графиками, а также высокоуровневый API для быстрого создания стандартных визуализаций.\n",
        "\n",
        "1. **Создание интерактивных графиков:**\n",
        "\n",
        "   Bokeh позволяет создавать графики с инструментами для взаимодействия, такими как масштабирование, панорамирование и наведение.\n",
        "\n",
        "   **Пример линейного графика:**\n",
        "   ```python\n",
        "   from bokeh.plotting import figure, show\n",
        "\n",
        "   # Данные\n",
        "   x = [1, 2, 3, 4]\n",
        "   y = [10, 20, 25, 30]\n",
        "\n",
        "   # Создание графика\n",
        "   p = figure(title=\"Линейный график\", x_axis_label='Ось X', y_axis_label='Ось Y')\n",
        "   p.line(x, y, legend_label=\"Линия 1\", line_width=2, color=\"blue\")\n",
        "   show(p)\n",
        "   ```\n",
        "\n",
        "   **Объяснение:**\n",
        "   - `figure()` — создание фигуры для графика.\n",
        "   - `p.line()` — добавление линии на график.\n",
        "   - `show(p)` — отображение графика.\n",
        "\n",
        "2. **Диаграммы рассеяния:**\n",
        "\n",
        "   Bokeh поддерживает создание интерактивных диаграмм рассеяния.\n",
        "\n",
        "   **Пример диаграммы рассеяния:**\n",
        "   ```python\n",
        "   from bokeh.plotting import figure, show\n",
        "\n",
        "   # Данные\n",
        "   x = [1, 2, 3, 4, 5]\n",
        "   y = [6, 7, 2, 4, 5]\n",
        "\n",
        "   # Создание диаграммы рассеяния\n",
        "   p = figure(title=\"Диаграмма рассеяния\", x_axis_label='Ось X', y_axis_label='Ось Y')\n",
        "   p.circle(x, y, size=10, color=\"red\")\n",
        "   show(p)\n",
        "   ```\n",
        "\n",
        "3. **Гистограммы:**\n",
        "\n",
        "   Bokeh позволяет создавать интерактивные гистограммы.\n",
        "\n",
        "   **Пример гистограммы:**\n",
        "   ```python\n",
        "   from bokeh.plotting import figure, show\n",
        "   import numpy as np\n",
        "\n",
        "   # Данные\n",
        "   data = np.random.normal(0, 1, 1000)\n",
        "\n",
        "   # Создание гистограммы\n",
        "   p = figure(title=\"Гистограмма\", x_axis_label='Значения', y_axis_label='Частота')\n",
        "   p.quad(top=np.histogram(data, bins=30)[0], bottom=0, left=np.histogram(data, bins=30)[1][:-1],\n",
        "          right=np.histogram(data, bins=30)[1][1:], fill_color=\"blue\", line_color=\"black\")\n",
        "   show(p)\n",
        "   ```\n",
        "\n",
        "4. **Интерактивные инструменты:**\n",
        "\n",
        "   Bokeh предоставляет встроенные инструменты для взаимодействия с графиками, такие как масштабирование, панорамирование и наведение.\n",
        "\n",
        "   **Пример добавления инструментов:**\n",
        "   ```python\n",
        "   from bokeh.plotting import figure, show\n",
        "   from bokeh.models import HoverTool\n",
        "\n",
        "   # Данные\n",
        "   x = [1, 2, 3, 4, 5]\n",
        "   y = [6, 7, 2, 4, 5]\n",
        "\n",
        "   # Создание графика\n",
        "   p = figure(title=\"График с инструментами\", x_axis_label='Ось X', y_axis_label='Ось Y',\n",
        "              tools=\"pan,wheel_zoom,box_zoom,reset\")\n",
        "   p.circle(x, y, size=10, color=\"green\")\n",
        "\n",
        "   # Добавление инструмента наведения\n",
        "   hover = HoverTool()\n",
        "   hover.tooltips = [(\"X\", \"@x\"), (\"Y\", \"@y\")]\n",
        "   p.add_tools(hover)\n",
        "\n",
        "   show(p)\n",
        "   ```\n",
        "\n",
        "\n",
        "\n",
        "#### Сравнение Plotly и Bokeh\n",
        "\n",
        "- **Plotly:**\n",
        "  - Простота использования, особенно с модулем `plotly.express`.\n",
        "  - Поддержка 3D-графиков и анимаций.\n",
        "  - Интеграция с Dash для создания веб-приложений.\n",
        "  - Хорошо подходит для быстрого создания интерактивных графиков.\n",
        "\n",
        "- **Bokeh:**\n",
        "  - Полный контроль над графиками через низкоуровневый API.\n",
        "  - Поддержка сложных интерактивных элементов, таких как виджеты.\n",
        "  - Хорошо подходит для встраивания графиков в веб-приложения.\n",
        "\n",
        "\n",
        "### 2.5 Polars: Более быстрый аналог Pandas\n",
        "\n",
        "Polars — это современная библиотека для работы с данными, написанная на Rust и оптимизированная для высокой производительности. Она предоставляет функциональность, аналогичную Pandas, но работает значительно быстрее, особенно при обработке больших объемов данных. Polars поддерживает многопоточность и эффективное использование памяти, что делает её идеальным выбором для задач, требующих высокой производительности.\n",
        "\n",
        "\n",
        "#### Основные возможности Polars\n",
        "\n",
        "1. **Работа с DataFrame**\n",
        "\n",
        "Polars использует структуру данных **DataFrame**, которая похожа на ту, что используется в Pandas. Однако Polars оптимизирована для работы с большими наборами данных и поддерживает ленивые вычисления (lazy evaluation), что позволяет минимизировать использование памяти и ускорить обработку.\n",
        "\n",
        "**Создание DataFrame:**\n",
        "```python\n",
        "import polars as pl\n",
        "\n",
        "# Создание DataFrame\n",
        "df = pl.DataFrame({\n",
        "    'Имя': ['Алекс', 'Мария', 'Иван'],\n",
        "    'Возраст': [25, 30, 22],\n",
        "    'Город': ['Москва', 'Санкт-Петербург', 'Новосибирск']\n",
        "})\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "```\n",
        "shape: (3, 3)\n",
        "┌────────┬────────┬──────────────────┐\n",
        "│ Имя    │ Возраст│ Город            │\n",
        "│ ---    │ ---    │ ---              │\n",
        "│ str    │ i64    │ str              │\n",
        "├────────┼────────┼──────────────────┤\n",
        "│ Алекс  │ 25     │ Москва           │\n",
        "│ Мария  │ 30     │ Санкт-Петербург  │\n",
        "│ Иван   │ 22     │ Новосибирск      │\n",
        "└────────┴────────┴──────────────────┘\n",
        "```\n",
        "\n",
        "**Основные свойства DataFrame:**\n",
        "```python\n",
        "print(\"Столбцы:\", df.columns)  # Названия столбцов\n",
        "print(\"Форма данных:\", df.shape)  # Количество строк и столбцов\n",
        "print(\"Типы данных:\", df.schema)  # Типы данных в каждом столбце\n",
        "```\n",
        "\n",
        "\n",
        "2. **Операции с данными**\n",
        "\n",
        "Polars поддерживает множество операций, таких как фильтрация, сортировка, группировка и агрегация. Эти операции выполняются очень быстро благодаря оптимизации и многопоточности.\n",
        "\n",
        "**Фильтрация данных:**\n",
        "```python\n",
        "# Фильтрация строк, где Возраст больше 25\n",
        "filtered_df = df.filter(pl.col('Возраст') > 25)\n",
        "print(filtered_df)\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "```\n",
        "shape: (1, 3)\n",
        "┌────────┬────────┬──────────────────┐\n",
        "│ Имя    │ Возраст│ Город            │\n",
        "│ ---    │ ---    │ ---              │\n",
        "│ str    │ i64    │ str              │\n",
        "├────────┼────────┼──────────────────┤\n",
        "│ Мария  │ 30     │ Санкт-Петербург  │\n",
        "└────────┴────────┴──────────────────┘\n",
        "```\n",
        "\n",
        "**Сортировка данных:**\n",
        "```python\n",
        "# Сортировка по столбцу 'Возраст' по убыванию\n",
        "sorted_df = df.sort('Возраст', reverse=True)\n",
        "print(sorted_df)\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "```\n",
        "shape: (3, 3)\n",
        "┌────────┬────────┬──────────────────┐\n",
        "│ Имя    │ Возраст│ Город            │\n",
        "│ ---    │ ---    │ ---              │\n",
        "│ str    │ i64    │ str              │\n",
        "├────────┼────────┼──────────────────┤\n",
        "│ Мария  │ 30     │ Санкт-Петербург  │\n",
        "│ Алекс  │ 25     │ Москва           │\n",
        "│ Иван   │ 22     │ Новосибирск      │\n",
        "└────────┴────────┴──────────────────┘\n",
        "```\n",
        "\n",
        "**Группировка и агрегация:**\n",
        "```python\n",
        "# Группировка по столбцу 'Город' и вычисление среднего возраста\n",
        "grouped_df = df.groupby('Город').agg(pl.col('Возраст').mean())\n",
        "print(grouped_df)\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "```\n",
        "shape: (3, 2)\n",
        "┌──────────────────┬──────────┐\n",
        "│ Город            │ Возраст  │\n",
        "│ ---              │ ---      │\n",
        "│ str              │ f64      │\n",
        "├──────────────────┼──────────┤\n",
        "│ Москва           │ 25.0     │\n",
        "│ Санкт-Петербург  │ 30.0     │\n",
        "│ Новосибирск      │ 22.0     │\n",
        "└──────────────────┴──────────┘\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "3. **Ленивые вычисления (Lazy Evaluation)**\n",
        "\n",
        "Polars поддерживает ленивые вычисления, что позволяет оптимизировать выполнение операций. Вместо немедленного выполнения операций, Polars строит план вычислений и выполняет его только при необходимости.\n",
        "\n",
        "**Пример ленивых вычислений:**\n",
        "```python\n",
        "# Создание ленивого DataFrame\n",
        "lazy_df = df.lazy()\n",
        "\n",
        "# Фильтрация и агрегация\n",
        "result = lazy_df.filter(pl.col('Возраст') > 20) \\\n",
        "                .groupby('Город') \\\n",
        "                .agg(pl.col('Возраст').mean()) \\\n",
        "                .collect()  # Выполнение вычислений\n",
        "\n",
        "print(result)\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "```\n",
        "shape: (3, 2)\n",
        "┌──────────────────┬──────────┐\n",
        "│ Город            │ Возраст  │\n",
        "│ ---              │ ---      │\n",
        "│ str              │ f64      │\n",
        "├──────────────────┼──────────┤\n",
        "│ Москва           │ 25.0     │\n",
        "│ Санкт-Петербург  │ 30.0     │\n",
        "│ Новосибирск      │ 22.0     │\n",
        "└──────────────────┴──────────┘\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "4. **Чтение и запись данных**\n",
        "\n",
        "Polars поддерживает чтение и запись данных в различных форматах, таких как CSV, Parquet и JSON.\n",
        "\n",
        "**Чтение данных из CSV:**\n",
        "```python\n",
        "# Чтение данных из CSV-файла\n",
        "df = pl.read_csv('data.csv')\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Запись данных в CSV:**\n",
        "```python\n",
        "# Запись данных в CSV-файл\n",
        "df.write_csv('output.csv')\n",
        "```\n",
        "\n",
        "**Чтение данных из Parquet:**\n",
        "```python\n",
        "# Чтение данных из Parquet-файла\n",
        "df = pl.read_parquet('data.parquet')\n",
        "print(df)\n",
        "```\n",
        "\n",
        "\n",
        "5. **Высокая производительность**\n",
        "\n",
        "Polars оптимизирована для работы с большими объемами данных. Она использует многопоточность и эффективные алгоритмы для ускорения операций.\n",
        "\n",
        "**Пример сравнения производительности:**\n",
        "```python\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Создание большого набора данных\n",
        "data = {'col1': np.random.rand(10**6),\n",
        "        'col2': np.random.rand(10**6)}\n",
        "\n",
        "# Pandas\n",
        "start_time = time.time()\n",
        "pd_df = pd.DataFrame(data)\n",
        "pd_df['col3'] = pd_df['col1'] + pd_df['col2']\n",
        "print(f\"Pandas: {time.time() - start_time:.4f} секунд\")\n",
        "\n",
        "# Polars\n",
        "start_time = time.time()\n",
        "pl_df = pl.DataFrame(data)\n",
        "pl_df = pl_df.with_column((pl.col('col1') + pl.col('col2')).alias('col3'))\n",
        "print(f\"Polars: {time.time() - start_time:.4f} секунд\")\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "```\n",
        "Pandas: 0.1234 секунд\n",
        "Polars: 0.0456 секунд\n",
        "```\n",
        "\n",
        "### 2.6 SciPy\n",
        "\n",
        "SciPy (Scientific Python) — это библиотека, которая предоставляет множество функций для научных и инженерных вычислений. В контексте статистики SciPy особенно полезна благодаря модулю `scipy.stats`, который содержит функции для работы с вероятностными распределениями, выполнения статистических тестов и анализа данных. Этот модуль является основным инструментом для статистического анализа в Python и предоставляет широкий спектр возможностей для работы с данными.\n",
        "\n",
        "\n",
        "#### Основные возможности SciPy для статистики\n",
        "\n",
        "1. **Работа с распределениями:**\n",
        "\n",
        "   Модуль `scipy.stats` содержит более 100 вероятностных распределений, включая нормальное, биномиальное, Пуассона, экспоненциальное и многие другие. Для каждого распределения доступны методы для вычисления плотности вероятности, функции распределения, генерации случайных чисел и вычисления статистик.\n",
        "\n",
        "   **Синтаксис:**\n",
        "   - **Плотность вероятности (Probability Density Function, PDF):**\n",
        "     ```python\n",
        "     scipy.stats.<распределение>.pdf(x, параметры)\n",
        "     ```\n",
        "     Где:\n",
        "     - `x` — точка, в которой вычисляется плотность вероятности.\n",
        "     - `параметры` — параметры распределения (например, среднее и стандартное отклонение для нормального распределения).\n",
        "\n",
        "   - **Функция распределения (Cumulative Distribution Function, CDF):**\n",
        "     ```python\n",
        "     scipy.stats.<распределение>.cdf(x, параметры)\n",
        "     ```\n",
        "     Где:\n",
        "     - `x` — точка, в которой вычисляется значение функции распределения.\n",
        "\n",
        "   - **Генерация случайных чисел:**\n",
        "     ```python\n",
        "     scipy.stats.<распределение>.rvs(параметры, size)\n",
        "     ```\n",
        "     Где:\n",
        "     - `size` — количество генерируемых случайных чисел.\n",
        "\n",
        "   - **Статистики распределения:**\n",
        "     ```python\n",
        "     scipy.stats.<распределение>.mean(параметры)  # Среднее значение\n",
        "     scipy.stats.<распределение>.var(параметры)   # Дисперсия\n",
        "     scipy.stats.<распределение>.std(параметры)   # Стандартное отклонение\n",
        "     ```\n",
        "\n",
        "   Эти функции позволяют анализировать свойства распределений, моделировать случайные процессы и проверять гипотезы о данных.\n",
        "\n",
        "2. **Статистические тесты:**\n",
        "\n",
        "   SciPy предоставляет множество функций для выполнения статистических тестов, которые позволяют проверять гипотезы о данных, сравнивать выборки и оценивать значимость результатов. Эти тесты включают параметрические и непараметрические методы.\n",
        "\n",
        "   **Синтаксис:**\n",
        "   - **t-тест для независимых выборок:**\n",
        "     ```python\n",
        "     scipy.stats.ttest_ind(выборка1, выборка2)\n",
        "     ```\n",
        "     Где:\n",
        "     - `выборка1` и `выборка2` — две независимые выборки данных.\n",
        "\n",
        "   - **t-тест для зависимых выборок (парный t-тест):**\n",
        "     ```python\n",
        "     scipy.stats.ttest_rel(выборка1, выборка2)\n",
        "     ```\n",
        "\n",
        "   - **Тест хи-квадрат:**\n",
        "     ```python\n",
        "     scipy.stats.chisquare(наблюдаемые, ожидаемые)\n",
        "     ```\n",
        "     Где:\n",
        "     - `наблюдаемые` — наблюдаемые частоты.\n",
        "     - `ожидаемые` — ожидаемые частоты.\n",
        "\n",
        "   - **Однофакторный дисперсионный анализ (ANOVA):**\n",
        "     ```python\n",
        "     scipy.stats.f_oneway(выборка1, выборка2, ...)\n",
        "     ```\n",
        "     Где:\n",
        "     - `выборка1`, `выборка2`, ... — выборки данных для сравнения.\n",
        "\n",
        "   - **Тест Колмогорова-Смирнова:**\n",
        "     ```python\n",
        "     scipy.stats.kstest(выборка, распределение)\n",
        "     ```\n",
        "     Где:\n",
        "     - `выборка` — данные для тестирования.\n",
        "     - `распределение` — название распределения или функция распределения.\n",
        "\n",
        "   Эти тесты позволяют проверять гипотезы о равенстве средних, распределений и других параметров данных.\n",
        "\n",
        "3. **Описательная статистика:**\n",
        "\n",
        "   SciPy предоставляет функции для вычисления основных статистик, которые помогают анализировать данные и делать выводы о их свойствах. Эти функции включают вычисление среднего, медианы, дисперсии, корреляции и других показателей.\n",
        "\n",
        "   **Синтаксис:**\n",
        "   - **Основные статистики:**\n",
        "     ```python\n",
        "     scipy.stats.describe(данные)\n",
        "     ```\n",
        "     Где:\n",
        "     - `данные` — массив данных.\n",
        "     Возвращает:\n",
        "     - Количество наблюдений.\n",
        "     - Минимальное и максимальное значения.\n",
        "     - Среднее значение.\n",
        "     - Дисперсию.\n",
        "\n",
        "   - **Коэффициент корреляции Пирсона:**\n",
        "     ```python\n",
        "     scipy.stats.pearsonr(выборка1, выборка2)\n",
        "     ```\n",
        "     Где:\n",
        "     - `выборка1` и `выборка2` — две переменные для анализа.\n",
        "     Возвращает:\n",
        "     - Коэффициент корреляции.\n",
        "     - p-значение.\n",
        "\n",
        "   - **Коэффициент корреляции Спирмена:**\n",
        "     ```python\n",
        "     scipy.stats.spearmanr(выборка1, выборка2)\n",
        "     ```\n",
        "\n",
        "   - **Коэффициент корреляции Кендалла:**\n",
        "     ```python\n",
        "     scipy.stats.kendalltau(выборка1, выборка2)\n",
        "     ```\n",
        "\n",
        "   Эти функции позволяют анализировать взаимосвязи между переменными и оценивать их статистическую значимость.\n",
        "\n",
        "4. **Доверительные интервалы:**\n",
        "\n",
        "   SciPy предоставляет функции для вычисления доверительных интервалов, которые позволяют оценить точность статистических оценок.\n",
        "\n",
        "   **Синтаксис:**\n",
        "   - **Доверительный интервал для среднего:**\n",
        "     ```python\n",
        "     scipy.stats.t.interval(доверительный_уровень, степени_свободы, loc=среднее, scale=стандартная_ошибка)\n",
        "     ```\n",
        "     Где:\n",
        "     - `доверительный_уровень` — уровень доверия (например, 0.95 для 95% интервала).\n",
        "     - `степени_свободы` — степени свободы.\n",
        "     - `loc` — среднее значение.\n",
        "     - `scale` — стандартная ошибка.\n",
        "\n",
        "   Эти функции помогают оценить точность статистических оценок и сделать выводы о данных.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " ### 2.7 Statsmodels\n",
        "\n",
        "Statsmodels — это библиотека, специально разработанная для оценки статистических моделей и проведения тестов. Она предоставляет инструменты для линейной и нелинейной регрессии, анализа временных рядов, проверки гипотез и многого другого. Statsmodels широко используется в статистическом анализе данных, экономике, социальных науках и других областях, где требуется построение и интерпретация статистических моделей.\n",
        "\n",
        "\n",
        "\n",
        "#### Основные возможности Statsmodels для статистики\n",
        "\n",
        "1. **Линейная регрессия:**\n",
        "\n",
        "   Statsmodels позволяет строить и анализировать линейные регрессионные модели, включая множественную регрессию. Она предоставляет подробные отчеты о коэффициентах, их значимости, доверительных интервалах и качестве модели. Это делает её мощным инструментом для анализа взаимосвязей между переменными.\n",
        "\n",
        "   **Синтаксис:**\n",
        "   - **Создание модели линейной регрессии:**\n",
        "     ```python\n",
        "     statsmodels.OLS(зависимая_переменная, независимые_переменные)\n",
        "     ```\n",
        "     Где:\n",
        "     - `зависимая_переменная` — целевая переменная (вектор).\n",
        "     - `независимые_переменные` — матрица независимых переменных (может включать константу, если добавлена с помощью `statsmodels.api.add_constant`).\n",
        "\n",
        "   - **Обучение модели:**\n",
        "     ```python\n",
        "     model.fit()\n",
        "     ```\n",
        "     Возвращает объект модели, содержащий результаты подгонки.\n",
        "\n",
        "   - **Вывод статистики модели:**\n",
        "     ```python\n",
        "     model.summary()\n",
        "     ```\n",
        "     Возвращает таблицу с подробной статистикой, включая коэффициенты, стандартные ошибки, p-значения и показатели качества модели (R², F-статистика и др.).\n",
        "\n",
        "   - **Доверительные интервалы для коэффициентов:**\n",
        "     ```python\n",
        "     model.conf_int()\n",
        "     ```\n",
        "     Возвращает доверительные интервалы для коэффициентов модели.\n",
        "\n",
        "   Эти функции позволяют анализировать влияние независимых переменных на зависимую переменную и оценивать качество модели.\n",
        "\n",
        "2. **Проверка гипотез:**\n",
        "\n",
        "\n",
        "Statsmodels предоставляет функции для проверки гипотез, которые позволяют оценивать свойства данных и моделей. Эти тесты включают проверку на нормальность распределения, гомогенность дисперсий, а также другие важные характеристики.\n",
        "\n",
        "\n",
        "Перед изучением различных статистических тестов важно понять базовые концепции и различия между основными методами сравнения данных. Ниже мы кратко рассмотрим три ключевых подхода: **U-тест**, **t-тест** и **ANOVA**.\n",
        "\n",
        "\n",
        "\n",
        "#### Что такое U-тест (Тест Манна-Уитни)?\n",
        "**U-тест**, также известный как тест Манна-Уитни, — это непараметрический тест, используемый для сравнения двух независимых выборок. Он проверяет гипотезу о том, одинаково ли распределены значения в двух группах.\n",
        "\n",
        "- **Применение:** Используется, когда предположение о нормальности данных не выполняется.\n",
        "- **Гипотезы:**\n",
        "  - Нулевая гипотеза (H₀): два распределения одинаковы.\n",
        "  - Альтернативная гипотеза (H₁): одно распределение больше или меньше другого.\n",
        "- **Преимущества:** Не требует предположений о форме распределения данных.\n",
        "\n",
        "\n",
        "\n",
        "#### Что такое t-тест?\n",
        "**T-тест** — это параметрический тест, который используется для сравнения средних значений двух групп. Он предполагает, что данные имеют нормальное распределение.\n",
        "\n",
        "- **Применение:**\n",
        "  - **Для одной выборки**: Проверяет, отличается ли среднее значение выборки от заданного значения.\n",
        "  - **Для двух выборок**: Проверяет, равны ли средние значения двух групп.\n",
        "- **Гипотезы:**\n",
        "  - Нулевая гипотеза (H₀): средние значения равны.\n",
        "  - Альтернативная гипотеза (H₁): средние значения различаются.\n",
        "- **Преимущества:** Быстрее и проще в вычислениях, если предположение о нормальности выполняется.\n",
        "\n",
        "\n",
        "#### Что такое ANOVA (Анализ дисперсии)?\n",
        "**ANOVA (Analysis of Variance)** — это статистический метод, используемый для сравнения средних значений более чем двух групп. Он проверяет, есть ли статистически значимые различия между группами.\n",
        "\n",
        "- **Применение:** Используется для анализа влияния одного или нескольких факторов на результат.\n",
        "- **Гипотезы:**\n",
        "  - Нулевая гипотеза (H₀): все группы имеют одинаковые средние значения.\n",
        "  - Альтернативная гипотеза (H₁): хотя бы одна группа имеет другое среднее значение.\n",
        "- **Преимущества:** Позволяет одновременно сравнивать несколько групп, что делает его более эффективным, чем множественные t-тесты.\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "### 1. **Тесты на нормальность**\n",
        "\n",
        "**Нормальность**: Это свойство данных, при котором они следуют нормальному (Гауссову) распределению. Нормальное распределение характеризуется симметричной колоколообразной кривой, где среднее, медиана и moda совпадают. Многие статистические методы, такие как t-тест и ANOVA, предполагают нормальность данных для корректности результатов.\n",
        "\n",
        "#### 1.1 Тест Харке-Бера\n",
        "\n",
        "Тест Харке-Бера проверяет гипотезу о нормальности распределения данных на основе эксцесса (остроты пика) и асимметрии распределения. Этот тест особенно полезен для больших выборок.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from statsmodels.stats.stattools import jarque_bera\n",
        "# Вычисление статистики теста и p-значения\n",
        "stat, p_value = jarque_bera(данные)\n",
        "```\n",
        "\n",
        "- `stat`: Значение тестовой статистики.\n",
        "- `p_value`: Вероятность того, что наблюдаемые данные могли возникнуть случайно, если нулевая гипотеза верна.\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): данные имеют нормальное распределение.\n",
        "- Альтернативная гипотеза (H₁): данные не имеют нормального распределения.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что данные не нормально распределены.\n",
        "\n",
        "#### 1.2 Тест Шапиро-Уилка\n",
        "\n",
        "Тест Шапиро-Уилка — один из самых точных тестов на нормальность для небольших выборок. Он работает лучше всего, когда объем данных меньше 5000 (хотя рекомендуется использовать его для выборок размером до 50).\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from scipy.stats import shapiro\n",
        "# Вычисление статистики теста и p-значения\n",
        "stat, p_value = shapiro(данные)\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): данные имеют нормальное распределение.\n",
        "- Альтернативная гипотеза (H₁): данные не имеют нормального распределения.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что данные не нормально распределены.\n",
        "\n",
        "#### 1.3 Тест Колмогорова-Смирнова\n",
        "\n",
        "Тест Колмогорова-Смирнова проверяет, соответствует ли эмпирическое распределение данных теоретическому распределению (например, нормальному). Однако этот тест менее мощный, чем тесты Шапиро-Уилка и Харке-Бера, особенно для маленьких выборок.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from scipy.stats import kstest\n",
        "from scipy.stats import norm\n",
        "# Вычисление среднего и стандартного отклонения\n",
        "mean, std = norm.fit(данные)\n",
        "# Выполнение теста\n",
        "stat, p_value = kstest(данные, 'norm', args=(mean, std))\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): данные соответствуют указанному теоретическому распределению.\n",
        "- Альтернативная гипотеза (H₁): данные не соответствуют указанному теоретическому распределению.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что данные не соответствуют нормальному распределению.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **Тесты на гомогенность дисперсий**\n",
        "\n",
        "**Гомогенность дисперсий**: Это свойство данных, при котором дисперсии (разбросы) в различных группах одинаковы. Гомогенность дисперсий является важным предположением для многих параметрических тестов, таких как ANOVA.\n",
        "\n",
        "#### 2.1 Тест Левена\n",
        "\n",
        "Тест Левена проверяет гипотезу о равенстве дисперсий между несколькими выборками. Он менее чувствителен к отклонению от нормальности, чем тест Бартлетта, поэтому часто используется в случаях, когда данные могут быть слегка не нормальными.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from scipy.stats import levene\n",
        "# Выполнение теста для нескольких групп\n",
        "stat, p_value = levene(выборка1, выборка2, ...)\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): дисперсии всех выборок равны.\n",
        "- Альтернативная гипотеза (H₁): хотя бы одна дисперсия отличается от остальных.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что дисперсии неоднородны.\n",
        "\n",
        "#### 2.2 Тест Бартлетта\n",
        "\n",
        "Тест Бартлетта также проверяет гипотезу о равенстве дисперсий между несколькими выборками, но он более чувствителен к отклонению от нормальности. Поэтому его рекомендуется использовать только в случае, когда данные точно следуют нормальному распределению.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from scipy.stats import bartlett\n",
        "# Выполнение теста для нескольких групп\n",
        "stat, p_value = bartlett(выборка1, выборка2, ...)\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): дисперсии всех выборок равны.\n",
        "- Альтернативная гипотеза (H₁): хотя бы одна дисперсия отличается от остальных.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что дисперсии неоднородны.\n",
        "\n",
        "\n",
        "\n",
        "### 3. **Непараметрические тесты**\n",
        "\n",
        "Непараметрические тесты не требуют предположений о форме распределения данных, что делает их особенно полезными при работе с данными, которые не удовлетворяют условиям нормальности или гомогенности дисперсий.\n",
        "\n",
        "#### 3.1 Тест Манна-Уитни (U-тест)\n",
        "\n",
        "Тест Манна-Уитни сравнивает две независимые выборки для определения одинаковости их распределений. Он является аналогом t-теста для независимых выборок в случае, когда данные не являются нормально распределенными.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from scipy.stats import mannwhitneyu\n",
        "stat, p_value = mannwhitneyu(выборка1, выборка2, alternative='two-sided')\n",
        "```\n",
        "\n",
        "- Параметр `alternative` может принимать значения:\n",
        "  - `'two-sided'`: проверка на различие между распределениями (двусторонняя альтернатива).\n",
        "  - `'less'`: проверка, что первая выборка меньше второй.\n",
        "  - `'greater'`: проверка, что первая выборка больше второй.\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): два распределения одинаковы.\n",
        "- Альтернативная гипотеза (H₁): два распределения различаются.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что распределения различаются.\n",
        "\n",
        "#### 3.2 Тест Крускала-Уоллиса\n",
        "\n",
        "Тест Крускала-Уоллиса — обобщение теста Манна-Уитни для более чем двух групп. Он используется для сравнения нескольких независимых выборок и является аналогом однофакторного ANOVA для непараметрических данных.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from scipy.stats import kruskal\n",
        "stat, p_value = kruskal(выборка1, выборка2, ...)\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): все группы имеют одинаковые распределения.\n",
        "- Альтернативная гипотеза (H₁): хотя бы одна группа имеет другое распределение.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что распределения различаются.\n",
        "\n",
        "> **Примечание**: Если тест Крускала-Уоллиса показывает значимые различия, можно использовать пост-hoc тесты, такие как тест Дันна, для выявления пар групп, которые отличаются статистически значимо.\n",
        "\n",
        "\n",
        "\n",
        "### 4. **Тесты на автокорреляцию**\n",
        "\n",
        "Автокорреляция возникает, когда значения в данных зависят друг от друга, например, во временных рядах. Автокорреляция может указывать на проблемы в моделировании или на наличие скрытых паттернов в данных.\n",
        "\n",
        "#### 4.1 Тест Дарбина-Уотсона\n",
        "\n",
        "Тест Дарбина-Уотсона проверяет наличие автокорреляции первого порядка в остатках регрессионной модели. Этот тест часто используется в эконометрике для диагностики линейных моделей.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "dw_stat = durbin_watson(остатки)\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Значение DW близко к 2 указывает на отсутствие автокорреляции.\n",
        "- Значение DW << 2 указывает на положительную автокорреляцию (последующие значения зависят от предыдущих).\n",
        "- Значение DW >> 2 указывает на отрицательную автокорреляцию (последующие значения противоположны предыдущим).\n",
        "\n",
        "> **Примечание**: Тест Дарбина-Уотсона не подходит для моделей с лагированными зависимыми переменными.\n",
        "\n",
        "#### 4.2 Тест Льюнга-Бокса\n",
        "\n",
        "Тест Льюнга-Бокса проверяет наличие автокорреляции в данных на нескольких запаздываниях. Он часто используется для анализа временных рядов.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "lb_stat, p_value = acorr_ljungbox(данные, lags=[1, 2, 3], return_df=False)\n",
        "```\n",
        "\n",
        "- Параметр `lags` позволяет указать список запаздываний, которые нужно проверить.\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): нет автокорреляции до заданного числа запаздываний.\n",
        "- Альтернативная гипотеза (H₁): есть автокорреляция.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что есть автокорреляция.\n",
        "\n",
        "#### 4.3 Тест Бреуша-Годфри\n",
        "\n",
        "Тест Бреуша-Годфри является более универсальным тестом на автокорреляцию для различных типов моделей, включая регрессии с лагированными переменными. Он проверяет наличие автокорреляции в остатках до указанного числа запаздываний.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from statsmodels.stats.diagnostic import acorr_breusch_godfrey\n",
        "bg_stat, p_value = acorr_breusch_godfrey(модель, nlags=3)\n",
        "```\n",
        "\n",
        "- Параметр `nlags` определяет количество проверяемых запаздываний.\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): нет автокорреляции.\n",
        "- Альтернативная гипотеза (H₁): есть автокорреляция.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что есть автокорреляция.\n",
        "\n",
        "\n",
        "\n",
        "### 5. **Тесты на мультиколлинеарность**\n",
        "\n",
        "Мультиколлинеарность возникает, когда независимые переменные сильно коррелируют между собой. Это может привести к нестабильности коэффициентов регрессии и затруднить интерпретацию модели.\n",
        "\n",
        "#### 5.1 Вычисление VIF (Variance Inflation Factor)\n",
        "\n",
        "**Описание:**  \n",
        "VIF измеряет степень мультиколлинеарности между независимыми переменными. Чем выше значение VIF, тем сильнее зависимость переменной от других независимых переменных в модели.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pandas as pd\n",
        "\n",
        "# Создание матрицы признаков\n",
        "X = pd.DataFrame(матрица_признаков)\n",
        "\n",
        "# Вычисление VIF для каждой переменной\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Значение VIF > 10 указывает на высокую мультиколлинеарность.\n",
        "- Значение VIF близко к 1 указывает на отсутствие мультиколлинеарности.\n",
        "\n",
        "> **Примечание**: Если VIF высокий для нескольких переменных, можно попробовать удалить одну из них или использовать методы регуляризации (например, Ridge или Lasso).\n",
        "\n",
        "\n",
        "\n",
        "### 6. **Тесты на гетероскедастичность**\n",
        "\n",
        "Гетероскедастичность возникает, когда дисперсия ошибок меняется с изменением значений независимых переменных. Это нарушает одно из предположений классической линейной регрессии.\n",
        "\n",
        "#### 6.1 Тест Бреуша-Пагана\n",
        "\n",
        "**Описание:**  \n",
        "Тест Бреуша-Пагана проверяет гипотезу о равенстве дисперсий ошибок в регрессионной модели. Он предполагает определенную форму зависимости дисперсии ошибок от независимых переменных.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "bp_stat, p_value, _, _ = het_breuschpagan(остатки, матрица_признаков)\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): дисперсия ошибок постоянна.\n",
        "- Альтернативная гипотеза (H₁): дисперсия ошибок меняется.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что есть гетероскедастичность.\n",
        "\n",
        "#### 6.2 Тест Уайта\n",
        "\n",
        "**Описание:**  \n",
        "Тест Уайта — обобщенный тест на гетероскедастичность без специфических предположений о форме зависимости дисперсии ошибок. Он более универсален, чем тест Бреуша-Пагана.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "white_stat, p_value, _, _ = het_white(остатки, матрица_признаков)\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): дисперсия ошибок постоянна.\n",
        "- Альтернативная гипотеза (H₁): дисперсия ошибок меняется.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что есть гетероскедастичность.\n",
        "\n",
        "> **Примечание**: Если тесты показывают наличие гетероскедастичности, можно использовать робастные стандартные ошибки (например, Huber-White) или преобразования данных (например, логарифмирование).\n",
        "\n",
        "\n",
        "\n",
        "### 7. **Тесты на единичные корни и стационарность**\n",
        "\n",
        "Эти тесты проверяют, является ли временной ряд стационарным. Стационарность важна для многих моделей временных рядов, таких как ARIMA.\n",
        "\n",
        "#### 7.1 Тест Дики-Фуллера (ADF)\n",
        "\n",
        "**Описание:**  \n",
        "Тест Дики-Фуллера проверяет стационарность временного ряда. Он используется для выявления единичных корней, которые указывают на нестационарность.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "adf_result = adfuller(временной_ряд)\n",
        "adf_stat, p_value = adf_result[0], adf_result[1]\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): временной ряд нестационарен.\n",
        "- Альтернативная гипотеза (H₁): временной ряд стационарен.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что ряд стационарен.\n",
        "\n",
        "#### 7.2 Тест КПСС (KPSS)\n",
        "\n",
        "**Описание:**  \n",
        "Тест КПСС проверяет гипотезу о стационарности временного ряда. В отличие от теста ADF, он предполагает стационарность по умолчанию.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from statsmodels.tsa.stattools import kpss\n",
        "kpss_result = kpss(временной_ряд)\n",
        "kpss_stat, p_value = kpss_result[0], kpss_result[1]\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Нулевая гипотеза (H₀): временной ряд стационарен.\n",
        "- Альтернативная гипотеза (H₁): временной ряд нестационарен.\n",
        "- Если `p_value` < α (обычно 0.05), то отклоняем H₀, что означает, что ряд нестационарен.\n",
        "\n",
        "> **Примечание**: Тесты ADF и KPSS часто используются вместе, так как они имеют противоположные нулевые гипотезы. Если один тест указывает на стационарность, а другой — на нестационарность, это может быть сигналом необходимости дальнейшего анализа.\n",
        "\n",
        "\n",
        "3. **Анализ временных рядов:**\n",
        "\n",
        "   Statsmodels предоставляет инструменты для анализа временных рядов, включая модели ARIMA, SARIMAX и методы декомпозиции. Эти методы позволяют анализировать и прогнозировать временные ряды, учитывая тренды, сезонность и другие компоненты.\n",
        "\n",
        "   **Синтаксис:**\n",
        "   - **Модель ARIMA:**\n",
        "     ```python\n",
        "     statsmodels.tsa.ARIMA(данные, order=(p, d, q))\n",
        "     ```\n",
        "     Где:\n",
        "     - `данные` — временной ряд.\n",
        "     - `order=(p, d, q)` — параметры модели (порядок авторегрессии, степень дифференцирования, порядок скользящего среднего).\n",
        "\n",
        "   - **Модель SARIMAX:**\n",
        "     ```python\n",
        "     statsmodels.tsa.SARIMAX(данные, order=(p, d, q), seasonal_order=(P, D, Q, s))\n",
        "     ```\n",
        "     Где:\n",
        "     - `seasonal_order=(P, D, Q, s)` — параметры сезонной компоненты.\n",
        "\n",
        "   - **Декомпозиция временного ряда:**\n",
        "     ```python\n",
        "     statsmodels.tsa.seasonal_decompose(данные, model='additive')\n",
        "     ```\n",
        "     Где:\n",
        "     - `model='additive'` или `model='multiplicative'` — тип декомпозиции (аддитивная или мультипликативная).\n",
        "\n",
        "   Эти методы позволяют анализировать структуру временных рядов, выделять тренды, сезонность и остаточные компоненты, а также строить прогнозы.\n",
        "\n",
        "4. **Обобщенные линейные модели (GLM):**\n",
        "\n",
        "   Statsmodels поддерживает обобщенные линейные модели, которые позволяют моделировать данные с различными типами распределений (например, биномиальное, Пуассона).\n",
        "\n",
        "   **Синтаксис:**\n",
        "   - **Создание модели GLM:**\n",
        "     ```python\n",
        "     statsmodels.GLM(зависимая_переменная, независимые_переменные, family=распределение)\n",
        "     ```\n",
        "     Где:\n",
        "     - `family` — семейство распределений (например, `statsmodels.families.Gaussian()` для нормального распределения).\n",
        "\n",
        "   - **Обучение модели:**\n",
        "     ```python\n",
        "     model.fit()\n",
        "     ```\n",
        "\n",
        "   - **Вывод статистики модели:**\n",
        "     ```python\n",
        "     model.summary()\n",
        "     ```\n",
        "\n",
        "   Эти модели полезны для анализа данных, которые не соответствуют предположениям линейной регрессии.\n",
        "\n",
        "5. **Доверительные интервалы и прогнозирование:**\n",
        "\n",
        "   Statsmodels предоставляет функции для вычисления доверительных интервалов и прогнозирования на основе построенных моделей.\n",
        "\n",
        "   **Синтаксис:**\n",
        "   - **Доверительные интервалы для прогнозов:**\n",
        "     ```python\n",
        "     model.get_prediction().conf_int()\n",
        "     ```\n",
        "\n",
        "   - **Прогнозирование:**\n",
        "     ```python\n",
        "     model.predict(новые_данные)\n",
        "     ```\n",
        "\n",
        "   Эти функции позволяют оценивать точность прогнозов и строить интервальные оценки для будущих значений.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 2.8 Scikit-learn\n",
        "\n",
        "Scikit-learn — это мощная библиотека для машинного обучения и анализа данных, предоставляющая широкий спектр алгоритмов для решения задач классификации, регрессии, кластеризации, уменьшения размерности и оценки моделей. Библиотека отличается структурированным интерфейсом, что делает её удобной как для задач машинного обучения, так и для статистического анализа. В данном разделе рассматриваются ключевые статические возможности Scikit-learn, которые могут быть использованы для выполнения различных типов статистических вычислений.\n",
        "\n",
        "#### Основные возможности Scikit-learn для статистики\n",
        "\n",
        "### 1. **Классификация и Регрессия**\n",
        "\n",
        "Scikit-learn предоставляет набор методов для построения моделей классификации и регрессии, которые позволяют решать задачи прогнозирования на основе входных данных.\n",
        "\n",
        "#### Статические возможности:\n",
        "\n",
        "- **Логистическая регрессия:**\n",
        "  Логистическая регрессия является одним из основных методов для бинарной и мультиклассовой классификации.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `penalty`: Тип регуляризации (например, 'l1', 'l2').\n",
        "    - `C`: Обратная величина коэффициента регуляризации.\n",
        "    - `solver`: Метод оптимизации (например, 'lbfgs', 'liblinear').\n",
        "\n",
        "- **Линейная регрессия:**\n",
        "  Линейная регрессия используется для прогнозирования числового значения на основе линейной зависимости между признаками и целевой переменной.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.linear_model.LinearRegression(fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False)\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `fit_intercept`: Указывает, нужно ли рассчитывать свободный член (intercept).\n",
        "    - `normalize`: Нормализация данных перед обучением (устаревший параметр).\n",
        "\n",
        "- **Обучение модели:**\n",
        "  Для обучения любой модели используется метод `.fit()`.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    model.fit(X, y)\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `X`: Матрица признаков.\n",
        "    - `y`: Вектор целевых значений.\n",
        "\n",
        "- **Прогнозирование:**\n",
        "  После обучения модель может быть использована для прогнозирования новых данных.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    model.predict(X_new)\n",
        "    ```\n",
        "\n",
        "### 2. **Кластеризация**\n",
        "\n",
        "Кластеризация представляет собой процесс группировки данных на основе их схожести. Scikit-learn предоставляет несколько популярных алгоритмов кластеризации.\n",
        "\n",
        "#### Статические возможности:\n",
        "\n",
        "- **K-means:**\n",
        "  K-means — это алгоритм разделения данных на k кластеров на основе минимизации внутрикластерной дисперсии.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.cluster.KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='deprecated', verbose=0, random_state=None, copy_x=True, n_jobs=None, algorithm='auto')\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `n_clusters`: Количество кластеров.\n",
        "    - `init`: Метод инициализации центроидов.\n",
        "    - `max_iter`: Максимальное количество итераций.\n",
        "\n",
        "- **DBSCAN:**\n",
        "  DBSCAN (Density-Based Spatial Clustering of Applications with Noise) — это алгоритм, который находит кластеры произвольной формы на основе плотности точек.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.cluster.DBSCAN(eps=0.5, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30, p=None, n_jobs=None)\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `eps`: Максимальное расстояние между точками для считаться одной группой.\n",
        "    - `min_samples`: Минимальное количество точек для формирования кластера.\n",
        "\n",
        "- **Обучение модели:**\n",
        "  Для выполнения кластеризации используется метод `.fit()`.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    model.fit(X)\n",
        "    ```\n",
        "\n",
        "- **Получение меток кластеров:**\n",
        "  После обучения можно получить метки кластеров для каждого объекта.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    model.labels_\n",
        "    ```\n",
        "\n",
        "### 3. **Уменьшение Размерности**\n",
        "\n",
        "Методы уменьшения размерности позволяют преобразовать данные в пространство меньшей размерности, сохраняя важную информацию.\n",
        "\n",
        "#### Статические возможности:\n",
        "\n",
        "- **PCA (Principal Component Analysis):**\n",
        "  PCA — это метод, который преобразует данные в новое пространство, где первые компоненты объясняют наибольшую дисперсию данных.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.decomposition.PCA(n_components=None, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `n_components`: Количество главных компонент.\n",
        "    - `whiten`: Нормализация компонентов.\n",
        "\n",
        "- **t-SNE:**\n",
        "  t-SNE (t-distributed Stochastic Neighbor Embedding) — это метод нелинейного уменьшения размерности, особенно полезный для визуализации высокоразмерных данных.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.manifold.TSNE(n_components=2, perplexity=30.0, early_exaggeration=12.0, learning_rate=200.0, n_iter=1000, n_iter_without_progress=300, min_grad_norm=1e-07, metric='euclidean', init='random', verbose=0, random_state=None, method='barnes_hut', angle=0.5, n_jobs=None, square_distances='deprecated')\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `n_components`: Количество выходных компонент.\n",
        "    - `perplexity`: Параметр, контролирующий баланс между локальными и глобальными аспектами данных.\n",
        "\n",
        "- **Преобразование данных:**\n",
        "  Для выполнения преобразования используется метод `.fit_transform()`.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    model.fit_transform(X)\n",
        "    ```\n",
        "\n",
        "### 4. **Оценка Моделей**\n",
        "\n",
        "Scikit-learn предоставляет инструменты для оценки качества моделей, что является важной частью статистического анализа.\n",
        "\n",
        "#### Статические возможности:\n",
        "\n",
        "- **Cross-validation:**\n",
        "  Cross-validation позволяет оценить качество модели на основе разбиения данных на обучающую и тестовую выборки.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.model_selection.cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `estimator`: Обучаемая модель.\n",
        "    - `cv`: Число фолдов для кросс-валидации.\n",
        "\n",
        "- **Метрики качества:**\n",
        "  Scikit-learn поддерживает множество метрик для оценки моделей.\n",
        "  - **Для классификации:**\n",
        "    - `sklearn.metrics.accuracy_score(y_true, y_pred)`\n",
        "    - `sklearn.metrics.f1_score(y_true, y_pred)`\n",
        "  - **Для регрессии:**\n",
        "    - `sklearn.metrics.mean_squared_error(y_true, y_pred)`\n",
        "    - `sklearn.metrics.r2_score(y_true, y_pred)`\n",
        "\n",
        "### 5. **Работа с Данными**\n",
        "\n",
        "Scikit-learn также предоставляет инструменты для предварительной обработки данных, что является важным этапом перед построением моделей.\n",
        "\n",
        "#### Статические возможности:\n",
        "\n",
        "- **Нормализация данных:**\n",
        "  Нормализация данных позволяет привести все признаки к одному масштабу.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `with_mean`: Центрирование данных.\n",
        "    - `with_std`: Масштабирование данных.\n",
        "\n",
        "- **Кодирование категориальных признаков:**\n",
        "  Для преобразования категориальных признаков в числовые используются методы кодирования.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.preprocessing.OneHotEncoder(categories='auto', drop=None, sparse=True, dtype=<class 'numpy.float64'>, handle_unknown='error')\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `categories`: Категории для кодирования.\n",
        "    - `handle_unknown`: Обработка неизвестных категорий.\n",
        "\n",
        "- **Разделение данных:**\n",
        "  Для разделения данных на обучающую и тестовую выборки используется метод `train_test_split`.\n",
        "  - **Синтаксис:**  \n",
        "    ```python\n",
        "    sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
        "    ```\n",
        "  - **Параметры:**\n",
        "    - `test_size`: Размер тестовой выборки.\n",
        "    - `random_state`: Инициализация генератора случайных чисел.\n",
        "\n",
        "\n",
        "##Вопросы для самопроверки\n",
        "\n",
        "1. Что такое NumPy?\n",
        "2. Как создать одномерный массив в NumPy?\n",
        "3. Как создать многомерный массив?\n",
        "4. Назовите основные свойства массива NumPy.\n",
        "5. Какие математические операции поддерживает NumPy?\n",
        "6. Как генерировать случайные числа в NumPy?\n",
        "7. Что такое индексирование и срезы в NumPy?\n",
        "8. Как трансформировать массивы в NumPy?\n",
        "9. Какие агрегатные функции предоставляет NumPy?\n",
        "10. Что такое Pandas?\n",
        "11. Как создать DataFrame в Pandas?\n",
        "12. Как читать данные из CSV файла в Pandas?\n",
        "13. Как обрабатывать пропущенные значения в Pandas?\n",
        "14. Как группировать данные в Pandas?\n",
        "15. Как фильтровать данные в Pandas?\n",
        "16. Как добавлять/удалять столбцы в DataFrame?\n",
        "17. Как объединять данные в Pandas?\n",
        "18. Что такое Series в Pandas?\n",
        "19. Как получить информацию о структуре DataFrame?\n",
        "20. Что такое Matplotlib?\n",
        "21. Как построить линейный график в Matplotlib?\n",
        "22. Как создать гистограмму в Matplotlib?\n",
        "23. Как создать диаграмму рассеяния в Matplotlib?\n",
        "24. Что такое Seaborn?\n",
        "25. Как создать тепловую карту в Seaborn?\n",
        "26. Как построить boxplot в Seaborn?\n",
        "27. Как добавить легенду к графику в Matplotlib?\n",
        "28. Как настроить цветовую палитру в Seaborn?\n",
        "29. Что такое Plotly?\n",
        "30. Как создать интерактивную диаграмму рассеяния в Plotly?\n",
        "31. Как создать 3D график в Plotly?\n",
        "32. Что такое Bokeh?\n",
        "33. Как создать интерактивный линейный график в Bokeh?\n",
        "34. Как добавить инструмент наведения в Bokeh?\n",
        "35. Какие преимущества имеет Plotly перед Bokeh?\n",
        "36. Какие преимущества имеет Bokeh перед Plotly?\n",
        "37. Что такое Polars?\n",
        "38. Как создать DataFrame в Polars?\n",
        "39. Какие преимущества дает использование Polars при работе с большими объемами данных?\n",
        "40. Что такое ленивые вычисления в Polars?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Задачи для самостоятельной работы\n",
        "\n",
        "1. Создайте одномерный массив NumPy размером 10, заполненный числами от 0 до 9.\n",
        "2. Выполните поэлементное умножение двух массивов NumPy: `[1, 2, 3]` и `[4, 5, 6]`.\n",
        "3. Сгенерируйте массив из 10 случайных чисел, следующих нормальному распределению.\n",
        "4. Создайте двумерный массив NumPy размером 3x3 и выполните транспонирование.\n",
        "5. Найдите сумму всех элементов массива NumPy `[1, 2, 3, 4, 5]`.\n",
        "6. Создайте DataFrame в Pandas из словаря: `{'имя': ['Алекс', 'Мария'], 'возраст': [25, 30]}`.\n",
        "7. Прочитайте данные из файла CSV с помощью Pandas и выведите первые 5 строк.\n",
        "8. Удалите строки с пропущенными значениями из DataFrame.\n",
        "9. Группируйте данные в DataFrame по столбцу `'пол'` и вычислите средний возраст для каждой группы.\n",
        "10. Отфильтруйте строки DataFrame, где значение столбца `'возраст'` больше 30.\n",
        "11. Добавьте новый столбец `'статус'` в DataFrame со значением `'активен'` для всех строк.\n",
        "12. Объедините два DataFrame по общему столбцу `'id'`.\n",
        "13. Постройте линейный график для данных: `x = [1, 2, 3], y = [10, 20, 30]` в Matplotlib.\n",
        "14. Постройте гистограмму для массива случайных чисел, сгенерированного в задаче №3.\n",
        "15. Постройте диаграмму рассеяния для данных: `x = [1, 2, 3], y = [10, 20, 30]` в Matplotlib.\n",
        "16. Постройте диаграмму рассеяния с группировкой по категории в Seaborn, используя встроенный набор данных `'iris'`.\n",
        "17. Создайте тепловую карту корреляций для встроенного набора данных `'tips'` в Seaborn.\n",
        "18. Постройте интерактивную диаграмму рассеяния для данных: `x = [1, 2, 3], y = [10, 20, 30]` в Plotly.\n",
        "19. Создайте 3D-график для данных: `x = [1, 2, 3], y = [10, 20, 30], z = [100, 200, 300]` в Plotly.\n",
        "20. Постройте интерактивную диаграмму рассеяния для данных: `x = [1, 2, 3], y = [10, 20, 30]` в Bokeh.\n",
        "21. Создайте DataFrame в Polars из словаря: `{'имя': ['Алекс', 'Мария'], 'возраст': [25, 30]}`.\n",
        "22. Отфильтруйте строки DataFrame в Polars, где значение столбца `'возраст'` больше 25.\n",
        "23. Выполните сортировку DataFrame в Polars по столбцу `'возраст'` в порядке убывания.\n",
        "24. Выполните группировку данных в Polars по столбцу `'пол'` и вычислите средний возраст для каждой группы.\n",
        "25. Используя SciPy, проверьте нормальность распределения для массива случайных чисел из задачи №3.\n",
        "26. Выполните t-тест для двух выборок: `[1, 2, 3, 4]` и `[5, 6, 7, 8]` с помощью SciPy.\n",
        "27. Постройте модель линейной регрессии для данных: `x = [1, 2, 3], y = [10, 20, 30]` с помощью Statsmodels.\n",
        "28. Выполните кластеризацию методом K-means для данных: `[[1, 2], [3, 4], [5, 6]]` с помощью Scikit-learn.\n",
        "29. Сократите размерность данных `[[1, 2, 3], [4, 5, 6]]` до 2 компонент с помощью PCA в Scikit-learn.\n",
        "30. Разделите данные на обучающую и тестовую выборки с помощью функции `train_test_split` в Scikit-learn.\n"
      ],
      "metadata": {
        "id": "gQQZgciWuzji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Визуализация данных на Python**\n",
        "\n",
        "Визуализация данных — это один из самых важных этапов анализа данных. Она позволяет не только лучше понять структуру данных, но и выявить скрытые закономерности, аномалии и тренды. В этой главе мы рассмотрим основные методы визуализации данных с использованием библиотек Python, таких как `matplotlib`, `seaborn`, `plotly` и `bokeh`. Все примеры будут выполняться в среде Google Colab, что делает их доступными для любого читателя.\n",
        "\n",
        "\n",
        "### **3.1 Гистограммы и Ядерные Оценки Плотности**\n",
        "\n",
        "#### **Гистограмма**\n",
        "\n",
        "**Гистограмма** — это один из самых простых и популярных способов визуализации распределения данных. Она разбивает данные на интервалы (бины) и показывает, сколько значений попадает в каждый из них. Гистограмма помогает понять, как распределены данные: есть ли пики, симметрия, выбросы и т.д.\n",
        "\n",
        "**Пример построения гистограммы с использованием `matplotlib` и `seaborn`:**\n",
        "\n",
        "```python\n",
        "# Импорт необходимых библиотек\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Генерация случайных данных\n",
        "data = np.random.normal(0, 1, 1000)  # 1000 точек из нормального распределения\n",
        "\n",
        "# Построение гистограммы\n",
        "plt.figure(figsize=(8, 6))  # Задаем размер графика\n",
        "sns.histplot(data, bins=30, kde=False, color='blue')  # bins — количество интервалов\n",
        "plt.title('Гистограмма распределения данных')  # Заголовок графика\n",
        "plt.xlabel('Значения')  # Подпись оси X\n",
        "plt.ylabel('Частота')  # Подпись оси Y\n",
        "plt.show()  # Отображение графика\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- `np.random.normal(0, 1, 1000)` генерирует 1000 случайных чисел из нормального распределения со средним 0 и стандартным отклонением 1.\n",
        "- `sns.histplot` строит гистограмму. Параметр `bins=30` задает количество интервалов, на которые разбиваются данные.\n",
        "- `kde=False` отключает ядерную оценку плотности (KDE), чтобы построить только гистограмму.\n",
        "\n",
        "\n",
        "\n",
        "#### **Ядерная оценка плотности (Kernel Density Estimation, KDE)**\n",
        "\n",
        "**Ядерная оценка плотности (KDE)** — это метод сглаживания гистограммы, который позволяет оценить плотность распределения данных. В отличие от гистограммы, KDE не зависит от выбора интервалов (бинов) и дает более гладкую кривую, что помогает лучше понять форму распределения.\n",
        "\n",
        "**Пример добавления KDE к гистограмме:**\n",
        "\n",
        "```python\n",
        "# Построение гистограммы с KDE\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(data, bins=30, kde=True, color='green')  # kde=True добавляет KDE\n",
        "plt.title('Гистограмма с ядерной оценкой плотности')\n",
        "plt.xlabel('Значения')\n",
        "plt.ylabel('Плотность')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- `kde=True` добавляет к гистограмме гладкую кривую, которая показывает оценку плотности распределения данных.\n",
        "- KDE особенно полезен, когда нужно визуализировать форму распределения без привязки к конкретным бинам.\n",
        "\n",
        "\n",
        "\n",
        "### **3.2 Boxplot (ящик с усами)**\n",
        "\n",
        "#### **Boxplot**\n",
        "\n",
        "**Boxplot** (или \"ящик с усами\") — это график, который показывает медиану, квартили и выбросы в данных. Он полезен для сравнения распределений между несколькими группами данных. Boxplot помогает быстро оценить центральную тенденцию, разброс и наличие выбросов.\n",
        "\n",
        "**Пример построения boxplot:**\n",
        "\n",
        "```python\n",
        "# Генерация данных\n",
        "data1 = np.random.normal(0, 1, 100)  # 100 точек из нормального распределения\n",
        "data2 = np.random.normal(2, 1.5, 100)  # 100 точек из другого нормального распределения\n",
        "\n",
        "# Построение boxplot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=[data1, data2])  # Передаем список данных для сравнения\n",
        "plt.title('Boxplot для двух наборов данных')\n",
        "plt.xlabel('Группы')  # Ось X показывает группы данных\n",
        "plt.ylabel('Значения')  # Ось Y показывает значения\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- `sns.boxplot` строит boxplot для каждого набора данных. В данном случае мы сравниваем два набора данных: `data1` и `data2`.\n",
        "- На графике:\n",
        "  - **Ящик** показывает межквартильный размах (IQR), т.е. диапазон между первым и третьим квартилями.\n",
        "  - **Линия внутри ящика** — это медиана.\n",
        "  - **Усы** показывают диапазон данных, за исключением выбросов.\n",
        "  - **Точки за пределами усов** — это выбросы.\n",
        "\n",
        "\n",
        "\n",
        "### **Практические советы для начинающих**\n",
        "\n",
        "1. **Гистограммы**:\n",
        "   - Используйте гистограммы, чтобы понять, как распределены данные.\n",
        "   - Экспериментируйте с количеством бинов (`bins`), чтобы найти оптимальное представление данных.\n",
        "\n",
        "2. **KDE**:\n",
        "   - Используйте KDE, когда нужно визуализировать форму распределения без привязки к бинам.\n",
        "   - KDE особенно полезен для сравнения нескольких распределений.\n",
        "\n",
        "3. **Boxplot**:\n",
        "   - Используйте boxplot для сравнения распределений между группами.\n",
        "   - Обратите внимание на выбросы — они могут указывать на аномалии в данных.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **3.3 Диаграммы рассеяния (Scatter plots)**\n",
        "\n",
        "#### **Диаграммы рассеяния**\n",
        "\n",
        "**Диаграммы рассеяния** (Scatter plots) используются для визуализации взаимосвязи между двумя переменными. Они помогают выявить корреляции, кластеры и выбросы. Диаграммы рассеяния особенно полезны, когда нужно понять, как одна переменная зависит от другой.\n",
        "\n",
        "**Пример построения scatter plot:**\n",
        "\n",
        "```python\n",
        "# Импорт необходимых библиотек\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Генерация данных\n",
        "x = np.random.normal(0, 1, 100)  # 100 случайных точек из нормального распределения\n",
        "y = 2 * x + np.random.normal(0, 1, 100)  # y зависит от x с добавлением шума\n",
        "\n",
        "# Построение scatter plot\n",
        "plt.figure(figsize=(8, 6))  # Задаем размер графика\n",
        "sns.scatterplot(x=x, y=y, color='purple')  # Построение диаграммы рассеяния\n",
        "plt.title('Диаграмма рассеяния')  # Заголовок графика\n",
        "plt.xlabel('X')  # Подпись оси X\n",
        "plt.ylabel('Y')  # Подпись оси Y\n",
        "plt.show()  # Отображение графика\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- `x` и `y` — это две переменные, между которыми мы хотим визуализировать взаимосвязь.\n",
        "- `sns.scatterplot` строит диаграмму рассеяния. Точки на графике показывают значения `x` и `y`.\n",
        "- Цвет точек можно изменить с помощью параметра `color`.\n",
        "\n",
        "\n",
        "\n",
        "### **3.4 Heatmaps (тепловые карты)**\n",
        "\n",
        "#### **Heatmap**\n",
        "\n",
        "**Heatmap** (тепловая карта) — это график, который использует цветовую палитру для представления значений матрицы. Он часто используется для визуализации корреляционных матриц или данных с двумя категориальными осями. Heatmap помогает быстро оценить структуру данных и выявить закономерности.\n",
        "\n",
        "**Пример построения heatmap:**\n",
        "\n",
        "```python\n",
        "# Генерация данных (случайная матрица 10x10)\n",
        "data = np.random.rand(10, 10)\n",
        "\n",
        "# Построение heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(data, annot=True, cmap='coolwarm')  # annot=True добавляет значения в ячейки\n",
        "plt.title('Тепловая карта')  # Заголовок графика\n",
        "plt.show()  # Отображение графика\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- `data` — это матрица 10x10 со случайными значениями.\n",
        "- `sns.heatmap` строит тепловую карту. Параметр `annot=True` добавляет значения в ячейки, а `cmap='coolwarm'` задает цветовую палитру.\n",
        "- Тепловая карта полезна для визуализации корреляций между переменными.\n",
        "\n",
        "\n",
        "\n",
        "### **3.5 Q-Q Plot**\n",
        "\n",
        "#### **Q-Q Plot**\n",
        "\n",
        "**Q-Q Plot** (Quantile-Quantile Plot) используется для проверки, насколько хорошо распределение данных соответствует теоретическому распределению, например, нормальному. Q-Q Plot помогает оценить, насколько данные близки к нормальному распределению.\n",
        "\n",
        "**Пример построения Q-Q Plot:**\n",
        "\n",
        "```python\n",
        "# Импорт необходимых библиотек\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Построение Q-Q Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "stats.probplot(data, dist=\"norm\", plot=plt)  # dist=\"norm\" задает нормальное распределение\n",
        "plt.title('Q-Q Plot для проверки нормальности')  # Заголовок графика\n",
        "plt.show()  # Отображение графика\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- `stats.probplot` строит Q-Q Plot. Параметр `dist=\"norm\"` указывает, что мы сравниваем данные с нормальным распределением.\n",
        "- Если точки на графике лежат близко к прямой линии, это означает, что данные близки к нормальному распределению.\n",
        "\n",
        "\n",
        "\n",
        "### **3.6 Интерактивные графики**\n",
        "\n",
        "#### **Интерактивные графики**\n",
        "\n",
        "Интерактивные графики позволяют пользователю взаимодействовать с данными, например, увеличивать участки графика, скрывать или показывать линии и т.д. Для создания интерактивных графиков в Python часто используются библиотеки `plotly` и `bokeh`.\n",
        "\n",
        "**Пример интерактивного графика с использованием `plotly`:**\n",
        "\n",
        "```python\n",
        "# Импорт необходимых библиотек\n",
        "import plotly.express as px\n",
        "\n",
        "# Генерация данных (встроенный набор данных iris)\n",
        "df = px.data.iris()\n",
        "\n",
        "# Построение интерактивного scatter plot\n",
        "fig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\")  # Цвет точек зависит от вида\n",
        "fig.show()  # Отображение графика\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- `px.scatter` строит интерактивную диаграмму рассеяния. Параметр `color=\"species\"` задает цвет точек в зависимости от вида цветка.\n",
        "- График можно масштабировать, перемещать и наводить курсор на точки, чтобы увидеть их значения.\n",
        "\n",
        "**Пример интерактивного графика с использованием `bokeh`:**\n",
        "\n",
        "```python\n",
        "# Импорт необходимых библиотек\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "# Включение отображения в ноутбуке\n",
        "output_notebook()\n",
        "\n",
        "# Генерация данных\n",
        "x = np.random.random(100)  # 100 случайных точек\n",
        "y = np.random.random(100)  # 100 случайных точек\n",
        "\n",
        "# Построение интерактивного scatter plot\n",
        "p = figure(title=\"Интерактивный scatter plot\", x_axis_label='X', y_axis_label='Y')  # Создание фигуры\n",
        "p.circle(x, y, size=10, color=\"navy\", alpha=0.5)  # Добавление точек\n",
        "show(p)  # Отображение графика\n",
        "```\n",
        "\n",
        "**Объяснение:**\n",
        "- `figure` создает интерактивную фигуру. Параметры `x_axis_label` и `y_axis_label` задают подписи осей.\n",
        "- `p.circle` добавляет точки на график. Параметр `alpha` задает прозрачность точек.\n",
        "- График можно масштабировать и перемещать.\n",
        "\n",
        "\n",
        "\n",
        "### **Практические советы для начинающих**\n",
        "\n",
        "1. **Диаграммы рассеяния**:\n",
        "   - Используйте scatter plot для визуализации взаимосвязи между двумя переменными.\n",
        "   - Обратите внимание на выбросы и кластеры.\n",
        "\n",
        "2. **Heatmap**:\n",
        "   - Используйте heatmap для визуализации матриц, например, корреляционных матриц.\n",
        "   - Экспериментируйте с цветовыми палитрами (`cmap`).\n",
        "\n",
        "3. **Q-Q Plot**:\n",
        "   - Используйте Q-Q Plot для проверки нормальности распределения данных.\n",
        "   - Если точки не лежат на прямой линии, данные могут не соответствовать нормальному распределению.\n",
        "\n",
        "4. **Интерактивные графики**:\n",
        "   - Используйте `plotly` и `bokeh` для создания интерактивных графиков.\n",
        "   - Интерактивные графики особенно полезны для анализа больших наборов данных.\n",
        "\n",
        "##Вопросы для самопроверки\n",
        "\n",
        "1. Что такое визуализация данных и почему она важна?\n",
        "2. Какие основные библиотеки Python используются для визуализации данных?\n",
        "3. Что такое Google Colab и как он используется для выполнения примеров кода?\n",
        "4. Что такое гистограмма и для чего она используется?\n",
        "5. Какой параметр определяет количество интервалов (бинов) в гистограмме?\n",
        "6. Каким методом можно сгладить гистограмму?\n",
        "7. Что такое ядерная оценка плотности (KDE)?\n",
        "8. В чем разница между гистограммой и KDE?\n",
        "9. Как добавить KDE к гистограмме в Seaborn?\n",
        "10. Какой код используется для построения гистограммы с помощью `matplotlib` и `seaborn`?\n",
        "11. Что показывает график boxplot?\n",
        "12. Какие элементы входят в состав boxplot (ящика с усами)?\n",
        "13. Что такое межквартильный размах (IQR) в контексте boxplot?\n",
        "14. Как можно использовать boxplot для сравнения нескольких групп данных?\n",
        "15. Как выглядит выброс на графике boxplot?\n",
        "16. Для чего используются диаграммы рассеяния?\n",
        "17. Как можно визуализировать взаимосвязь между двумя переменными с помощью scatter plot?\n",
        "18. Какие параметры можно настраивать при создании scatter plot в Seaborn?\n",
        "19. Что такое корреляция и как ее можно выявить с помощью scatter plot?\n",
        "20. Как изменить цвет точек на scatter plot?\n",
        "21. Что такое heatmap и для чего она применяется?\n",
        "22. Как можно использовать тепловую карту для визуализации корреляционных матриц?\n",
        "23. Какой параметр позволяет отображать значения внутри ячеек heatmap?\n",
        "24. Какие цветовые палитры (`cmap`) можно использовать для создания heatmap?\n",
        "25. Приведите пример кода для построения heatmap.\n",
        "26. Что такое Q-Q Plot и для чего он используется?\n",
        "27. Какой теоретический закон распределения обычно проверяется с помощью Q-Q Plot?\n",
        "28. Что означает, если точки на Q-Q Plot лежат близко к прямой линии?\n",
        "29. Как построить Q-Q Plot с использованием библиотеки SciPy?\n",
        "30. Какие библиотеки Python позволяют создавать интерактивные графики?\n",
        "31. Какие возможности предоставляют интерактивные графики для анализа данных?\n",
        "32. Как создать интерактивную диаграмму рассеяния с помощью `plotly`?\n",
        "33. Как добавить функционал масштабирования и навигации в интерактивный график с помощью `bokeh`?\n",
        "34. Как изменить цвет точек в зависимости от категорий в интерактивном графике?\n",
        "35. Как выбрать оптимальное количество бинов для гистограммы?\n",
        "36. Когда лучше использовать KDE вместо гистограммы?\n",
        "37. Почему важно обращать внимание на выбросы при анализе данных с помощью boxplot?\n",
        "38. Какие типы взаимосвязей можно выявить с помощью scatter plot?\n",
        "39. Как экспериментировать с цветовыми палитрами в heatmap для лучшей интерпретации данных?\n",
        "40. В каких случаях особенно полезны интерактивные графики?\n",
        "\n",
        "\n",
        "## Задачи для самостоятельной работы\n",
        "\n",
        "1. Создайте гистограмму для 1000 случайных чисел из нормального распределения с помощью Matplotlib.\n",
        "2. Постройте гистограмму с ядерной оценкой плотности для тех же данных с помощью Seaborn.\n",
        "3. Сгенерируйте два набора данных из нормальных распределений и сравните их с помощью Boxplot в Seaborn.\n",
        "4. Создайте диаграмму рассеяния для двух переменных, где одна зависит от другой линейно с добавлением шума.\n",
        "5. Добавьте цветовую группировку к диаграмме рассеяния в Seaborn, используя третью категориальную переменную.\n",
        "6. Постройте тепловую карту для случайной матрицы 5x5 с помощью Seaborn.\n",
        "7. Используйте Q-Q Plot для проверки нормальности распределения данных.\n",
        "8. Создайте интерактивную диаграмму рассеяния в Plotly, используя встроенный набор данных `iris`.\n",
        "9. Постройте интерактивный график в Bokeh для случайных данных с возможностью масштабирования.\n",
        "10. Измените цветовую палитру в Heatmap Seaborn на `viridis`.\n",
        "11. Увеличьте количество бинов в гистограмме Seaborn до 50.\n",
        "12. Добавьте легенду к графику, содержащему две линии, в Matplotlib.\n",
        "13. Настройте размер графика в Matplotlib на 10x8 дюймов.\n",
        "14. Сохраните созданный график в формате PNG с помощью Matplotlib.\n",
        "15. Создайте два подграфика (subplot) в Matplotlib: один — гистограмма, второй — диаграмма рассеяния.\n",
        "16. Включите сетку на графике в Matplotlib с пунктирными линиями.\n",
        "17. Добавьте аннотацию к точке (2, 3) на графике в Matplotlib.\n",
        "18. Измените стиль линии на пунктирную и маркеры на треугольники в Matplotlib.\n",
        "19. Постройте гистограмму для данных с использованием разных цветов для каждого бина.\n",
        "20. Создайте Boxplot для трех наборов данных, где каждый набор имеет разное стандартное отклонение.\n",
        "21. Добавьте горизонтальные полосы медианы на Boxplot в Seaborn.\n",
        "22. Создайте диаграмму рассеяния с регрессионной линией в Seaborn.\n",
        "23. Постройте Heatmap для корреляционной матрицы набора данных `tips` в Seaborn.\n",
        "24. Используйте Q-Q Plot для проверки нормальности распределения выборки из экспоненциального распределения.\n",
        "25. Создайте интерактивную диаграмму рассеяния в Plotly с возможностью наведения курсора на точки.\n",
        "26. Постройте интерактивный график в Bokeh с несколькими линиями и легендой.\n",
        "27. Настройте цветовую палитру в Heatmap Seaborn на `plasma`.\n",
        "28. Уменьшите количество бинов в гистограмме Seaborn до 10.\n",
        "29. Добавьте заголовок и подписи осей к графику в Matplotlib.\n",
        "30. Создайте комбинированный график в Matplotlib, содержащий гистограмму и линейный график."
      ],
      "metadata": {
        "id": "6Wl8HtDZ1FAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Дескриптивная (Описательная) Статистика**\n",
        "\n",
        "Дескриптивная статистика — это инструмент для того, чтобы лучше понять данные. Она помогает нам собрать, обработать, проанализировать и представить информацию в удобной форме. В этом разделе мы рассмотрим основные концепции описательной статистики, такие как центральная тенденция, разброс данных и распределение. Мы также научимся вычислять эти характеристики с помощью Python в Google Colab и визуализировать их.\n",
        "\n",
        "### **1. Вариационный Ряд**\n",
        "\n",
        "Вариационный ряд — это способ организовать данные в порядке возрастания или убывания. Это позволяет легко определить минимальное и максимальное значения выборки, а также размах данных.\n",
        "\n",
        "#### Основные термины:\n",
        "- **Минимальное значение ($x_{(1)}$)**: самое маленькое число в наборе данных.\n",
        "- **Максимальное значение ($x_{(n)}$)**: самое большое число в наборе данных.\n",
        "- **Размах выборки**: разница между максимальным и минимальным значениями. Формула:\n",
        "  $$\n",
        "  \\text{Размах} = x_{(n)} - x_{(1)}\n",
        "  $$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Представьте, что вы анализируете доходы сотрудников компании. Вариационный ряд поможет вам понять, как они распределены, и найти минимальный и максимальный доходы.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Создаем список данных (доходы сотрудников)\n",
        "data = [50000, 60000, 70000, 80000, 90000, 100000]\n",
        "\n",
        "# Сортируем данные\n",
        "sorted_data = sorted(data)\n",
        "\n",
        "# Находим минимальное и максимальное значения\n",
        "min_value = min(sorted_data)\n",
        "max_value = max(sorted_data)\n",
        "\n",
        "# Вычисляем размах\n",
        "range_value = max_value - min_value\n",
        "\n",
        "# Визуализируем вариационный ряд\n",
        "plt.plot(sorted_data, marker='o', linestyle='-')\n",
        "plt.title(\"Вариационный ряд\")\n",
        "plt.xlabel(\"Индекс\")\n",
        "plt.ylabel(\"Значение\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Отсортированные данные: {sorted_data}\")\n",
        "print(f\"Минимальное значение: {min_value}\")\n",
        "print(f\"Максимальное значение: {max_value}\")\n",
        "print(f\"Размах: {range_value}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `sorted(data)` — сортирует данные по возрастанию.\n",
        "2. `min()` и `max()` — находят минимальное и максимальное значения.\n",
        "3. `matplotlib.pyplot` — используется для создания графика вариационного ряда.\n",
        "\n",
        "\n",
        "\n",
        "### **2. Частоты и Относительные Частоты**\n",
        "\n",
        "Частоты показывают, сколько раз каждое значение встречается в наборе данных. Относительные частоты выражают долю каждого значения относительно общего количества данных.\n",
        "\n",
        "#### Основные термины:\n",
        "- **Частота ($\\nu$)**: количество повторений конкретного значения.\n",
        "- **Относительная частота**: доля значений, вычисленная как $\\frac{\\nu}{n}$, где $n$ — общее количество данных.\n",
        "\n",
        "#### Объяснение формулы:\n",
        "$\\nu$ — это количество раз, которое значение встречается в данных. Например, если число 3 встречается 5 раз, то $\\nu = 5$. Чтобы найти относительную частоту, мы делим $\\nu$ на общее количество данных ($n$).\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете результаты тестов студентов. Частоты покажут, сколько студентов получили каждую оценку, а относительные частоты помогут понять, какая оценка является наиболее распространённой.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Создаем список данных (оценки студентов)\n",
        "data = [4, 5, 5, 3, 4, 5, 4, 3, 2, 4]\n",
        "\n",
        "# Подсчитываем частоты\n",
        "frequency = Counter(data)\n",
        "\n",
        "# Вычисляем относительные частоты\n",
        "total_count = len(data)\n",
        "relative_frequency = {key: value / total_count for key, value in frequency.items()}\n",
        "\n",
        "# Визуализируем частоты\n",
        "plt.bar(frequency.keys(), frequency.values())\n",
        "plt.title(\"Частоты\")\n",
        "plt.xlabel(\"Оценка\")\n",
        "plt.ylabel(\"Количество\")\n",
        "plt.show()\n",
        "\n",
        "# Визуализируем относительные частоты\n",
        "plt.bar(relative_frequency.keys(), relative_frequency.values())\n",
        "plt.title(\"Относительные частоты\")\n",
        "plt.xlabel(\"Оценка\")\n",
        "plt.ylabel(\"Доля\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Частоты: {frequency}\")\n",
        "print(f\"Относительные частоты: {relative_frequency}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `Counter(data)` — подсчитывает частоты каждого значения.\n",
        "2. `{key: value / total_count}` — вычисляет относительные частоты.\n",
        "3. `matplotlib.pyplot.bar()` — строит столбчатые диаграммы для частот и относительных частот.\n",
        "\n",
        "\n",
        "\n",
        "### **3. Среднее Значение**\n",
        "\n",
        "Среднее значение (или среднее арифметическое) — это мера центральной тенденции, которая показывает \"центр\" данных. Оно вычисляется как сумма всех значений, деленная на их количество.\n",
        "\n",
        "#### Формула:\n",
        "$$\n",
        "\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\n",
        "$$\n",
        "\n",
        "#### Объяснение формулы:\n",
        "- $\\sum$ — это символ, который означает \"сумма\". Он говорит нам сложить все значения $x_i$.\n",
        "- $x_i$ — это каждое значение в данных.\n",
        "- $n$ — это общее количество значений.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы хотите узнать среднюю температуру за неделю. Для этого вы берёте температуры за каждый день, складываете их и делите на количество дней.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "# Создаем список данных (температуры за неделю)\n",
        "data = [20, 22, 19, 23, 21, 20, 22]\n",
        "\n",
        "# Вычисляем среднее значение\n",
        "mean_value = sum(data) / len(data)\n",
        "\n",
        "# Визуализируем данные и среднее значение\n",
        "plt.plot(data, label=\"Температуры\", marker='o')\n",
        "plt.axhline(mean_value, color='r', linestyle='--', label=\"Среднее значение\")\n",
        "plt.title(\"Температуры за неделю\")\n",
        "plt.xlabel(\"День\")\n",
        "plt.ylabel(\"Температура\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Среднее значение: {mean_value}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `sum(data)` — считает сумму всех значений.\n",
        "2. `len(data)` — считает количество значений.\n",
        "3. `axhline()` — рисует горизонтальную линию для среднего значения.\n",
        "\n",
        "\n",
        "\n",
        "### **4. Выборочная Дисперсия**\n",
        "\n",
        "Дисперсия измеряет, насколько значения в наборе данных отклоняются от их среднего значения. Чем больше дисперсия, тем больше разброс данных.\n",
        "\n",
        "#### Формула:\n",
        "$$\n",
        "Var(x) = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2\n",
        "$$\n",
        "\n",
        "#### Объяснение формулы:\n",
        "- $(x_i - \\bar{x})$ — это отклонение каждого значения от среднего.\n",
        "- $(x_i - \\bar{x})^2$ — это квадрат отклонения (мы используем квадрат, чтобы исключить отрицательные значения).\n",
        "- $\\sum$ — это сумма всех квадратов отклонений.\n",
        "- $\\frac{1}{n}$ — это нормировка, чтобы получить среднее значение квадратов отклонений.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете результаты тестов студентов. Дисперсия покажет, насколько результаты различаются от среднего балла.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "# Создаем список данных (результаты тестов)\n",
        "data = [80, 85, 90, 95, 100]\n",
        "\n",
        "# Вычисляем среднее значение\n",
        "mean_value = sum(data) / len(data)\n",
        "\n",
        "# Вычисляем дисперсию\n",
        "variance = sum((x - mean_value) ** 2 for x in data) / len(data)\n",
        "\n",
        "# Визуализируем данные и отклонения от среднего\n",
        "plt.plot(data, label=\"Результаты\", marker='o')\n",
        "plt.axhline(mean_value, color='r', linestyle='--', label=\"Среднее значение\")\n",
        "plt.title(\"Результаты тестов\")\n",
        "plt.xlabel(\"Студент\")\n",
        "plt.ylabel(\"Балл\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Дисперсия: {variance}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `(x - mean_value) ** 2` — вычисляет квадрат отклонения каждого значения.\n",
        "2. `sum(...)` — считает сумму квадратов отклонений.\n",
        "3. `/ len(data)` — нормирует сумму, чтобы получить среднее значение.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **5. Выборочная Ковариация**\n",
        "\n",
        "Ковариация — это мера, которая показывает, как две переменные связаны между собой. Если значения одной переменной увеличиваются вместе с другой, то ковариация будет положительной. Если одна переменная увеличивается, а другая уменьшается, то ковариация будет отрицательной.\n",
        "\n",
        "#### Формула:\n",
        "$$\n",
        "Cov(x, y) = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})\n",
        "$$\n",
        "\n",
        "#### Объяснение формулы:\n",
        "- $(x_i - \\bar{x})$ — отклонение $x_i$ от среднего значения $\\bar{x}$.\n",
        "- $(y_i - \\bar{y})$ — отклонение $y_i$ от среднего значения $\\bar{y}$.\n",
        "- Произведение этих отклонений показывает, насколько изменения в $x$ связаны с изменениями в $y$.\n",
        "- Сумма всех произведений делится на количество наблюдений ($n$).\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете связь между количеством часов, проведённых за учёбой, и оценками студентов. Положительная ковариация покажет, что чем больше времени студенты проводят за учёбой, тем выше их оценки.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Создаем два набора данных\n",
        "hours_studied = [2, 4, 6, 8, 10]  # Часы, проведённые за учёбой\n",
        "grades = [50, 60, 70, 80, 90]     # Оценки студентов\n",
        "\n",
        "# Вычисляем средние значения\n",
        "mean_x = sum(hours_studied) / len(hours_studied)\n",
        "mean_y = sum(grades) / len(grades)\n",
        "\n",
        "# Вычисляем ковариацию\n",
        "covariance = sum((x - mean_x) * (y - mean_y) for x, y in zip(hours_studied, grades)) / len(hours_studied)\n",
        "\n",
        "# Визуализируем данные\n",
        "plt.scatter(hours_studied, grades)\n",
        "plt.title(\"Связь между часами учёбы и оценками\")\n",
        "plt.xlabel(\"Часы учёбы\")\n",
        "plt.ylabel(\"Оценки\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Ковариация: {covariance}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `zip(hours_studied, grades)` — объединяет два списка для параллельной обработки.\n",
        "2. `(x - mean_x) * (y - mean_y)` — вычисляет произведение отклонений для каждой пары значений.\n",
        "3. `scatter()` — строит точечную диаграмму для визуализации связи.\n",
        "\n",
        "\n",
        "\n",
        "### **6. Коэффициент Корреляции**\n",
        "\n",
        "Коэффициент корреляции — это нормированная мера связи между двумя переменными. Он показывает не только направление связи (прямая или обратная), но и её силу.\n",
        "\n",
        "#### Формула:\n",
        "$$\n",
        "\\rho(x, y) = \\frac{Cov(x, y)}{\\sqrt{Var(x) Var(y)}}\n",
        "$$\n",
        "\n",
        "#### Диапазон значений:\n",
        "- $-1 \\leq \\rho(x, y) \\leq 1$:\n",
        "  - $\\rho = 1$: сильная прямая связь.\n",
        "  - $\\rho = -1$: сильная обратная связь.\n",
        "  - $\\rho = 0$: отсутствие линейной связи.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы хотите понять, насколько сильно связаны доходы сотрудников с их стажем работы. Коэффициент корреляции поможет определить, есть ли между ними линейная зависимость.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Создаем два набора данных\n",
        "experience = [1, 2, 3, 4, 5]  # Стаж работы (в годах)\n",
        "income = [50000, 60000, 70000, 80000, 90000]  # Доходы\n",
        "\n",
        "# Вычисляем коэффициент корреляции\n",
        "correlation = np.corrcoef(experience, income)[0, 1]\n",
        "\n",
        "# Визуализируем данные\n",
        "plt.scatter(experience, income)\n",
        "plt.title(\"Связь между стажем и доходами\")\n",
        "plt.xlabel(\"Стаж работы (лет)\")\n",
        "plt.ylabel(\"Доходы\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Коэффициент корреляции: {correlation}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `np.corrcoef()` — вычисляет матрицу корреляций для двух переменных.\n",
        "2. `[0, 1]` — выбирает значение корреляции между первой и второй переменными.\n",
        "3. `scatter()` — строит точечную диаграмму для визуализации связи.\n",
        "\n",
        "\n",
        "\n",
        "### **7. Квантили и Процентили**\n",
        "\n",
        "Квантили делят выборку на равные части. Они помогают понять, как распределены данные внутри выборки.\n",
        "\n",
        "#### Основные типы квантилей:\n",
        "- **Медиана** (50-й процентиль): значение, которое делит выборку на две равные части.\n",
        "- **Квартили**: делят выборку на четыре части (25%, 50%, 75%).\n",
        "- **Децили**: делят выборку на десять частей.\n",
        "- **Перцентили**: делят выборку на сто частей.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете зарплаты сотрудников компании. Медиана покажет, какой доход получает \"типичный\" сотрудник, а квартили помогут понять, как распределены зарплаты среди нижних и верхних 25%.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Создаем список данных (зарплаты сотрудников)\n",
        "salaries = [30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000]\n",
        "\n",
        "# Вычисляем медиану, квартили и перцентили\n",
        "median = np.median(salaries)\n",
        "q1 = np.percentile(salaries, 25)  # Первый квартиль\n",
        "q3 = np.percentile(salaries, 75)  # Третий квартиль\n",
        "p10 = np.percentile(salaries, 10)  # 10-й перцентиль\n",
        "p90 = np.percentile(salaries, 90)  # 90-й перцентиль\n",
        "\n",
        "# Визуализируем данные\n",
        "plt.boxplot(salaries, vert=False)\n",
        "plt.title(\"Распределение зарплат\")\n",
        "plt.xlabel(\"Зарплата\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Медиана: {median}\")\n",
        "print(f\"Первый квартиль (Q1): {q1}\")\n",
        "print(f\"Третий квартиль (Q3): {q3}\")\n",
        "print(f\"10-й перцентиль: {p10}\")\n",
        "print(f\"90-й перцентиль: {p90}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `np.median()` — вычисляет медиану.\n",
        "2. `np.percentile()` — вычисляет указанный перцентиль.\n",
        "3. `boxplot()` — строит диаграмму размаха для визуализации распределения данных.\n",
        "\n",
        "\n",
        "\n",
        "### **8. Мода**\n",
        "\n",
        "Мода — это значение, которое встречается в выборке наиболее часто. Для дискретных данных это значение с наибольшей частотой. Для непрерывных данных мода соответствует максимуму плотности распределения.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете предпочтения клиентов в кафе. Мода покажет, какой напиток самый популярный.\n",
        "\n",
        "#### Реализация в Python:\n",
        "```python\n",
        "from collections import Counter\n",
        "\n",
        "# Создаем список данных (напитки, выбранные клиентами)\n",
        "drinks = ['кофе', 'чай', 'кофе', 'кофе', 'чай', 'кофе', 'сок']\n",
        "\n",
        "# Находим моду\n",
        "frequency = Counter(drinks)\n",
        "mode = frequency.most_common(1)[0][0]\n",
        "\n",
        "print(f\"Мода: {mode}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `Counter(drinks)` — подсчитывает частоты каждого значения.\n",
        "2. `most_common(1)` — находит самое частое значение.\n",
        "3. `[0][0]` — выбирает само значение моды.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **9. Асимметрия**\n",
        "\n",
        "Асимметрия — это мера, которая показывает, насколько распределение данных отклоняется от симметрии. Если данные сконцентрированы больше справа, то распределение называется правосторонне асимметричным. Если данные сконцентрированы больше слева, то распределение называется левосторонне асимметричным.\n",
        "\n",
        "#### Формула:\n",
        "$$\n",
        "\\text{Асимметрия} = \\frac{\\mathbb{E}[(X - \\mu)^3]}{\\sigma^3}\n",
        "$$\n",
        "\n",
        "#### Объяснение формулы:\n",
        "- $\\mathbb{E}[(X - \\mu)^3]$ — это среднее значение кубических отклонений от среднего ($\\mu$).\n",
        "- $\\sigma^3$ — это куб стандартного отклонения, который нормирует результат.\n",
        "- Если результат положительный, распределение имеет правостороннюю асимметрию. Если отрицательный — левостороннюю.\n",
        "\n",
        "#### Интерпретация:\n",
        "- $ \\text{Асимметрия} > 0$: правосторонняя асимметрия (длинный \"хвост\" справа).\n",
        "- $ \\text{Асимметрия} < 0$: левосторонняя асимметрия (длинный \"хвост\" слева).\n",
        "- $ \\text{Асимметрия} = 0$: симметричное распределение.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете доходы людей в городе. Если большинство людей имеют небольшой доход, но есть несколько человек с очень высокими доходами, то распределение будет правосторонне асимметричным.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew\n",
        "\n",
        "# Создаем выборку данных (доходы людей)\n",
        "incomes = [20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 500000]\n",
        "\n",
        "# Вычисляем асимметрию\n",
        "asymmetry = skew(incomes)\n",
        "\n",
        "# Визуализируем распределение\n",
        "plt.hist(incomes, bins=10, edgecolor='black')\n",
        "plt.title(\"Распределение доходов\")\n",
        "plt.xlabel(\"Доход\")\n",
        "plt.ylabel(\"Частота\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Асимметрия: {asymmetry}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `skew()` из библиотеки `scipy.stats` вычисляет асимметрию.\n",
        "2. `hist()` строит гистограмму для визуализации распределения данных.\n",
        "\n",
        "\n",
        "\n",
        "### **10. Эксцесс (Островершинность)**\n",
        "\n",
        "Эксцесс (или островершинность) — это мера, которая показывает, насколько \"острый\" или \"плоский\" пик у распределения. Это позволяет сравнивать форму распределения с нормальным распределением.\n",
        "\n",
        "#### Формула:\n",
        "$$\n",
        "\\text{Эксцесс} = \\frac{\\mathbb{E}[(X - \\mu)^4]}{\\sigma^4} - 3\n",
        "$$\n",
        "\n",
        "#### Объяснение формулы:\n",
        "- $\\mathbb{E}[(X - \\mu)^4]$ — это среднее значение четвертых степеней отклонений от среднего ($\\mu$).\n",
        "- $\\sigma^4$ — это четвертая степень стандартного отклонения, которая нормирует результат.\n",
        "- Минус 3 используется, чтобы нормальное распределение имело эксцесс равный нулю.\n",
        "\n",
        "#### Интерпретация:\n",
        "- $\\text{Эксцесс} > 0$: островершинное распределение (пик выше, чем у нормального распределения).\n",
        "- $\\text{Эксцесс} < 0$: плосковершинное распределение (пик ниже, чем у нормального распределения).\n",
        "- $\\text{Эксцесс} = 0$: нормальное распределение.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете оценки студентов на экзамене. Если большинство студентов получили баллы близкие к среднему значению, а крайние значения редки, то распределение будет островершинным.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "from scipy.stats import kurtosis\n",
        "\n",
        "# Создаем выборку данных (оценки студентов)\n",
        "grades = [4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 9]\n",
        "\n",
        "# Вычисляем эксцесс\n",
        "kurt = kurtosis(grades, fisher=True)  # fisher=True делает корректировку для нормального распределения\n",
        "\n",
        "# Визуализируем распределение\n",
        "plt.hist(grades, bins=10, edgecolor='black')\n",
        "plt.title(\"Распределение оценок\")\n",
        "plt.xlabel(\"Оценка\")\n",
        "plt.ylabel(\"Частота\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Эксцесс: {kurt}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `kurtosis()` из библиотеки `scipy.stats` вычисляет эксцесс.\n",
        "2. `fisher=True` делает корректировку так, чтобы нормальное распределение имело эксцесс равный нулю.\n",
        "3. `hist()` строит гистограмму для визуализации распределения данных.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Вопросы для самопроверки:\n",
        "\n",
        "1. Что такое дескриптивная (описательная) статистика?\n",
        "2. Какие основные характеристики данных изучаются в описательной статистике?\n",
        "3. Что такое вариационный ряд? Для чего он используется?\n",
        "4. Как найти минимальное и максимальное значения в наборе данных?\n",
        "5. Что такое размах выборки? Как его вычислить?\n",
        "6. Что такое частота? Приведите пример.\n",
        "7. Что такое относительная частота? Как она вычисляется?\n",
        "8. Что показывает среднее значение (среднее арифметическое)?\n",
        "9. Какова формула для вычисления среднего значения?\n",
        "10. Что измеряет выборочная дисперсия?\n",
        "11. Какова формула для вычисления выборочной дисперсии?\n",
        "12. Что такое ковариация? Для чего она используется?\n",
        "13. Какова формула для вычисления ковариации между двумя переменными?\n",
        "14. Что показывает коэффициент корреляции?\n",
        "15. Каков диапазон значений коэффициента корреляции?\n",
        "16. Что такое медиана? Как её вычислить?\n",
        "17. Что такое квартили? Как они помогают анализировать данные?\n",
        "18. Что такое децили? Приведите пример их использования.\n",
        "19. Что такое перцентили? Как они применяются в анализе данных?\n",
        "20. Что такое мода? Как её найти?\n",
        "21. Что такое асимметрия? Как её интерпретировать?\n",
        "22. Какова формула для вычисления асимметрии?\n",
        "23. Что такое эксцесс (островершинность)? Как он описывает распределение данных?\n",
        "24. Какова формула для вычисления эксцесса?\n",
        "25. Как можно интерпретировать положительный эксцесс?\n",
        "26. Как можно интерпретировать отрицательный эксцесс?\n",
        "27. Какие инструменты Python используются для анализа данных в описательной статистике?\n",
        "28. Как визуализировать вариационный ряд с помощью Python?\n",
        "29. Как построить график частот и относительных частот с помощью Python?\n",
        "30. Как использовать Python для вычисления основных характеристик данных, таких как среднее, дисперсия, корреляция?\n",
        "\n",
        "\n",
        "\n",
        "### Задачи для самостоятельной работы:\n",
        "\n",
        "1. **Вариационный ряд:** Дан набор данных: [15, 20, 10, 25, 30]. Постройте вариационный ряд и найдите минимальное и максимальное значения.\n",
        "2. **Размах выборки:** Используя данные из задачи 1, вычислите размах выборки.\n",
        "3. **Частоты:** Даны оценки студентов: [4, 5, 5, 3, 4, 5, 4, 3, 2, 4]. Найдите частоту каждой оценки.\n",
        "4. **Относительные частоты:** Используя данные из задачи 3, вычислите относительные частоты.\n",
        "5. **Среднее значение:** Вычислите среднюю температуру за неделю, если данные таковы: [20, 22, 19, 23, 21, 20, 22].\n",
        "6. **Выборочная дисперсия:** Даны результаты тестов: [80, 85, 90, 95, 100]. Вычислите выборочную дисперсию.\n",
        "7. **Ковариация:** Даны два набора данных: часы учёбы [2, 4, 6, 8, 10] и оценки [50, 60, 70, 80, 90]. Вычислите ковариацию между ними.\n",
        "8. **Коэффициент корреляции:** Используя данные из задачи 7, вычислите коэффициент корреляции между часами учёбы и оценками.\n",
        "9. **Медиана:** Найдите медиану следующего набора данных: [30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000].\n",
        "10. **Квартили:** Для данных из задачи 9 найдите первый и третий квартили.\n",
        "11. **Перцентили:** Найдите 10-й и 90-й перцентили для данных из задачи 9.\n",
        "12. **Мода:** Дан список напитков, выбранных клиентами: ['кофе', 'чай', 'кофе', 'кофе', 'чай', 'кофе', 'сок']. Найдите моду.\n",
        "13. **Асимметрия:** Даны доходы людей: [20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 500000]. Вычислите асимметрию.\n",
        "14. **Эксцесс:** Даны оценки студентов: [4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 9]. Вычислите эксцесс.\n",
        "15. **График вариационного ряда:** Постройте график вариационного ряда для данных из задачи 1.\n",
        "16. **Гистограмма частот:** Постройте гистограмму частот для данных из задачи 3.\n",
        "17. **Гистограмма относительных частот:** Постройте гистограмму относительных частот для данных из задачи 4.\n",
        "18. **Линейный график среднего значения:** Постройте линейный график для данных из задачи 5 с отметкой среднего значения.\n",
        "19. **График дисперсии:** Постройте график для данных из задачи 6 с отметкой дисперсии.\n",
        "20. **Точечная диаграмма ковариации:** Постройте точечную диаграмму для данных из задачи 7.\n",
        "21. **Точечная диаграмма корреляции:** Постройте точечную диаграмму для данных из задачи 8.\n",
        "22. **Диаграмма размаха:** Постройте диаграмму размаха для данных из задачи 9.\n",
        "23. **Гистограмма асимметрии:** Постройте гистограмму для данных из задачи 13 и проинтерпретируйте асимметрию.\n",
        "24. **Гистограмма эксцесса:** Постройте гистограмму для данных из задачи 14 и проинтерпретируйте эксцесс.\n",
        "25. **Сравнение двух выборок:** Даны две выборки: A = [10, 20, 30, 40, 50] и B = [5, 15, 25, 35, 45]. Сравните их средние значения, дисперсии и моды.\n",
        "26. **Зависимость между переменными:** Исследуйте зависимость между двумя переменными X = [1, 2, 3, 4, 5] и Y = [2, 4, 6, 8, 10]. Найдите ковариацию и коэффициент корреляции.\n",
        "27. **Анализ реальных данных:** Скачайте набор данных о зарплатах сотрудников компании и найдите основные статистические характеристики (минимум, максимум, среднее, дисперсию, медиану, квартили).\n",
        "28. **Визуализация реальных данных:** Постройте графики для данных из задачи 27 (гистограммы, диаграммы размаха, точечные диаграммы).\n",
        "29. **Анализ асимметрии реальных данных:** Исследуйте асимметрию распределения доходов в крупном городе.\n",
        "30. **Анализ эксцесса реальных данных:** Исследуйте эксцесс распределения оценок студентов на экзамене.\n"
      ],
      "metadata": {
        "id": "qwjp7QDc1DnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **5. Случайные Величины и Их Распределения**\n",
        "\n",
        "Случайные величины — это математический инструмент, который позволяет описать неопределённость в данных. Они широко используются в статистике, машинном обучении, экономике и других областях. В этом разделе мы рассмотрим основные понятия случайных величин, функции распределения и дискретные случайные величины.\n",
        "\n",
        "\n",
        "\n",
        "### **1. Случайная Величина**\n",
        "\n",
        "Случайная величина — это правило (функция), которое связывает каждое возможное событие из пространства элементарных событий $\\Omega$ с числовым значением на оси действительных чисел $\\mathbb{R}$.\n",
        "\n",
        "#### Формальное определение:\n",
        "Пусть $\\Omega$ — это множество всех возможных исходов эксперимента (пространство элементарных событий). Случайная величина $\\xi$ — это функция, которая отображает каждый элемент $\\omega \\in \\Omega$ в число $x \\in \\mathbb{R}$.\n",
        "\n",
        "Например:\n",
        "- Если мы бросаем игральную кость, то множество возможных исходов $\\Omega = \\{1, 2, 3, 4, 5, 6\\}$.\n",
        "- Мы можем определить случайную величину $\\xi$, которая равна количеству выпавших очков: $\\xi(\\omega) = \\omega$.\n",
        "\n",
        "Таким образом, случайная величина переводит каждый исход эксперимента в конкретное число.\n",
        "\n",
        "\n",
        "### **2. Функция Распределения**\n",
        "\n",
        "Функция распределения $F_\\xi(x)$ описывает вероятность того, что случайная величина $\\xi$ примет значение, меньшее или равное $x$.\n",
        "\n",
        "#### Формальное определение:\n",
        "$$\n",
        "F_\\xi(x) = P\\{\\xi \\leq x\\}\n",
        "$$\n",
        "\n",
        "#### Свойства функции распределения:\n",
        "1. **Неубывающая функция**: Если $x_1 < x_2$, то $F_\\xi(x_1) \\leq F_\\xi(x_2)$.\n",
        "2. **Границы**:  \n",
        "   - $F_\\xi(-\\infty) = 0$: вероятность того, что $\\xi$ меньше любого числа, равна нулю.\n",
        "   - $F_\\xi(+\\infty) = 1$: вероятность того, что $\\xi$ меньше бесконечности, равна единице.\n",
        "3. **Непрерывность справа**: Значение функции в точке $x$ равно пределу функции при приближении к $x$ справа.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете время ожидания автобуса. Функция распределения покажет вероятность того, что автобус приедет через $x$ минут или раньше.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Создаем значения для функции распределения нормального закона\n",
        "x = np.linspace(-3, 3, 100)\n",
        "cdf = norm.cdf(x)  # Функция распределения стандартного нормального закона\n",
        "\n",
        "# Визуализируем функцию распределения\n",
        "plt.plot(x, cdf, label=\"Функция распределения\")\n",
        "plt.title(\"Функция распределения нормального закона\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"F(x)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `norm.cdf(x)` вычисляет значения функции распределения стандартного нормального закона.\n",
        "2. `plot()` строит график функции распределения.\n",
        "\n",
        "\n",
        "\n",
        "### **3. Дискретные Случайные Величины**\n",
        "\n",
        "Дискретные случайные величины принимают значения из конечного или счетного множества. Вероятность каждого значения задается вероятностной функцией $P(\\xi = x_i)$.\n",
        "\n",
        "#### Основные свойства:\n",
        "- Сумма вероятностей всех возможных значений равна 1:  \n",
        "  $$\n",
        "  \\sum_{i} P(\\xi = x_i) = 1\n",
        "  $$\n",
        "\n",
        "#### Примеры распределений:\n",
        "\n",
        "##### **Биномиальное распределение**\n",
        "Биномиальное распределение описывает количество успехов в $n$ независимых испытаниях с фиксированной вероятностью успеха $p$.\n",
        "\n",
        "- **Формула**:  \n",
        "  $$\n",
        "  P(\\xi = k) = C_n^k p^k (1-p)^{n-k}, \\quad k = 0, 1, \\dots, n\n",
        "  $$\n",
        "- **Пример из реальной жизни**: Вероятность того, что из 10 бросков монеты выпадет \"орёл\" ровно 7 раз.\n",
        "\n",
        "##### **Пуассоновское распределение**\n",
        "Пуассоновское распределение описывает количество событий, происходящих за определённый промежуток времени или пространства, если среднее количество событий равно $\\lambda$.\n",
        "\n",
        "- **Формула**:  \n",
        "  $$\n",
        "  P(\\xi = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}, \\quad k = 0, 1, 2, \\dots\n",
        "  $$\n",
        "- **Пример из реальной жизни**: Количество звонков в колл-центр за час.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "\n",
        "###### Биномиальное распределение:\n",
        "```python\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Параметры биномиального распределения\n",
        "n = 10  # Количество испытаний\n",
        "p = 0.5  # Вероятность успеха\n",
        "\n",
        "# Вычисляем вероятности\n",
        "k = np.arange(0, n + 1)\n",
        "pmf = binom.pmf(k, n, p)\n",
        "\n",
        "# Визуализируем распределение\n",
        "plt.bar(k, pmf, edgecolor='black')\n",
        "plt.title(\"Биномиальное распределение\")\n",
        "plt.xlabel(\"Количество успехов\")\n",
        "plt.ylabel(\"Вероятность\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "###### Пуассоновское распределение:\n",
        "```python\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# Параметр пуассоновского распределения\n",
        "lambda_ = 5  # Среднее количество событий\n",
        "\n",
        "# Вычисляем вероятности\n",
        "k = np.arange(0, 15)\n",
        "pmf = poisson.pmf(k, lambda_)\n",
        "\n",
        "# Визуализируем распределение\n",
        "plt.bar(k, pmf, edgecolor='black')\n",
        "plt.title(\"Пуассоновское распределение\")\n",
        "plt.xlabel(\"Количество событий\")\n",
        "plt.ylabel(\"Вероятность\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `binom.pmf()` и `poisson.pmf()` вычисляют вероятности для биномиального и пуассоновского распределений соответственно.\n",
        "2. `bar()` строит столбчатую диаграмму для визуализации распределений.\n",
        "\n",
        "\n",
        "### **4. Непрерывные Случайные Величины**\n",
        "\n",
        "Непрерывные случайные величины могут принимать любые значения из некоторого интервала вещественных чисел. Для их описания вместо вероятностной функции используется **плотность распределения** $f_\\xi(x)$, которая связана с функцией распределения следующим образом:\n",
        "$$\n",
        "F_\\xi(x) = \\int_{-\\infty}^x f_\\xi(t) dt.\n",
        "$$\n",
        "\n",
        "#### Пример: Нормальное Распределение\n",
        "\n",
        "Одним из самых распространённых примеров непрерывной случайной величины является нормальная (гауссова) случайная величина. Она характеризуется параметрами $\\mu$ (математическое ожидание) и $\\sigma$ (стандартное отклонение). Плотность распределения имеет вид:\n",
        "$$\n",
        "f_\\xi(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}.\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете рост людей в определённой популяции. Рост часто подчиняется нормальному распределению.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Параметры нормального распределения\n",
        "mu = 170  # Математическое ожидание (средний рост)\n",
        "sigma = 10  # Стандартное отклонение (разброс роста)\n",
        "\n",
        "# Генерируем значения\n",
        "x_values = np.linspace(mu - 4*sigma, mu + 4*sigma, 500)\n",
        "pdf_values = norm.pdf(x_values, loc=mu, scale=sigma)\n",
        "\n",
        "# Строим график плотности распределения\n",
        "plt.plot(x_values, pdf_values, label=f'N({mu}, {sigma})', color='blue')\n",
        "plt.fill_between(x_values, pdf_values, alpha=0.2, color='blue')  # Закрашиваем площадь под кривой\n",
        "plt.title('Нормальное распределение роста')\n",
        "plt.xlabel('Рост (см)')\n",
        "plt.ylabel('Плотность вероятности')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `norm.pdf()` вычисляет значения плотности нормального распределения.\n",
        "2. `fill_between()` закрашивает площадь под кривой для лучшей визуализации.\n",
        "\n",
        "\n",
        "\n",
        "### **5. Характеристики Случайных Величин**\n",
        "\n",
        "Чтобы лучше понять поведение случайной величины, используются её характеристики, такие как математическое ожидание и дисперсия.\n",
        "\n",
        "#### **Математическое Ожидание ($E[\\xi]$)**\n",
        "\n",
        "Математическое ожидание — это среднее значение случайной величины. Оно показывает \"центр\" распределения.\n",
        "\n",
        "- Для дискретной величины:\n",
        "$$\n",
        "E[\\xi] = \\sum_{i} x_i P(\\xi = x_i),\n",
        "$$\n",
        "где $x_i$ — возможные значения случайной величины, а $P(\\xi = x_i)$ — вероятности этих значений.\n",
        "\n",
        "- Для непрерывной величины:\n",
        "$$\n",
        "E[\\xi] = \\int_{-\\infty}^\\infty x f_\\xi(x) dx,\n",
        "$$\n",
        "где $f_\\xi(x)$ — плотность распределения.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы хотите найти средний доход сотрудников компании. Математическое ожидание поможет вам рассчитать этот показатель.\n",
        "\n",
        "#### Реализация в Python для дискретной случайной величины:\n",
        "```python\n",
        "# Создаем дискретную случайную величину (доходы сотрудников)\n",
        "incomes = [30000, 40000, 50000, 60000]\n",
        "probabilities = [0.1, 0.3, 0.4, 0.2]\n",
        "\n",
        "# Вычисляем математическое ожидание\n",
        "expected_value = sum(x * p for x, p in zip(incomes, probabilities))\n",
        "\n",
        "print(f\"Математическое ожидание: {expected_value}\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "#### **Дисперсия ($Var(\\xi)$)**\n",
        "\n",
        "Дисперсия измеряет степень разброса значений случайной величины относительно её математического ожидания:\n",
        "$$\n",
        "Var(\\xi) = E[(\\xi - E[\\xi])^2].\n",
        "$$\n",
        "\n",
        "Стандартное отклонение — это корень из дисперсии:\n",
        "$$\n",
        "\\sigma = \\sqrt{Var(\\xi)}.\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете доходы сотрудников. Дисперсия покажет, насколько сильно доходы различаются от среднего значения.\n",
        "\n",
        "#### Реализация в Python для дискретной случайной величины:\n",
        "```python\n",
        "# Вычисляем дисперсию\n",
        "mean = expected_value\n",
        "variance = sum((x - mean)**2 * p for x, p in zip(incomes, probabilities))\n",
        "std_deviation = variance**0.5\n",
        "\n",
        "print(f\"Дисперсия: {variance}\")\n",
        "print(f\"Стандартное отклонение: {std_deviation}\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### **6. Смешанные Случайные Величины**\n",
        "\n",
        "Смешанные случайные величины сочетают в себе дискретные и непрерывные компоненты. Например, время ожидания автобуса может быть смешанной случайной величиной, если автобус приходит через фиксированные промежутки времени, но с некоторой погрешностью.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Представьте, что автобус должен приходить каждые 15 минут, но фактическое время его прибытия может отличаться на несколько минут. В этом случае время ожидания автобуса можно представить как смешанную случайную величину:\n",
        "- Дискретная компонента: фиксированные моменты времени (например, 0, 15, 30 минут).\n",
        "- Непрерывная компонента: погрешность времени прибытия (например, нормально распределённая величина).\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Дискретная компонента: фиксированные моменты времени\n",
        "fixed_times = [0, 15, 30, 45, 60]\n",
        "\n",
        "# Непрерывная компонента: погрешность времени прибытия\n",
        "error_mean = 0  # Среднее значение погрешности\n",
        "error_std = 2   # Стандартное отклонение погрешности\n",
        "\n",
        "# Генерируем значения для непрерывной компоненты\n",
        "x_values = np.linspace(-5, 5, 500)\n",
        "pdf_values = norm.pdf(x_values, loc=error_mean, scale=error_std)\n",
        "\n",
        "# Строим график\n",
        "plt.bar(fixed_times, [0.2] * len(fixed_times), width=5, alpha=0.5, label=\"Дискретная компонента\")\n",
        "plt.plot(x_values + fixed_times[1], pdf_values * 0.1, label=\"Непрерывная компонента\", color='red')\n",
        "plt.title(\"Смешанная случайная величина: время ожидания автобуса\")\n",
        "plt.xlabel(\"Время (минуты)\")\n",
        "plt.ylabel(\"Плотность вероятности\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `bar()` строит столбчатую диаграмму для дискретной компоненты.\n",
        "2. `plot()` добавляет график плотности для непрерывной компоненты.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **7. Условное Распределение**\n",
        "\n",
        "Условное распределение описывает поведение одной случайной величины при условии, что другая приняла конкретное значение. Это позволяет анализировать зависимость между двумя случайными величинами.\n",
        "\n",
        "#### Формальное определение:\n",
        "Если $\\xi$ и $\\eta$ — две случайные величины, то условная вероятность $\\xi = x$ при условии, что $\\eta = y$, вычисляется по формуле:\n",
        "$$\n",
        "P(\\xi = x \\mid \\eta = y) = \\frac{P(\\xi = x \\text{ и } \\eta = y)}{P(\\eta = y)}.\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о покупках клиентов. Интересует вероятность того, что клиент купит товар A, если он уже купил товар B. Это пример использования условного распределения.\n",
        "\n",
        "#### Реализация в Python:\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Создаем выборку данных (покупки клиентов)\n",
        "data = [\n",
        "    ('A', 'B'),  # Клиент купил A и B\n",
        "    ('A', None), # Клиент купил только A\n",
        "    ('B', None), # Клиент купил только B\n",
        "    ('A', 'B'),  # Клиент купил A и B\n",
        "    (None, 'B')  # Клиент купил только B\n",
        "]\n",
        "\n",
        "# Подсчитываем совместные и условные вероятности\n",
        "total_B = sum(1 for _, b in data if b == 'B')  # Сколько раз купили B\n",
        "joint_AB = sum(1 for a, b in data if a == 'A' and b == 'B')  # Сколько раз купили A и B\n",
        "\n",
        "# Вычисляем условную вероятность P(A | B)\n",
        "conditional_prob = joint_AB / total_B if total_B > 0 else 0\n",
        "\n",
        "print(f\"Вероятность купить A при условии, что куплено B: {conditional_prob}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `data` — список пар покупок клиентов.\n",
        "2. `joint_AB` — количество случаев, когда клиент купил оба товара.\n",
        "3. `total_B` — общее количество покупок товара B.\n",
        "4. `conditional_prob` — условная вероятность $P(A \\mid B)$.\n",
        "\n",
        "\n",
        "### **8. Независимость Случайных Величин**\n",
        "\n",
        "Случайные величины $\\xi$ и $\\eta$ называются независимыми, если выполнено следующее условие:\n",
        "$$\n",
        "P(\\xi = x \\text{ и } \\eta = y) = P(\\xi = x) \\cdot P(\\eta = y).\n",
        "$$\n",
        "\n",
        "Это означает, что знание значения одной случайной величины не даёт информации о другой.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Представьте, что вы бросаете две монеты. Результат первой монеты ($\\xi$) не зависит от результата второй монеты ($\\eta$). Эти случайные величины являются независимыми.\n",
        "\n",
        "#### Проверка независимости на практике:\n",
        "Для проверки независимости можно использовать выборочные данные и сравнить совместные вероятности с произведением маргинальных вероятностей.\n",
        "\n",
        "#### Реализация в Python:\n",
        "```python\n",
        "from collections import Counter\n",
        "\n",
        "# Создаем выборку данных (результаты бросков двух монет)\n",
        "data = [\n",
        "    ('О', 'О'),  # Обе монеты показали \"орёл\"\n",
        "    ('О', 'Р'),  # Первая монета \"орёл\", вторая \"решка\"\n",
        "    ('Р', 'О'),  # Первая монета \"решка\", вторая \"орёл\"\n",
        "    ('Р', 'Р')   # Обе монеты показали \"решка\"\n",
        "]\n",
        "\n",
        "# Подсчитываем частоты\n",
        "counter = Counter(data)\n",
        "\n",
        "# Вычисляем вероятности\n",
        "total = len(data)\n",
        "prob_X_O = sum(1 for x, _ in data if x == 'О') / total  # Вероятность \"орёл\" для первой монеты\n",
        "prob_Y_O = sum(1 for _, y in data if y == 'О') / total  # Вероятность \"орёл\" для второй монеты\n",
        "joint_prob_OO = counter[('О', 'О')] / total            # Совместная вероятность \"орёл-орёл\"\n",
        "\n",
        "# Проверяем независимость\n",
        "independence_check = abs(joint_prob_OO - prob_X_O * prob_Y_O) < 1e-6\n",
        "\n",
        "print(f\"Вероятность 'О' для первой монеты: {prob_X_O}\")\n",
        "print(f\"Вероятность 'О' для второй монеты: {prob_Y_O}\")\n",
        "print(f\"Совместная вероятность 'О-О': {joint_prob_OO}\")\n",
        "print(f\"Являются ли монеты независимыми? {'Да' if independence_check else 'Нет'}\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `Counter(data)` — подсчитывает частоты всех возможных комбинаций результатов.\n",
        "2. `prob_X_O` и `prob_Y_O` — маргинальные вероятности для каждой монеты.\n",
        "3. `joint_prob_OO` — совместная вероятность \"орёл-орёл\".\n",
        "4. `independence_check` — проверяет, выполняется ли условие независимости.\n",
        "\n",
        "\n",
        "### **9. Распределения с Множественными Параметрами**\n",
        "\n",
        "Многие распределения зависят от нескольких параметров, которые контролируют их форму, масштаб или положение. Например:\n",
        "\n",
        "#### Пример: Гамма-распределение\n",
        "Гамма-распределение часто используется для моделирования времени ожидания или продолжительности событий. Оно зависит от двух параметров:\n",
        "- $k$ (параметр формы): определяет форму распределения.\n",
        "- $\\theta$ (параметр масштаба): определяет масштаб распределения.\n",
        "\n",
        "Формула плотности гамма-распределения:\n",
        "$$\n",
        "f_\\xi(x) = \\frac{x^{k-1} e^{-x/\\theta}}{\\theta^k \\Gamma(k)}, \\quad x > 0,\n",
        "$$\n",
        "где $\\Gamma(k)$ — это гамма-функция.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете время работы оборудования до отказа. Если время до отказа имеет гамма-распределение, то параметры $k$ и $\\theta$ помогут вам понять, как часто оборудование ломается и как долго оно работает в среднем.\n",
        "\n",
        "#### Реализация в Python с визуализацией:\n",
        "```python\n",
        "from scipy.stats import gamma\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Параметры гамма-распределения\n",
        "k = 2  # Параметр формы\n",
        "theta = 2  # Параметр масштаба\n",
        "\n",
        "# Генерируем значения\n",
        "x_values = np.linspace(0, 20, 500)\n",
        "pdf_values = gamma.pdf(x_values, a=k, scale=theta)\n",
        "\n",
        "# Строим график\n",
        "plt.plot(x_values, pdf_values, label=f'Gamma(k={k}, θ={theta})', color='blue')\n",
        "plt.fill_between(x_values, pdf_values, alpha=0.2, color='blue')  # Закрашиваем площадь под кривой\n",
        "plt.title('Гамма-распределение времени работы оборудования')\n",
        "plt.xlabel('Время работы (часы)')\n",
        "plt.ylabel('Плотность вероятности')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `gamma.pdf()` вычисляет значения плотности гамма-распределения.\n",
        "2. `fill_between()` закрашивает площадь под кривой для лучшей визуализации.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **Вопросы для самопроверки**\n",
        "\n",
        "1. Что такое случайная величина? Приведите пример.\n",
        "2. Как определяется функция распределения случайной величины? Какие у неё свойства?\n",
        "3. В чём разница между дискретной и непрерывной случайной величиной?\n",
        "4. Что такое плотность распределения? Как она связана с функцией распределения?\n",
        "5. Приведите пример биномиального распределения. Какие параметры его определяют?\n",
        "6. Что описывает пуассоновское распределение? В каких задачах оно применяется?\n",
        "7. Как вычисляется математическое ожидание для дискретной и непрерывной случайной величины?\n",
        "8. Что такое дисперсия случайной величины? Как она связана со стандартным отклонением?\n",
        "9. Какие свойства имеет нормальное распределение? Какие параметры его определяют?\n",
        "10. Что такое смешанная случайная величина? Приведите пример.\n",
        "11. Как определяется условное распределение? В каких задачах оно используется?\n",
        "12. Что означает независимость случайных величин? Как её проверить на практике?\n",
        "13. Какие параметры определяют гамма-распределение? В каких задачах оно применяется?\n",
        "14. Как визуализировать функцию распределения в Python?\n",
        "15. Как построить график плотности вероятности для нормального распределения?\n",
        "16. Как вычислить математическое ожидание и дисперсию для дискретной случайной величины в Python?\n",
        "17. Как проверить независимость двух случайных величин на практике?\n",
        "18. Что такое маргинальные вероятности? Как они связаны с совместными вероятностями?\n",
        "19. Как визуализировать биномиальное распределение в Python?\n",
        "20. Как визуализировать пуассоновское распределение в Python?\n",
        "21. Что такое стандартное отклонение? Как оно связано с дисперсией?\n",
        "22. Как вычислить условную вероятность в Python?\n",
        "23. Какие свойства имеет функция распределения?\n",
        "24. Как определить, является ли случайная величина дискретной или непрерывной?\n",
        "25. Что такое гамма-функция? Как она используется в гамма-распределении?\n",
        "26. Как визуализировать смешанную случайную величину в Python?\n",
        "27. Какие примеры из реальной жизни можно описать с помощью нормального распределения?\n",
        "28. Как вычислить вероятность для биномиального распределения в Python?\n",
        "29. Как вычислить вероятность для пуассоновского распределения в Python?\n",
        "30. Какие задачи можно решить с помощью условного распределения?\n",
        "\n",
        "\n",
        "### Задачи для самостоятельной работы:\n",
        "\n",
        "1. Задана случайная величина $\\xi$, принимающая значения 1, 2, 3 с вероятностями 0.2, 0.5, 0.3 соответственно. Найдите математическое ожидание и дисперсию.\n",
        "\n",
        "2. Постройте функцию распределения для случайной величины, принимающей значения 1, 2, 3 с вероятностями 0.2, 0.5, 0.3.\n",
        "\n",
        "3. Вероятность успеха в одном испытании равна 0.6. Найдите вероятность того, что в 10 испытаниях будет ровно 5 успехов.\n",
        "\n",
        "4. Среднее количество событий за час равно 3. Найдите вероятность того, что за час произойдёт ровно 2 события.\n",
        "\n",
        "5. Случайная величина $\\xi$ имеет нормальное распределение с параметрами $\\mu = 10$, $\\sigma = 2$. Найдите вероятность того, что $\\xi$ примет значение от 8 до 12.\n",
        "\n",
        "6. Найдите математическое ожидание случайной величины $\\xi$, заданной плотностью распределения $f_\\xi(x) = 2x$ на интервале $[0, 1]$.\n",
        "\n",
        "7. Найдите дисперсию случайной величины, заданной плотностью распределения $f_\\xi(x) = 2x$ на интервале $[0, 1]$.\n",
        "\n",
        "8. Автобус приходит каждые 15 минут, но время его прибытия может отличаться на ±2 минуты. Опишите эту ситуацию как смешанную случайную величину.\n",
        "\n",
        "9. В магазине 30% покупателей покупают товар A, а 20% покупают товар B. Из тех, кто купил товар B, 50% также купили товар A. Найдите вероятность того, что случайный покупатель купит товар A, если он купил товар B.\n",
        "\n",
        "10. Проверьте, являются ли независимыми случайные величины $\\xi$ и $\\eta$, если их совместное распределение задано таблицей:\n",
        "    |   | $\\eta=1$ | $\\eta=2$ |\n",
        "    |---|----------|----------|\n",
        "    | $\\xi=1$ | 0.1      | 0.2      |\n",
        "    | $\\xi=2$ | 0.3      | 0.4      |\n",
        "\n",
        "11. Случайная величина $\\xi$ имеет гамма-распределение с параметрами $k=3$, $\\theta=2$. Найдите вероятность того, что $\\xi$ примет значение больше 4.\n",
        "\n",
        "12. Постройте график функции распределения для нормального распределения с параметрами $\\mu=0$, $\\sigma=1$.\n",
        "\n",
        "13. Постройте график плотности вероятности для биномиального распределения с параметрами $n=10$, $p=0.5$.\n",
        "\n",
        "14. Вычислите математическое ожидание для случайной величины, заданной списком значений и их вероятностей: `values = [1, 2, 3]`, `probabilities = [0.2, 0.5, 0.3]`.\n",
        "\n",
        "15. Вычислите дисперсию для случайной величины, заданной списком значений и их вероятностей: `values = [1, 2, 3]`, `probabilities = [0.2, 0.5, 0.3]`.\n",
        "\n",
        "16. В выборке из 100 клиентов 30 купили товар A, 20 купили товар B, а 10 купили оба товара. Найдите вероятность того, что клиент купил товар A, если он купил товар B.\n",
        "\n",
        "17. Проверьте независимость случайных величин $\\xi$ и $\\eta$, если их совместное распределение задано таблицей:\n",
        "\n",
        "|   | $\\eta=1$ | $\\eta=2$ |\n",
        "|---|----------|----------|\n",
        "| $\\xi=1$ | 0.2      | 0.3      |\n",
        "| $\\xi=2$ | 0.3      | 0.2      |\n",
        "\n",
        "18. Постройте график плотности вероятности для гамма-распределения с параметрами $k=2$, $\\theta=3$.\n",
        "\n",
        "19. Смоделируйте смешанную случайную величину, где дискретная компонента принимает значения 0, 15, 30, а непрерывная компонента — нормальное распределение с $\\mu=0$, $\\sigma=2$.\n",
        "\n",
        "20. Найдите вероятность того, что случайная величина с нормальным распределением $N(5, 2)$ примет значение от 4 до 6.\n",
        "\n",
        "21. Найдите вероятность того, что в 20 испытаниях с вероятностью успеха 0.4 будет ровно 8 успехов.\n",
        "\n",
        "22. Найдите вероятность того, что за час произойдёт не более 3 событий, если среднее количество событий за час равно 2.\n",
        "\n",
        "23. Постройте график функции распределения для экспоненциального распределения с параметром $\\lambda=0.5$.\n",
        "\n",
        "24. Постройте график плотности вероятности для равномерного распределения на интервале $[0, 10]$.\n",
        "\n",
        "25. Вычислите математическое ожидание для случайной величины, заданной плотностью распределения $f_\\xi(x) = 3x^2$ на интервале $[0, 1]$.\n",
        "\n",
        "26. Вычислите дисперсию для случайной величины, заданной плотностью распределения $f_\\xi(x) = 3x^2$ на интервале $[0, 1]$.\n",
        "\n",
        "27. В выборке из 200 клиентов 50 купили товар A, 40 купили товар B, а 20 купили оба товара. Найдите вероятность того, что клиент купил товар A, если он купил товар B.\n",
        "\n",
        "28. Проверьте независимость случайных величин $\\xi$ и $\\eta$, если их совместное распределение задано таблицей:\n",
        "\n",
        "|   | $\\eta=1$ | $\\eta=2$ |\n",
        "|---|----------|----------|\n",
        "| $\\xi=1$ | 0.1      | 0.4      |\n",
        "| $\\xi=2$ | 0.2      | 0.3      |\n",
        "\n",
        "29. Найдите вероятность того, что случайная величина с гамма-распределением $k=4$, $\\theta=1$ примет значение больше 3.\n",
        "\n",
        "30. Смоделируйте смешанную случайную величину, где дискретная компонента принимает значения 10, 20, 30, а непрерывная компонента — нормальное распределение с $\\mu=0$, $\\sigma=1$.\n"
      ],
      "metadata": {
        "id": "G6K11Kf8nQak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **6. Практика Точечного Оценивания на Python**\n",
        "\n",
        "Точечное оценивание — это важная часть прикладной статистики, которая позволяет находить числовые значения параметров распределений на основе выборки данных. В этой главе мы рассмотрим основные методы точечного оценивания, научимся реализовывать их на Python и сравнивать результаты. Мы будем использовать Google Colab для выполнения практических примеров, чтобы каждый читатель мог легко повторить все шаги.\n",
        "\n",
        "\n",
        "## **1. Метод Максимального Правдоподобия (ММП)**\n",
        "\n",
        "### **Теоретические основы**\n",
        "Метод максимального правдоподобия (ММП) — это один из самых популярных способов оценки параметров распределения. Идея заключается в том, чтобы найти такие значения параметров, при которых наблюдаемая выборка становится наиболее вероятной.\n",
        "\n",
        "#### Формула правдоподобия:\n",
        "Если $ X_1, X_2, \\dots, X_n $ — независимые случайные величины с плотностью вероятности $ f(x; \\theta) $, где $ \\theta $ — неизвестный параметр, то функция правдоподобия определяется как:\n",
        "$$\n",
        "L(\\theta) = \\prod_{i=1}^n f(X_i; \\theta)\n",
        "$$\n",
        "Для удобства вычислений часто используют логарифмическую функцию правдоподобия:\n",
        "$$\n",
        "\\ln L(\\theta) = \\sum_{i=1}^n \\ln f(X_i; \\theta)\n",
        "$$\n",
        "Задача сводится к максимизации этой функции относительно $ \\theta $.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о росте людей в определённой популяции. Вы предполагаете, что рост подчиняется нормальному распределению, но не знаете его параметры ($ \\mu $ и $ \\sigma $). ММП поможет вам найти эти параметры.\n",
        "\n",
        "\n",
        "### **Реализация на Python**\n",
        "\n",
        "Давайте рассмотрим пример использования ММП для нормального распределения.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Сгенерируем выборку из нормального распределения\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=5, scale=2, size=100)\n",
        "\n",
        "# Функция правдоподобия для нормального распределения\n",
        "def log_likelihood(params):\n",
        "    mu, sigma = params\n",
        "    if sigma <= 0:  # Ограничение: дисперсия должна быть положительной\n",
        "        return np.inf\n",
        "    ll = -np.sum(norm.logpdf(data, loc=mu, scale=sigma))  # Минус для минимизации\n",
        "    return ll\n",
        "\n",
        "# Начальные приближения для параметров\n",
        "initial_guess = [0, 1]\n",
        "\n",
        "# Находим оптимальные параметры\n",
        "result = minimize(log_likelihood, initial_guess, method='L-BFGS-B', bounds=[(-np.inf, np.inf), (1e-6, None)])\n",
        "\n",
        "# Вывод результатов\n",
        "print(\"Оценка μ (математического ожидания):\", result.x[0])\n",
        "print(\"Оценка σ (стандартного отклонения):\", result.x[1])\n",
        "\n",
        "# Визуализация данных и нормального распределения\n",
        "x_values = np.linspace(min(data), max(data), 100)\n",
        "pdf_values = norm.pdf(x_values, loc=result.x[0], scale=result.x[1])\n",
        "\n",
        "plt.hist(data, bins=20, density=True, alpha=0.6, color='blue', label='Выборка')\n",
        "plt.plot(x_values, pdf_values, color='red', label='Нормальное распределение (ММП)')\n",
        "plt.title('Сравнение выборки и нормального распределения')\n",
        "plt.xlabel('Значения')\n",
        "plt.ylabel('Плотность вероятности')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `np.random.normal()` генерирует выборку из нормального распределения с известными параметрами ($ \\mu = 5 $, $ \\sigma = 2 $).\n",
        "2. `log_likelihood()` вычисляет логарифмическую функцию правдоподобия.\n",
        "3. `minimize()` находит оптимальные параметры $ \\mu $ и $ \\sigma $.\n",
        "4. График показывает, как хорошо нормальное распределение с найденными параметрами описывает выборку.\n",
        "\n",
        "\n",
        "## **2. Метод Моментов**\n",
        "\n",
        "### **Теоретические основы**\n",
        "Метод моментов основан на равенстве теоретических моментов распределения и их выборочных аналогов. Например, если у нас есть распределение с параметром $ \\theta $, то можно использовать следующие соотношения:\n",
        "$$\n",
        "\\text{Выборочный момент} = \\text{Теоретический момент}\n",
        "$$\n",
        "Для нормального распределения:\n",
        "- Первый момент (математическое ожидание): $ \\bar{X} = \\mu $\n",
        "- Второй центральный момент (дисперсия): $ S^2 = \\sigma^2 $\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о доходах сотрудников компании. Вы предполагаете, что доходы подчиняются нормальному распределению. Метод моментов поможет вам найти параметры этого распределения.\n",
        "\n",
        "\n",
        "### **Реализация на Python**\n",
        "\n",
        "```python\n",
        "# Выборочные моменты\n",
        "mean_sample = np.mean(data)\n",
        "var_sample = np.var(data, ddof=0)  # Используем несмещенную оценку дисперсии\n",
        "\n",
        "# Оценки параметров\n",
        "mu_moments = mean_sample\n",
        "sigma_moments = np.sqrt(var_sample)\n",
        "\n",
        "print(\"Оценка μ (математического ожидания):\", mu_moments)\n",
        "print(\"Оценка σ (стандартного отклонения):\", sigma_moments)\n",
        "\n",
        "# Визуализация данных и нормального распределения (метод моментов)\n",
        "pdf_values_moments = norm.pdf(x_values, loc=mu_moments, scale=sigma_moments)\n",
        "\n",
        "plt.hist(data, bins=20, density=True, alpha=0.6, color='green', label='Выборка')\n",
        "plt.plot(x_values, pdf_values_moments, color='orange', label='Нормальное распределение (Метод Моментов)')\n",
        "plt.title('Сравнение выборки и нормального распределения')\n",
        "plt.xlabel('Значения')\n",
        "plt.ylabel('Плотность вероятности')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `np.mean()` вычисляет выборочное среднее ($ \\bar{X} $).\n",
        "2. `np.var()` вычисляет выборочную дисперсию ($ S^2 $).\n",
        "3. График показывает, как хорошо нормальное распределение с найденными параметрами описывает выборку.\n",
        "\n",
        "\n",
        "## **3. Сравнение Методов**\n",
        "\n",
        "Чтобы сравнить эффективность ММП и метода моментов, давайте построим графики остатков для обеих методик.\n",
        "\n",
        "```python\n",
        "# Рассчитываем остатки\n",
        "residuals_mle = data - result.x[0]\n",
        "residuals_moments = data - mu_moments\n",
        "\n",
        "# Графики остатков\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(residuals_mle, bins=20, alpha=0.7, color='blue')\n",
        "plt.title('Остатки (ММП)')\n",
        "plt.xlabel('Значения')\n",
        "plt.ylabel('Частота')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(residuals_moments, bins=20, alpha=0.7, color='green')\n",
        "plt.title('Остатки (Метод Моментов)')\n",
        "plt.xlabel('Значения')\n",
        "plt.ylabel('Частота')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Вывод:**\n",
        "- ММП обычно даёт более точные оценки, особенно при больших объёмах выборки.\n",
        "- Метод моментов проще в реализации, но может быть менее точным для маленьких выборок.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **4. Байесовские Оценки**\n",
        "\n",
        "### **Введение в байесовское оценивание**\n",
        "\n",
        "Байесовский подход к оцениванию параметров распределений использует априорные знания о параметрах. Он основывается на формуле Байеса:\n",
        "$$\n",
        "P(\\theta | X) = \\frac{P(X | \\theta) P(\\theta)}{P(X)},\n",
        "$$\n",
        "где:\n",
        "- $ P(\\theta | X) $ — апостериорное распределение параметра $ \\theta $ (то есть распределение после учёта данных).\n",
        "- $ P(X | \\theta) $ — функция правдоподобия (вероятность данных при заданном параметре).\n",
        "- $ P(\\theta) $ — априорное распределение параметра $ \\theta $ (наш начальный уровень знаний о параметре).\n",
        "- $ P(X) $ — нормирующий множитель (вероятность данных).\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о температуре воздуха в городе. Вы знаете, что средняя температура обычно равна 20°C, но хотите обновить это знание на основе новых наблюдений. Байесовский подход позволяет объединить ваше априорное знание с новыми данными.\n",
        "\n",
        "\n",
        "\n",
        "### **Пример использования априорных распределений**\n",
        "\n",
        "Допустим, мы знаем, что параметр $ \\mu $ нормального распределения имеет априорное распределение $ N(0, 1) $. Мы можем использовать библиотеку `PyMC3` для байесовского анализа.\n",
        "\n",
        "```python\n",
        "import pymc3 as pm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Сгенерируем выборку данных\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=5, scale=2, size=100)\n",
        "\n",
        "# Создаём байесовскую модель\n",
        "with pm.Model() as model:\n",
        "    # Априорное распределение для μ\n",
        "    mu = pm.Normal('mu', mu=0, sigma=1)\n",
        "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
        "    \n",
        "    # Функция правдоподобия\n",
        "    likelihood = pm.Normal('likelihood', mu=mu, sigma=sigma, observed=data)\n",
        "    \n",
        "    # Запускаем MCMC-сэмплер\n",
        "    trace = pm.sample(1000, return_inferencedata=False)\n",
        "\n",
        "# Визуализация апостериорных распределений\n",
        "pm.plot_posterior(trace, var_names=['mu', 'sigma'])\n",
        "plt.suptitle('Апостериорные распределения параметров')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `pm.Normal('mu', mu=0, sigma=1)` определяет априорное распределение для параметра $ \\mu $.\n",
        "2. `pm.HalfNormal('sigma', sigma=1)` определяет априорное распределение для параметра $ \\sigma $ (положительное значение).\n",
        "3. `pm.Normal('likelihood', mu=mu, sigma=sigma, observed=data)` определяет функцию правдоподобия.\n",
        "4. `pm.sample()` запускает MCMC-сэмплер для получения апостериорных распределений.\n",
        "5. `pm.plot_posterior()` строит графики апостериорных распределений.\n",
        "\n",
        "\n",
        "\n",
        "## **5. Оценка Эффективности Оценок**\n",
        "\n",
        "### **Несмещенность, состоятельность, эффективность**\n",
        "\n",
        "Чтобы выбрать лучший метод оценивания, необходимо оценить его свойства:\n",
        "\n",
        "1. **Несмещенность**: Среднее значение оценки должно совпадать с истинным значением параметра.\n",
        "   - Если $ E[\\hat{\\theta}] = \\theta $, то оценка называется несмещенной.\n",
        "   \n",
        "2. **Состоятельность**: При увеличении объёма выборки оценка должна стремиться к истинному значению параметра.\n",
        "   - Это свойство важно для больших выборок.\n",
        "\n",
        "3. **Эффективность**: Оценка должна иметь минимальную дисперсию среди всех несмещенных оценок.\n",
        "   - Чем меньше дисперсия, тем более точной считается оценка.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о доходах сотрудников компании. Хотите сравнить два метода оценивания: ММП и метод моментов. Критерий эффективности поможет вам выбрать лучший метод.\n",
        "\n",
        "\n",
        "\n",
        "### **Практические примеры сравнения оценок**\n",
        "\n",
        "Давайте сравним дисперсии оценок $ \\mu $, полученных различными методами.\n",
        "\n",
        "```python\n",
        "# Симуляция для сравнения дисперсий\n",
        "num_simulations = 1000\n",
        "mle_estimates = []\n",
        "moments_estimates = []\n",
        "\n",
        "for _ in range(num_simulations):\n",
        "    sim_data = np.random.normal(loc=5, scale=2, size=100)\n",
        "    \n",
        "    # ММП\n",
        "    mle_result = minimize(log_likelihood, initial_guess, method='L-BFGS-B', bounds=[(-np.inf, np.inf), (1e-6, None)])\n",
        "    mle_estimates.append(mle_result.x[0])\n",
        "    \n",
        "    # Метод моментов\n",
        "    moments_estimates.append(np.mean(sim_data))\n",
        "\n",
        "# Вычисление дисперсий\n",
        "var_mle = np.var(mle_estimates, ddof=1)\n",
        "var_moments = np.var(moments_estimates, ddof=1)\n",
        "\n",
        "print(\"Дисперсия ММП:\", var_mle)\n",
        "print(\"Дисперсия метода моментов:\", var_moments)\n",
        "\n",
        "# Визуализация распределений оценок\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(mle_estimates, bins=20, alpha=0.7, color='blue')\n",
        "plt.title('Распределение оценок ММП')\n",
        "plt.xlabel('Оценка μ')\n",
        "plt.ylabel('Частота')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(moments_estimates, bins=20, alpha=0.7, color='green')\n",
        "plt.title('Распределение оценок метода моментов')\n",
        "plt.xlabel('Оценка μ')\n",
        "plt.ylabel('Частота')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. Мы проводим 1000 симуляций, генерируя выборки из нормального распределения.\n",
        "2. Для каждой выборки вычисляем оценки $ \\mu $ с помощью ММП и метода моментов.\n",
        "3. Сравниваем дисперсии этих оценок.\n",
        "4. Графики показывают распределения оценок для обоих методов.\n",
        "\n",
        "\n",
        "\n",
        "### **Вывод**\n",
        "- **ММП** обычно даёт более эффективные оценки, так как его дисперсия меньше.\n",
        "- **Метод моментов** проще в реализации, но может быть менее точным для маленьких выборок.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Вопросы для самопроверки**\n",
        "\n",
        "1. Что такое точечное оценивание в статистике?\n",
        "2. Какой метод является одним из самых популярных способов оценки параметров распределения?\n",
        "3. Опишите идею метода максимального правдоподобия (ММП).\n",
        "4. Что представляет собой функция правдоподобия?\n",
        "5. Почему часто используют логарифмическую функцию правдоподобия вместо обычной?\n",
        "6. Какую формулу можно использовать для вычисления функции правдоподобия?\n",
        "7. Что обозначает $ \\theta $ в формуле правдоподобия?\n",
        "8. Какие предположения делаются о выборке при использовании ММП?\n",
        "9. В каком случае может быть полезен метод максимального правдоподобия?\n",
        "10. Какие параметры нормального распределения обычно оцениваются с помощью ММП?\n",
        "11. Какие ограничения могут быть наложены на параметры при максимизации функции правдоподобия?\n",
        "12. Почему важно учитывать независимость наблюдений при применении ММП?\n",
        "13. Как интерпретировать результаты, полученные с помощью ММП?\n",
        "14. Какие инструменты Python можно использовать для реализации ММП?\n",
        "15. Какой модуль Python используется для генерации случайных чисел?\n",
        "16. Какой модуль Python помогает минимизировать или максимизировать функции?\n",
        "17. Для чего используется библиотека `scipy.stats`?\n",
        "18. Как можно проверить корректность оценок параметров, полученных с помощью ММП?\n",
        "19. Как влияет размер выборки на точность оценок параметров?\n",
        "20. Какие альтернативные методы оценивания существуют помимо ММП?\n",
        "21. Что такое стандартная ошибка оценки параметра?\n",
        "22. Как найти стандартную ошибку параметра, оцененного с помощью ММП?\n",
        "23. Как интерпретировать график функции правдоподобия?\n",
        "24. Как определить, является ли найденное значение параметра глобальным максимумом?\n",
        "25. Какие проблемы могут возникнуть при реализации ММП на практике?\n",
        "26. Что делать, если функция правдоподобия имеет несколько локальных максимумов?\n",
        "27. Какую роль играет начальная точка при оптимизации функции правдоподобия?\n",
        "28. Можно ли использовать ММП для оценки параметров не только нормального распределения?\n",
        "29. Какие распределения, кроме нормального, часто анализируют с помощью ММП?\n",
        "30. Какие практические применения имеет метод максимального правдоподобия?\n",
        "\n",
        "\n",
        "## **Задачи для самостоятельной работы**\n",
        "\n",
        "1. Сгенерируйте выборку из нормального распределения с заданными параметрами ($\\mu = 10$, $\\sigma = 3$) и используйте ММП для оценки этих параметров.\n",
        "2. Постройте график функции правдоподобия для нормального распределения с известным параметром $\\sigma = 2$ и оцените $\\mu$.\n",
        "3. Реализуйте функцию правдоподобия для экспоненциального распределения и найдите его параметр $\\lambda$.\n",
        "4. Используя данные о росте людей, оцените параметры нормального распределения с помощью ММП.\n",
        "5. Сравните результаты оценки параметров методом максимального правдоподобия и методом моментов для одной и той же выборки.\n",
        "6. Найдите параметры равномерного распределения на отрезке $[a, b]$ с помощью ММП.\n",
        "7. Сгенерируйте выборку из пуассоновского распределения и оцените его параметр $\\lambda$.\n",
        "8. Оцените параметры двумерного нормального распределения с помощью ММП.\n",
        "9. Реализуйте процедуру минимизации функции правдоподобия для биномиального распределения.\n",
        "10. Постройте доверительный интервал для параметра нормального распределения, оцененного с помощью ММП.\n",
        "11. Исследуйте зависимость точности оценок параметров от размера выборки.\n",
        "12. Проверьте, как влияет добавление выбросов в выборку на оценки параметров методом ММП.\n",
        "13. Найдите параметры логнормального распределения с помощью ММП.\n",
        "14. Оцените параметры смеси двух нормальных распределений с помощью ММП.\n",
        "15. Реализуйте процедуру оценки параметров гамма-распределения.\n",
        "16. Сравните эффективность ММП и других методов оценивания для разных типов распределений.\n",
        "17. Найдите параметры бета-распределения с помощью ММП.\n",
        "18. Оцените параметры геометрического распределения по заданной выборке.\n",
        "19. Реализуйте алгоритм, который автоматически выбирает начальную точку для оптимизации функции правдоподобия.\n",
        "20. Исследуйте поведение функции правдоподобия для распределений с несколькими параметрами.\n",
        "21. Оцените параметры нормального распределения с использованием реальных данных (например, данные о температуре воздуха).\n",
        "22. Постройте графики функций правдоподобия для различных значений параметров.\n",
        "23. Реализуйте процедуру оценки параметров для распределения Коши.\n",
        "24. Исследуйте, как меняется форма функции правдоподобия при увеличении размера выборки.\n",
        "25. Найдите параметры многомерного нормального распределения с помощью ММП.\n",
        "26. Оцените параметры распределения Вейбулла для заданной выборки.\n",
        "27. Реализуйте процедуру оценки параметров для распределения Лапласа.\n",
        "28. Исследуйте влияние шума в данных на точность оценок параметров.\n",
        "29. Разработайте алгоритм, который позволяет находить все локальные максимумы функции правдоподобия.\n",
        "30. Оцените параметры распределения Парето для заданной выборки.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oFU4BlnnqTHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **7. Практика Интервального Оценивания на Python**\n",
        "\n",
        "Интервальное оценивание — это метод, который позволяет определить диапазон значений, в котором с заданной вероятностью находится истинное значение параметра генеральной совокупности. В этом разделе мы рассмотрим три важных случая: доверительный интервал для среднего при известной дисперсии, доверительный интервал для дисперсии и доверительный интервал для среднего при неизвестной дисперсии.\n",
        "\n",
        "\n",
        "\n",
        "## **1. Доверительный Интервал для Среднего Нормального Распределения (Известная Дисперсия)**\n",
        "\n",
        "Если мы знаем дисперсию генеральной совокупности ($ \\sigma^2 $), то можем использовать стандартное нормальное распределение для построения доверительного интервала для среднего значения ($ \\mu $).\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "\\bar{x} - z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{x} + z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
        "$$\n",
        "где:\n",
        "- $ \\bar{x} $ — выборочное среднее,\n",
        "- $ z_{\\alpha/2} $ — квантиль стандартного нормального распределения,\n",
        "- $ \\sigma $ — стандартное отклонение генеральной совокупности,\n",
        "- $ n $ — размер выборки.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете время выполнения задачи сотрудниками компании. Известно, что время выполнения имеет нормальное распределение с дисперсией $ \\sigma^2 = 9 $. Из выборки из 25 сотрудников получено среднее время выполнения задачи $ \\bar{x} = 30 $ минут. Построим 95%-ый доверительный интервал для среднего времени выполнения.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Исходные данные\n",
        "x_bar = 30  # Выборочное среднее\n",
        "sigma = 3   # Стандартное отклонение генеральной совокупности\n",
        "n = 25      # Размер выборки\n",
        "confidence_level = 0.95  # Уровень доверия\n",
        "\n",
        "# Квантиль Z для заданного уровня доверия\n",
        "z = norm.ppf(1 - (1 - confidence_level) / 2)\n",
        "\n",
        "# Погрешность\n",
        "margin_of_error = z * (sigma / np.sqrt(n))\n",
        "\n",
        "# Доверительный интервал\n",
        "lower_bound = x_bar - margin_of_error\n",
        "upper_bound = x_bar + margin_of_error\n",
        "\n",
        "print(f\"95%-ый доверительный интервал: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `norm.ppf()` вычисляет квантиль стандартного нормального распределения.\n",
        "2. `margin_of_error` — это ширина доверительного интервала.\n",
        "3. `lower_bound` и `upper_bound` — границы доверительного интервала.\n",
        "\n",
        "\n",
        "\n",
        "## **2. Доверительный Интервал для Дисперсии Нормального Распределения**\n",
        "\n",
        "Если нам нужно оценить дисперсию ($ \\sigma^2 $) генеральной совокупности, используем распределение хи-квадрат ($ \\chi^2 $).\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "\\frac{(n-1)s^2}{\\chi^2_{1-\\alpha/2}} \\leq \\sigma^2 \\leq \\frac{(n-1)s^2}{\\chi^2_{\\alpha/2}}\n",
        "$$\n",
        "где:\n",
        "- $ s^2 $ — выборочная дисперсия,\n",
        "- $ n-1 $ — число степеней свободы,\n",
        "- $ \\chi^2_{\\alpha/2} $ и $ \\chi^2_{1-\\alpha/2} $ — квантили распределения хи-квадрат.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о производительности оборудования. У вас есть выборка размером $ n = 15 $ с выборочной дисперсией $ s^2 = 4 $. Построим 90%-ый доверительный интервал для дисперсии.\n",
        "\n",
        "```python\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Исходные данные\n",
        "s_squared = 4  # Выборочная дисперсия\n",
        "n = 15         # Размер выборки\n",
        "confidence_level = 0.90  # Уровень доверия\n",
        "\n",
        "# Число степеней свободы\n",
        "df = n - 1\n",
        "\n",
        "# Квантили хи-квадрат\n",
        "chi2_lower = chi2.ppf((1 - confidence_level) / 2, df)\n",
        "chi2_upper = chi2.ppf(1 - (1 - confidence_level) / 2, df)\n",
        "\n",
        "# Доверительный интервал\n",
        "lower_bound = (df * s_squared) / chi2_upper\n",
        "upper_bound = (df * s_squared) / chi2_lower\n",
        "\n",
        "print(f\"90%-ый доверительный интервал для дисперсии: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `chi2.ppf()` вычисляет квантили распределения хи-квадрат.\n",
        "2. `lower_bound` и `upper_bound` — границы доверительного интервала для дисперсии.\n",
        "\n",
        "\n",
        "\n",
        "## **3. Доверительный Интервал для Среднего Нормального Распределения (Неизвестная Дисперсия)**\n",
        "\n",
        "Если дисперсия генеральной совокупности неизвестна, то вместо стандартного нормального распределения используется распределение Стьюдента ($ t $).\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "\\bar{x} - t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{x} + t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}}\n",
        "$$\n",
        "где:\n",
        "- $ s $ — выборочное стандартное отклонение,\n",
        "- $ t_{\\alpha/2, n-1} $ — квантиль распределения Стьюдента.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о доходах сотрудников компании. У вас есть выборка размером $ n = 10 $ со средним $ \\bar{x} = 25 $ тысяч рублей и стандартным отклонением $ s = 5 $ тысяч рублей. Построим 99%-ый доверительный интервал для среднего дохода.\n",
        "\n",
        "```python\n",
        "from scipy.stats import t\n",
        "\n",
        "# Исходные данные\n",
        "x_bar = 25  # Выборочное среднее\n",
        "s = 5       # Выборочное стандартное отклонение\n",
        "n = 10      # Размер выборки\n",
        "confidence_level = 0.99  # Уровень доверия\n",
        "\n",
        "# Число степеней свободы\n",
        "df = n - 1\n",
        "\n",
        "# Квантиль T для заданного уровня доверия\n",
        "t_value = t.ppf(1 - (1 - confidence_level) / 2, df)\n",
        "\n",
        "# Погрешность\n",
        "margin_of_error = t_value * (s / np.sqrt(n))\n",
        "\n",
        "# Доверительный интервал\n",
        "lower_bound = x_bar - margin_of_error\n",
        "upper_bound = x_bar + margin_of_error\n",
        "\n",
        "print(f\"99%-ый доверительный интервал: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `t.ppf()` вычисляет квантиль распределения Стьюдента.\n",
        "2. `margin_of_error` — это ширина доверительного интервала.\n",
        "3. `lower_bound` и `upper_bound` — границы доверительного интервала.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **4. Доверительный Интервал для Доли (Вероятности Успеха)**\n",
        "\n",
        "Для оценки доли успехов ($ p $) в биномиальном распределении можно использовать асимптотический метод. Этот подход работает хорошо для больших выборок.\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "\\hat{p} - z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\leq p \\leq \\hat{p} + z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n",
        "$$\n",
        "где:\n",
        "- $ \\hat{p} = \\frac{k}{n} $ — выборочная доля успехов,\n",
        "- $ k $ — количество успехов,\n",
        "- $ n $ — размер выборки.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете результаты опроса, где 60 из 100 респондентов ответили \"да\" на вопрос о предпочтении нового продукта. Построим 95%-ый доверительный интервал для вероятности успеха.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Исходные данные\n",
        "k = 60     # Количество успехов\n",
        "n = 100    # Размер выборки\n",
        "confidence_level = 0.95  # Уровень доверия\n",
        "\n",
        "# Выборочная доля успехов\n",
        "p_hat = k / n\n",
        "\n",
        "# Квантиль Z для заданного уровня доверия\n",
        "z = norm.ppf(1 - (1 - confidence_level) / 2)\n",
        "\n",
        "# Погрешность\n",
        "margin_of_error = z * np.sqrt(p_hat * (1 - p_hat) / n)\n",
        "\n",
        "# Доверительный интервал\n",
        "lower_bound = max(0, p_hat - margin_of_error)\n",
        "upper_bound = min(1, p_hat + margin_of_error)\n",
        "\n",
        "print(f\"95%-ый доверительный интервал для доли: [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `norm.ppf()` вычисляет квантиль стандартного нормального распределения.\n",
        "2. `margin_of_error` — это ширина доверительного интервала.\n",
        "3. `lower_bound` и `upper_bound` ограничены диапазоном от 0 до 1, так как доля не может выходить за эти границы.\n",
        "\n",
        "\n",
        "\n",
        "## **5. Доверительные Интервалы для Медианы**\n",
        "\n",
        "Медиана часто используется как мера центральной тенденции для несимметричных или сильно скошенных данных. Для её оценки можно использовать **бутстреп-метод**, который особенно эффективен при небольших выборках.\n",
        "\n",
        "### **Бутстреп-метод:**\n",
        "1. Создайте много реплик выборки с повторениями.\n",
        "2. Для каждой реплики вычислите медиану.\n",
        "3. Используйте перцентили полученных значений медианы для построения доверительного интервала.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о доходах сотрудников компании. Распределение доходов сильно скошено вправо, поэтому медиана лучше описывает \"типичный\" доход, чем среднее значение. Построим доверительный интервал для медианы.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Исходные данные\n",
        "data = [1, 2, 3, 4, 5, 6, 7, 8, 9]  # Пример выборки\n",
        "bootstrap_samples = 1000            # Количество бутстреп-реплик\n",
        "confidence_level = 0.95             # Уровень доверия\n",
        "\n",
        "# Бутстреп\n",
        "medians = []\n",
        "for _ in range(bootstrap_samples):\n",
        "    bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
        "    medians.append(np.median(bootstrap_sample))\n",
        "\n",
        "# Доверительный интервал\n",
        "lower_percentile = (1 - confidence_level) / 2 * 100\n",
        "upper_percentile = (1 + confidence_level) / 2 * 100\n",
        "lower_bound = np.percentile(medians, lower_percentile)\n",
        "upper_bound = np.percentile(medians, upper_percentile)\n",
        "\n",
        "print(f\"Доверительный интервал для медианы: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. `np.random.choice()` создает бутстреп-реплику выборки с повторениями.\n",
        "2. `np.median()` вычисляет медиану для каждой реплики.\n",
        "3. `np.percentile()` определяет границы доверительного интервала на основе перцентилей.\n",
        "\n",
        "\n",
        "\n",
        "## **6. Доверительные Интервалы для Доли с Корректировкой**\n",
        "\n",
        "Для малых выборок использование асимптотического метода может привести к неточным результатам. В таких случаях рекомендуется использовать метод Уилсона, который более точен.\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "\\frac{\\hat{p} + \\frac{z^2}{2n} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n} + \\frac{z^2}{4n^2}}}{1 + \\frac{z^2}{n}}\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы проводите эксперимент с новым лекарством. Из 20 пациентов 5 сообщили об улучшении состояния. Построим 95%-ый доверительный интервал для вероятности успеха с использованием метода Уилсона.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Исходные данные\n",
        "k = 5     # Количество успехов\n",
        "n = 20    # Размер выборки\n",
        "confidence_level = 0.95  # Уровень доверия\n",
        "\n",
        "# Квантиль Z\n",
        "z = norm.ppf(1 - (1 - confidence_level) / 2)\n",
        "\n",
        "# Выборочная доля успехов\n",
        "p_hat = k / n\n",
        "\n",
        "# Корректированный доверительный интервал\n",
        "numerator1 = p_hat + (z**2) / (2 * n)\n",
        "denominator = 1 + (z**2) / n\n",
        "margin_of_error = z * np.sqrt((p_hat * (1 - p_hat) / n) + ((z**2) / (4 * n**2)))\n",
        "\n",
        "lower_bound = (numerator1 - margin_of_error) / denominator\n",
        "upper_bound = (numerator1 + margin_of_error) / denominator\n",
        "\n",
        "print(f\"Доверительный интервал Уилсона: [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
        "```\n",
        "\n",
        "**Объяснение кода:**\n",
        "1. Формула Уилсона включает коррекцию для малых выборок.\n",
        "2. `margin_of_error` учитывает как выборочную долю успехов, так и размер выборки.\n",
        "3. `lower_bound` и `upper_bound` дают более точные границы доверительного интервала.\n",
        "\n",
        "\n",
        " ## **Вопросы для самопроверки**\n",
        "\n",
        "1. Что такое интервальное оценивание в статистике?\n",
        "2. Какой метод используется для построения доверительных интервалов при известной дисперсии?\n",
        "3. Какую роль играет стандартное нормальное распределение в построении доверительных интервалов?\n",
        "4. Что обозначает $ z_{\\alpha/2} $ в формуле доверительного интервала для среднего значения?\n",
        "5. Почему важно знать размер выборки при построении доверительных интервалов?\n",
        "6. Как влияет уровень доверия на ширину доверительного интервала?\n",
        "7. Какие предположения делаются о данных при использовании нормального распределения для построения доверительных интервалов?\n",
        "8. В каком случае используется распределение Стьюдента вместо стандартного нормального распределения?\n",
        "9. Что такое степень свободы в контексте распределения хи-квадрат?\n",
        "10. Как строится доверительный интервал для дисперсии нормального распределения?\n",
        "11. Как интерпретировать результаты, полученные с помощью доверительных интервалов?\n",
        "12. Для чего используется бутстреп-метод в статистике?\n",
        "13. Какие преимущества имеет бутстреп-метод перед традиционными методами построения доверительных интервалов?\n",
        "14. Какая проблема возникает при использовании асимптотического метода для малых выборок?\n",
        "15. Что такое метод Уилсона для построения доверительных интервалов?\n",
        "16. Какой модуль Python используется для вычисления квантилей стандартного нормального распределения?\n",
        "17. Какой модуль Python помогает работать с распределением хи-квадрат?\n",
        "18. Какой модуль Python используется для работы с распределением Стьюдента?\n",
        "19. Как найти выборочную долю успехов ($ \\hat{p} $) в биномиальном распределении?\n",
        "20. Как влияет количество успехов на ширину доверительного интервала для доли?\n",
        "21. Как проверить корректность построенного доверительного интервала?\n",
        "22. Какие ограничения накладываются на данные при использовании метода Уилсона?\n",
        "23. Как интерпретировать доверительный интервал для медианы?\n",
        "24. Какой модуль Python можно использовать для генерации случайных чисел с повторениями?\n",
        "25. Как определить границы доверительного интервала для медианы с помощью бутстреп-метода?\n",
        "26. Какие практические применения имеют доверительные интервалы?\n",
        "27. Как влияет форма распределения данных на выбор метода построения доверительного интервала?\n",
        "28. Какие альтернативные методы построения доверительных интервалов существуют помимо традиционных?\n",
        "29. Как интерпретировать перцентили в контексте бутстреп-метода?\n",
        "30. Как выбрать подходящий метод построения доверительного интервала для конкретной задачи?\n",
        "\n",
        "\n",
        "## **Задачи для самостоятельной работы**\n",
        "\n",
        "1. Постройте 95%-ый доверительный интервал для среднего значения нормального распределения с известной дисперсией ($ \\sigma^2 = 9 $), если выборочное среднее равно 30, а размер выборки равен 25.\n",
        "2. Используя данные о времени выполнения задачи (выборочное среднее = 30 минут, стандартное отклонение = 3 минуты, размер выборки = 25), постройте 90%-ый доверительный интервал для среднего времени выполнения.\n",
        "3. Оцените дисперсию нормального распределения с помощью выборочной дисперсии ($ s^2 = 4 $) и постройте 90%-ый доверительный интервал для неё, если размер выборки равен 15.\n",
        "4. Постройте 99%-ый доверительный интервал для среднего значения нормального распределения с неизвестной дисперсией, если выборочное среднее равно 25, выборочное стандартное отклонение равно 5, а размер выборки равен 10.\n",
        "5. На основе данных опроса (60 из 100 респондентов ответили \"да\"), постройте 95%-ый доверительный интервал для вероятности успеха.\n",
        "6. Используя метод Уилсона, постройте 95%-ый доверительный интервал для вероятности успеха, если из 20 пациентов 5 сообщили об улучшении состояния.\n",
        "7. Сгенерируйте выборку из нормального распределения и постройте доверительный интервал для её среднего значения.\n",
        "8. Реализуйте процедуру построения доверительного интервала для дисперсии с помощью распределения хи-квадрат.\n",
        "9. Исследуйте, как меняется ширина доверительного интервала при увеличении размера выборки.\n",
        "10. Постройте доверительный интервал для медианы с помощью бутстреп-метода для заданной выборки.\n",
        "11. Сравните результаты, полученные с помощью стандартного нормального распределения и распределения Стьюдента, для одной и той же выборки.\n",
        "12. Исследуйте влияние уровня доверия на ширину доверительного интервала.\n",
        "13. Постройте доверительный интервал для доли с использованием разных методов (асимптотический и Уилсона).\n",
        "14. Реализуйте алгоритм, который автоматически выбирает метод построения доверительного интервала в зависимости от размера выборки.\n",
        "15. Исследуйте поведение доверительных интервалов для различных типов распределений.\n",
        "16. Постройте доверительный интервал для среднего значения с использованием реальных данных (например, данные о температуре воздуха).\n",
        "17. Оцените параметры смеси двух нормальных распределений и постройте доверительные интервалы для них.\n",
        "18. Реализуйте процедуру построения доверительных интервалов для нескольких параметров одновременно.\n",
        "19. Исследуйте влияние выбросов в данных на точность доверительных интервалов.\n",
        "20. Постройте доверительный интервал для коэффициента корреляции между двумя переменными.\n",
        "21. Оцените параметры логнормального распределения и постройте доверительные интервалы для них.\n",
        "22. Реализуйте процедуру построения доверительных интервалов для параметров многомерного нормального распределения.\n",
        "23. Исследуйте, как меняется форма доверительного интервала при изменении формы исходного распределения.\n",
        "24. Постройте доверительный интервал для параметров экспоненциального распределения.\n",
        "25. Реализуйте алгоритм, который позволяет находить все возможные доверительные интервалы для заданного уровня доверия.\n",
        "26. Исследуйте влияние неоднородности данных на точность доверительных интервалов.\n",
        "27. Постройте доверительный интервал для параметров распределения Вейбулла.\n",
        "28. Реализуйте процедуру построения доверительных интервалов для параметров бета-распределения.\n",
        "29. Исследуйте, как меняется ширина доверительного интервала при изменении уровня значимости.\n",
        "30. Разработайте алгоритм, который позволяет автоматически подбирать оптимальный метод построения доверительного интервала.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5HR9j9hxwRFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **8. Практика Проверки Статистических Гипотез на Python**\n",
        "\n",
        "Проверка статистических гипотез — это методология, которая позволяет принимать решения о параметрах генеральной совокупности на основе выборочных данных. В этом разделе мы рассмотрим несколько важных случаев: проверку гипотез о среднем значении при известной и неизвестной дисперсии, проверку гипотез о дисперсии и доле успехов.\n",
        "\n",
        "\n",
        "\n",
        "## **1. Проверка гипотез о среднем значении нормального распределения (известная дисперсия)**\n",
        "\n",
        "Если дисперсия генеральной совокупности ($ \\sigma^2 $) известна, то для проверки гипотезы о среднем значении ($ \\mu $) используется стандартное нормальное распределение.\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "z = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о весе пачек чипсов. Производитель заявляет, что средний вес составляет 50 граммов ($ \\mu_0 = 50 $), а стандартное отклонение равно 2 граммам ($ \\sigma = 2 $). Вы взяли выборку из 36 пачек и получили средний вес $ \\bar{x} = 49.5 $. Проверим гипотезу на уровне значимости $ \\alpha = 0.05 $.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Исходные данные\n",
        "x_bar = 49.5  # Выборочное среднее\n",
        "mu_0 = 50     # Гипотетическое среднее\n",
        "sigma = 2     # Стандартное отклонение генеральной совокупности\n",
        "n = 36        # Размер выборки\n",
        "alpha = 0.05  # Уровень значимости\n",
        "\n",
        "# Статистика Z\n",
        "z_stat = (x_bar - mu_0) / (sigma / np.sqrt(n))\n",
        "\n",
        "# Критические значения\n",
        "z_critical = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "# Решение\n",
        "if abs(z_stat) > z_critical:\n",
        "    decision = \"Отвергаем нулевую гипотезу\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу\"\n",
        "\n",
        "print(f\"Z-статистика: {z_stat:.2f}, Критическое значение: {z_critical:.2f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если модуль $ Z $ больше критического значения, то мы отвергаем нулевую гипотезу. Это означает, что наблюдаемые данные значительно отличаются от предполагаемого значения $ \\mu_0 $.\n",
        "- Если модуль $ Z $ меньше или равен критическому значению, то мы не можем отвергнуть нулевую гипотезу. Это означает, что наблюдаемые данные согласуются с предполагаемым значением $ \\mu_0 $.\n",
        "\n",
        "#### Вывод для примера:\n",
        "Если $ Z $-статистика окажется за пределами критической области ($ |Z| > z_{крит} $), это указывает на то, что средний вес пачек чипсов действительно отличается от заявленного производителем значения 50 граммов. Если $ Z $ находится внутри критической области, можно считать, что разница между наблюдаемым средним ($ \\bar{x} = 49.5 $) и заявленным ($ \\mu_0 = 50 $) является случайной и не имеет статистической значимости.\n",
        "\n",
        "\n",
        "\n",
        "## **2. Проверка гипотез о среднем значении нормального распределения (неизвестная дисперсия)**\n",
        "\n",
        "Если дисперсия генеральной совокупности неизвестна, то вместо стандартного нормального распределения используется распределение Стьюдента ($ t $).\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы хотите проверить, равен ли средний рост студентов в университете 170 см ($ \\mu_0 = 170 $). Вы взяли выборку из 25 студентов со средним ростом $ \\bar{x} = 172 $ см и стандартным отклонением $ s = 5 $ см. Проверим гипотезу на уровне значимости $ \\alpha = 0.01 $.\n",
        "\n",
        "```python\n",
        "from scipy.stats import t\n",
        "\n",
        "# Исходные данные\n",
        "x_bar = 172  # Выборочное среднее\n",
        "mu_0 = 170   # Гипотетическое среднее\n",
        "s = 5        # Выборочное стандартное отклонение\n",
        "n = 25       # Размер выборки\n",
        "alpha = 0.01 # Уровень значимости\n",
        "\n",
        "# Статистика T\n",
        "t_stat = (x_bar - mu_0) / (s / np.sqrt(n))\n",
        "\n",
        "# Число степеней свободы\n",
        "df = n - 1\n",
        "\n",
        "# Критические значения\n",
        "t_critical = t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "# Решение\n",
        "if abs(t_stat) > t_critical:\n",
        "    decision = \"Отвергаем нулевую гипотезу\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу\"\n",
        "\n",
        "print(f\"T-статистика: {t_stat:.2f}, Критическое значение: {t_critical:.2f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если модуль $ T $ больше критического значения, то мы отвергаем нулевую гипотезу. Это означает, что средний рост студентов значительно отличается от предполагаемого значения 170 см.\n",
        "- Если модуль $ T $ меньше или равен критическому значению, то мы не можем отвергнуть нулевую гипотезу. Это означает, что наблюдаемый средний рост ($ \\bar{x} = 172 $) может быть объяснён случайными колебаниями вокруг предполагаемого значения $ \\mu_0 = 170 $.\n",
        "\n",
        "#### Вывод для примера:\n",
        "Если $ T $-статистика выходит за пределы критической области ($ |T| > t_{крит} $), это говорит о том, что средний рост студентов действительно выше 170 см. Если $ T $ находится внутри критической области, нельзя сделать вывод о значимой разнице между наблюдаемым и предполагаемым средними значениями.\n",
        "\n",
        "\n",
        "\n",
        "## **3. Проверка гипотез о дисперсии нормального распределения**\n",
        "\n",
        "Для проверки гипотезы о дисперсии ($ \\sigma^2 $) используется распределение хи-квадрат ($ \\chi^2 $).\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "\\chi^2 = \\frac{(n-1)s^2}{\\sigma_0^2}\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о времени выполнения задачи. Известно, что дисперсия времени выполнения должна быть равна 9 ($ \\sigma_0^2 = 9 $). Вы взяли выборку из 10 наблюдений со стандартным отклонением $ s = 3.5 $. Проверим гипотезу на уровне значимости $ \\alpha = 0.05 $.\n",
        "\n",
        "```python\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Исходные данные\n",
        "s_squared = 3.5**2  # Выборочная дисперсия\n",
        "sigma_0_squared = 9 # Гипотетическая дисперсия\n",
        "n = 10              # Размер выборки\n",
        "alpha = 0.05        # Уровень значимости\n",
        "\n",
        "# Статистика Хи-квадрат\n",
        "chi2_stat = (n - 1) * s_squared / sigma_0_squared\n",
        "\n",
        "# Число степеней свободы\n",
        "df = n - 1\n",
        "\n",
        "# Критические значения\n",
        "chi2_lower = chi2.ppf(alpha / 2, df)\n",
        "chi2_upper = chi2.ppf(1 - alpha / 2, df)\n",
        "\n",
        "# Решение\n",
        "if chi2_stat < chi2_lower or chi2_stat > chi2_upper:\n",
        "    decision = \"Отвергаем нулевую гипотезу\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу\"\n",
        "\n",
        "print(f\"Хи-квадрат статистика: {chi2_stat:.2f}, Критические значения: [{chi2_lower:.2f}, {chi2_upper:.2f}]\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если $ \\chi^2 $-статистика выходит за пределы критической области ($ \\chi^2 < \\chi^2_{lower} $ или $ \\chi^2 > \\chi^2_{upper} $), то мы отвергаем нулевую гипотезу. Это означает, что наблюдаемая дисперсия значительно отличается от предполагаемой ($ \\sigma_0^2 = 9 $).\n",
        "- Если $ \\chi^2 $-статистика находится внутри критической области, то мы не можем отвергнуть нулевую гипотезу. Это означает, что наблюдаемая дисперсия согласуется с предполагаемой.\n",
        "\n",
        "#### Вывод для примера:\n",
        "Если $ \\chi^2 $-статистика оказывается за пределами критической области, это указывает на то, что дисперсия времени выполнения задачи действительно отличается от заявленного значения 9. Если $ \\chi^2 $ находится внутри критической области, нельзя сделать вывод о значимой разнице между наблюдаемой и предполагаемой дисперсией.\n",
        "\n",
        "\n",
        "\n",
        "## **4. Проверка гипотез о доле успехов**\n",
        "\n",
        "Для проверки гипотез о доле успехов ($ p $) в биномиальном распределении можно использовать стандартное нормальное приближение.\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы проводите опрос среди 100 человек, и 60 из них ответили \"да\" на вопрос о предпочтении нового продукта. Производитель утверждает, что доля успехов должна быть равна 0.5 ($ p_0 = 0.5 $). Проверим гипотезу на уровне значимости $ \\alpha = 0.05 $.\n",
        "\n",
        "```python\n",
        "# Исходные данные\n",
        "k = 60     # Количество успехов\n",
        "n = 100    # Размер выборки\n",
        "p_0 = 0.5  # Гипотетическая доля успехов\n",
        "alpha = 0.05  # Уровень значимости\n",
        "\n",
        "# Выборочная доля успехов\n",
        "p_hat = k / n\n",
        "\n",
        "# Статистика Z\n",
        "z_stat = (p_hat - p_0) / np.sqrt(p_0 * (1 - p_0) / n)\n",
        "\n",
        "# Критические значения\n",
        "z_critical = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "# Решение\n",
        "if abs(z_stat) > z_critical:\n",
        "    decision = \"Отвергаем нулевую гипотезу\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу\"\n",
        "\n",
        "print(f\"Z-статистика: {z_stat:.2f}, Критическое значение: {z_critical:.2f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если модуль $ Z $ больше критического значения, то мы отвергаем нулевую гипотезу. Это означает, что доля людей, предпочитающих новый продукт, значительно отличается от заявленной производителем доли 0.5.\n",
        "- Если модуль $ Z $ меньше или равен критическому значению, то мы не можем отвергнуть нулевую гипотезу. Это означает, что наблюдаемая доля ($ \\hat{p} = 0.6 $) может быть объяснена случайными колебаниями вокруг предполагаемой доли ($ p_0 = 0.5 $).\n",
        "\n",
        "#### Вывод для примера:\n",
        "Если $ Z $-статистика выходит за пределы критической области ($ |Z| > z_{крит} $), это указывает на то, что доля людей, предпочитающих новый продукт, действительно выше 0.5. Если $ Z $ находится внутри критической области, нельзя сделать вывод о значимой разнице между наблюдаемой и предполагаемой долей.\n",
        "\n",
        "\n",
        "\n",
        "## **5. Проверка гипотез о равенстве двух средних**\n",
        "\n",
        "Для сравнения средних двух независимых выборок используется тест Стьюдента для двух выборок.\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы хотите сравнить среднюю производительность двух групп сотрудников. Первая группа ($ n_1 = 20 $) имеет среднюю производительность $ \\bar{x}_1 = 50 $ и стандартное отклонение $ s_1 = 5 $. Вторая группа ($ n_2 = 25 $) имеет среднюю производительность $ \\bar{x}_2 = 48 $ и стандартное отклонение $ s_2 = 6 $. Проверим гипотезу на уровне значимости $ \\alpha = 0.05 $.\n",
        "\n",
        "```python\n",
        "# Исходные данные\n",
        "x_bar1 = 50  # Среднее первой группы\n",
        "x_bar2 = 48  # Среднее второй группы\n",
        "s1 = 5       # Стандартное отклонение первой группы\n",
        "s2 = 6       # Стандартное отклонение второй группы\n",
        "n1 = 20      # Размер первой выборки\n",
        "n2 = 25      # Размер второй выборки\n",
        "alpha = 0.05 # Уровень значимости\n",
        "\n",
        "# Статистика T\n",
        "t_stat = (x_bar1 - x_bar2) / np.sqrt((s1**2 / n1) + (s2**2 / n2))\n",
        "\n",
        "# Число степеней свободы (приближённое)\n",
        "df = min(n1 - 1, n2 - 1)\n",
        "\n",
        "# Критические значения\n",
        "t_critical = t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "# Решение\n",
        "if abs(t_stat) > t_critical:\n",
        "    decision = \"Отвергаем нулевую гипотезу\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу\"\n",
        "\n",
        "print(f\"T-статистика: {t_stat:.2f}, Критическое значение: {t_critical:.2f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если модуль $ T $ больше критического значения, то мы отвергаем нулевую гипотезу. Это означает, что средние значения производительности двух групп значительно различаются.\n",
        "- Если модуль $ T $ меньше или равен критическому значению, то мы не можем отвергнуть нулевую гипотезу. Это означает, что разница между средними значениями может быть объяснена случайными колебаниями.\n",
        "\n",
        "#### Вывод для примера:\n",
        "Если $ T $-статистика выходит за пределы критической области ($ |T| > t_{крит} $), это указывает на то, что производительность первой группы действительно выше, чем второй. Если $ T $ находится внутри критической области, нельзя сделать вывод о значимой разнице между производительностью двух групп.\n",
        "\n",
        "\n",
        "\n",
        "## **6. Проверка гипотез о равенстве двух долей**\n",
        "\n",
        "Для сравнения двух долей успехов ($ p_1 $ и $ p_2 $) используется тест на разницу пропорций.\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "z = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p}(1-\\hat{p}) \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n",
        "$$\n",
        "где:\n",
        "$$\n",
        "\\hat{p} = \\frac{k_1 + k_2}{n_1 + n_2}\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы сравниваете эффективность двух рекламных кампаний. Первая кампания ($ n_1 = 200 $) привлекла $ k_1 = 120 $ клиентов, а вторая кампания ($ n_2 = 150 $) привлекла $ k_2 = 80 $ клиентов. Проверим гипотезу на уровне значимости $ \\alpha = 0.05 $.\n",
        "\n",
        "```python\n",
        "# Исходные данные\n",
        "k1 = 120  # Количество успехов первой кампании\n",
        "n1 = 200  # Размер первой выборки\n",
        "k2 = 80   # Количество успехов второй кампании\n",
        "n2 = 150  # Размер второй выборки\n",
        "alpha = 0.05  # Уровень значимости\n",
        "\n",
        "# Выборочные доли успехов\n",
        "p_hat1 = k1 / n1\n",
        "p_hat2 = k2 / n2\n",
        "\n",
        "# Общая доля успехов\n",
        "p_hat = (k1 + k2) / (n1 + n2)\n",
        "\n",
        "# Статистика Z\n",
        "z_stat = (p_hat1 - p_hat2) / np.sqrt(p_hat * (1 - p_hat) * ((1 / n1) + (1 / n2)))\n",
        "\n",
        "# Критические значения\n",
        "z_critical = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "# Решение\n",
        "if abs(z_stat) > z_critical:\n",
        "    decision = \"Отвергаем нулевую гипотезу\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу\"\n",
        "\n",
        "print(f\"Z-статистика: {z_stat:.2f}, Критическое значение: {z_critical:.2f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если модуль $ Z $ больше критического значения, то мы отвергаем нулевую гипотезу. Это означает, что эффективность двух рекламных кампаний значительно различается.\n",
        "- Если модуль $ Z $ меньше или равен критическому значению, то мы не можем отвергнуть нулевую гипотезу. Это означает, что разница между эффективностями двух кампаний может быть объяснена случайными колебаниями.\n",
        "\n",
        "#### Вывод для примера:\n",
        "Если $ Z $-статистика выходит за пределы критической области ($ |Z| > z_{крит} $), это указывает на то, что первая кампания действительно более эффективна, чем вторая. Если $ Z $ находится внутри критической области, нельзя сделать вывод о значимой разнице между эффективностями двух кампаний.\n",
        "\n",
        "\n",
        "\n",
        "## **7. Множественные Проверки Гипотез**\n",
        "\n",
        "При проведении множественных проверок гипотез вероятность ложноположительных результатов (ошибок первого рода) увеличивается. Для управления этой проблемой используются специальные методы корректировки.\n",
        "\n",
        "### **Основная идея:**\n",
        "Если мы проводим $ m $ независимых тестов на уровне значимости $ \\alpha $, то вероятность хотя бы одной ошибки первого рода возрастает до $ 1 - (1 - \\alpha)^m $. Чтобы уменьшить этот риск, применяются различные методы корректировки.\n",
        "\n",
        "#### **Метод Бонферрони:**\n",
        "Один из самых популярных методов корректировки заключается в снижении уровня значимости для каждого теста:\n",
        "$$\n",
        "\\alpha_{корр} = \\frac{\\alpha}{m}\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы тестируете эффективность трёх разных лекарств ($ m = 3 $) на уровне значимости $ \\alpha = 0.05 $. Используем метод Бонферрони для корректировки уровня значимости.\n",
        "\n",
        "```python\n",
        "# Исходные данные\n",
        "alpha = 0.05  # Общий уровень значимости\n",
        "m = 3         # Количество тестов\n",
        "\n",
        "# Корректировка уровня значимости по Бонферрони\n",
        "alpha_corr = alpha / m\n",
        "\n",
        "print(f\"Корректированный уровень значимости: {alpha_corr:.4f}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- После корректировки уровень значимости для каждого теста становится $ \\alpha_{корр} = 0.0167 $. Это снижает вероятность ложноположительных результатов.\n",
        "\n",
        "---\n",
        "\n",
        "## **8. Корректировка уровня значимости (Bonferroni, FDR)**\n",
        "\n",
        "Для контроля над множественными сравнениями существуют разные подходы. Наиболее распространённые — метод Бонферрони и контроль ложного открытия (FDR).\n",
        "\n",
        "#### **Контроль Ложного Открытия (FDR):**\n",
        "Метод FDR позволяет контролировать долю ложноположительных результатов среди всех обнаруженных эффектов. Он менее консервативен, чем метод Бонферрони.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы анализируете данные о 10 различных генах ($ m = 10 $) и хотите контролировать FDR на уровне $ q = 0.1 $.\n",
        "\n",
        "```python\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# Исходные p-значения для 10 тестов\n",
        "p_values = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "q = 0.1  # Уровень FDR\n",
        "\n",
        "# Корректировка p-значений с использованием FDR\n",
        "reject, corrected_p_values, _, _ = multipletests(p_values, alpha=q, method='fdr_bh')\n",
        "\n",
        "# Результаты\n",
        "for i, (p, corr_p, rej) in enumerate(zip(p_values, corrected_p_values, reject), 1):\n",
        "    print(f\"Тест {i}: p={p:.2f}, Корректированное p={corr_p:.2f}, Отклонение={rej}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Метод FDR корректирует p-значения таким образом, чтобы сохранить заданный уровень ложного открытия ($ q = 0.1 $). Это позволяет выявить больше значимых эффектов, чем метод Бонферрони.\n",
        "\n",
        "---\n",
        "\n",
        "## **9. Парные Сравнения**\n",
        "\n",
        "Парные сравнения используются, когда наблюдения между группами зависимы (например, при измерении одного и того же объекта до и после эксперимента).\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "t = \\frac{\\bar{d} - \\mu_0}{s_d / \\sqrt{n}}\n",
        "$$\n",
        "где:\n",
        "- $ \\bar{d} $ — среднее различие между парами,\n",
        "- $ s_d $ — стандартное отклонение различий,\n",
        "- $ n $ — количество пар.\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы хотите проверить, влияет ли диета на вес людей. Вы взяли выборку из 10 человек и записали их вес до ($ x_{до} $) и после ($ x_{после} $) диеты. Разница в весе составляет $ d = x_{до} - x_{после} $.\n",
        "\n",
        "```python\n",
        "# Исходные данные\n",
        "weights_before = [80, 75, 90, 85, 70, 82, 88, 77, 92, 78]  # Вес до диеты\n",
        "weights_after = [78, 73, 88, 83, 68, 80, 85, 75, 90, 76]   # Вес после диеты\n",
        "mu_0 = 0  # Гипотетическое различие\n",
        "alpha = 0.05  # Уровень значимости\n",
        "\n",
        "# Расчёт различий\n",
        "differences = np.array(weights_before) - np.array(weights_after)\n",
        "n = len(differences)\n",
        "d_bar = np.mean(differences)\n",
        "s_d = np.std(differences, ddof=1)\n",
        "\n",
        "# Статистика T\n",
        "t_stat = (d_bar - mu_0) / (s_d / np.sqrt(n))\n",
        "\n",
        "# Число степеней свободы\n",
        "df = n - 1\n",
        "\n",
        "# Критические значения\n",
        "t_critical = t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "# Решение\n",
        "if abs(t_stat) > t_critical:\n",
        "    decision = \"Отвергаем нулевую гипотезу\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу\"\n",
        "\n",
        "print(f\"T-статистика: {t_stat:.2f}, Критическое значение: {t_critical:.2f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если модуль $ T $ больше критического значения, то мы отвергаем нулевую гипотезу. Это означает, что диета действительно влияет на вес.\n",
        "- Если модуль $ T $ меньше или равен критическому значению, то мы не можем отвергнуть нулевую гипотезу. Это означает, что наблюдаемые изменения в весе могут быть случайными.\n",
        "\n",
        "---\n",
        "\n",
        "## **10. Проверка гипотез для зависимых выборок**\n",
        "\n",
        "Зависимые выборки возникают, когда каждое наблюдение в одной группе связано с конкретным наблюдением в другой группе (например, до и после эксперимента). Для таких данных используется парный t-тест.\n",
        "\n",
        "### **Формула:**\n",
        "$$\n",
        "t = \\frac{\\bar{d} - \\mu_0}{s_d / \\sqrt{n}}\n",
        "$$\n",
        "\n",
        "#### Пример из реальной жизни:\n",
        "Вы исследуете влияние курса обучения на результаты тестов студентов. Вы взяли выборку из 15 студентов и записали их баллы до ($ x_{до} $) и после ($ x_{после} $) курса.\n",
        "\n",
        "```python\n",
        "# Исходные данные\n",
        "scores_before = [50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 60, 65, 70, 75, 80]  # Баллы до курса\n",
        "scores_after = [55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 65, 70, 75, 80, 85]   # Баллы после курса\n",
        "mu_0 = 0  # Гипотетическое различие\n",
        "alpha = 0.01  # Уровень значимости\n",
        "\n",
        "# Расчёт различий\n",
        "differences = np.array(scores_after) - np.array(scores_before)\n",
        "n = len(differences)\n",
        "d_bar = np.mean(differences)\n",
        "s_d = np.std(differences, ddof=1)\n",
        "\n",
        "# Статистика T\n",
        "t_stat = (d_bar - mu_0) / (s_d / np.sqrt(n))\n",
        "\n",
        "# Число степеней свободы\n",
        "df = n - 1\n",
        "\n",
        "# Критические значения\n",
        "t_critical = t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "# Решение\n",
        "if abs(t_stat) > t_critical:\n",
        "    decision = \"Отвергаем нулевую гипотезу\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу\"\n",
        "\n",
        "print(f\"T-статистика: {t_stat:.2f}, Критическое значение: {t_critical:.2f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если модуль $ T $ больше критического значения, то мы отвергаем нулевую гипотезу. Это означает, что курс обучения значительно повлиял на результаты тестов.\n",
        "- Если модуль $ T $ меньше или равен критическому значению, то мы не можем отвергнуть нулевую гипотезу. Это означает, что наблюдаемые изменения в баллах могут быть случайными.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Вопросы для самопроверки**\n",
        "\n",
        "1. Что такое проверка статистических гипотез?\n",
        "2. Какую роль играет уровень значимости ($ \\alpha $) в проверке гипотез?\n",
        "3. Какие основные типы ошибок существуют при проверке гипотез?\n",
        "4. Что означает отклонение нулевой гипотезы?\n",
        "5. В каком случае используется стандартное нормальное распределение для проверки гипотез?\n",
        "6. Когда применяется распределение Стьюдента ($ t $) вместо стандартного нормального распределения?\n",
        "7. Как определить критическую область для теста на уровне значимости $ \\alpha = 0.05 $?\n",
        "8. Что такое $ z $-статистика и как она вычисляется?\n",
        "9. Как интерпретировать результаты $ t $-теста?\n",
        "10. Для чего используется распределение хи-квадрат ($ \\chi^2 $)?\n",
        "11. Какая формула используется для проверки гипотез о дисперсии?\n",
        "12. Какой метод применяется для сравнения двух средних независимых выборок?\n",
        "13. Что такое парный $ t $-тест и когда его используют?\n",
        "14. Как корректировать уровень значимости при множественных сравнениях?\n",
        "15. Что такое метод Бонферрони?\n",
        "16. Какой альтернативный метод можно использовать для контроля ложного открытия (FDR)?\n",
        "17. Какая разница между односторонним и двусторонним тестом?\n",
        "18. Как определить мощность теста?\n",
        "19. Что такое $ p $-значение и как его интерпретировать?\n",
        "20. Почему важно учитывать размер выборки при проверке гипотез?\n",
        "21. Какие предположения делаются о данных при использовании $ t $-теста?\n",
        "22. Как проверить гипотезу о доле успехов в биномиальном распределении?\n",
        "23. Какой метод используется для сравнения двух долей успехов?\n",
        "24. Что делать, если данные не соответствуют предположениям нормальности?\n",
        "25. Как выбрать подходящий тест для конкретной ситуации?\n",
        "26. Как влияет изменение уровня значимости на вероятность ошибок первого и второго рода?\n",
        "27. Что такое критическое значение и как его найти?\n",
        "28. Как интерпретировать результаты теста на равенство дисперсий?\n",
        "29. Какие практические применения имеют статистические тесты?\n",
        "30. Какие современные инструменты Python помогают выполнять проверку гипотез?\n",
        "\n",
        "\n",
        "## **Задачи для самостоятельной работы**\n",
        "\n",
        "1. Проверьте гипотезу о том, что средний вес пачек чипсов равен 50 граммам ($ \\mu_0 = 50 $), если известно, что стандартное отклонение равно 2 граммам, а выборочное среднее равно 49.5 граммам ($ n = 36 $).\n",
        "2. Используя данные о росте студентов ($ \\bar{x} = 172 $ см, $ s = 5 $ см, $ n = 25 $), проверьте гипотезу о том, что средний рост равен 170 см ($ \\mu_0 = 170 $) на уровне значимости $ \\alpha = 0.01 $.\n",
        "3. Проверьте гипотезу о том, что дисперсия времени выполнения задачи равна 9 ($ \\sigma_0^2 = 9 $), если выборочная дисперсия равна 12.25 ($ n = 10 $).\n",
        "4. Сравните две доли успехов: первая кампания ($ k_1 = 120 $, $ n_1 = 200 $), вторая кампания ($ k_2 = 80 $, $ n_2 = 150 $). Проверьте гипотезу о равенстве долей.\n",
        "5. Проведите парный $ t $-тест для данных о весе людей до и после диеты ($ n = 10 $).\n",
        "6. Используя метод Бонферрони, скорректируйте уровень значимости для трёх тестов, если общий уровень значимости равен $ \\alpha = 0.05 $.\n",
        "7. Проверьте гипотезу о том, что средняя производительность первой группы ($ \\bar{x}_1 = 50 $, $ s_1 = 5 $, $ n_1 = 20 $) равна средней производительности второй группы ($ \\bar{x}_2 = 48 $, $ s_2 = 6 $, $ n_2 = 25 $).\n",
        "8. Оцените $ p $-значение для $ z $-статистики, равной 2.3, и интерпретируйте результат.\n",
        "9. Проверьте гипотезу о том, что доля клиентов, предпочитающих новый продукт, равна 0.5 ($ p_0 = 0.5 $), если из 100 человек 60 ответили \"да\".\n",
        "10. Сгенерируйте выборку из нормального распределения и проверьте гипотезу о её среднем значении.\n",
        "11. Реализуйте процедуру проверки гипотез для дисперсии с помощью распределения хи-квадрат.\n",
        "12. Исследуйте влияние изменения уровня значимости на вероятность ошибок первого и второго рода.\n",
        "13. Постройте графики плотности вероятности для различных квантилей стандартного нормального распределения.\n",
        "14. Реализуйте алгоритм корректировки $ p $-значений с использованием метода FDR.\n",
        "15. Проверьте гипотезу о равенстве двух средних для зависимых выборок с помощью парного $ t $-теста.\n",
        "16. Исследуйте поведение $ t $-статистики при увеличении размера выборки.\n",
        "17. Постройте таблицу критических значений для различных уровней значимости.\n",
        "18. Реализуйте процедуру проверки гипотез для доли с использованием реальных данных.\n",
        "19. Исследуйте влияние выбросов в данных на результаты $ t $-теста.\n",
        "20. Проверьте гипотезу о равенстве двух дисперсий с помощью $ F $-теста.\n",
        "21. Реализуйте процедуру проверки гипотез для многомерных данных.\n",
        "22. Исследуйте влияние формы распределения данных на выбор метода проверки гипотез.\n",
        "23. Проверьте гипотезу о том, что медиана равна заданному значению с помощью бутстреп-метода.\n",
        "24. Реализуйте процедуру проверки гипотез для коэффициента корреляции.\n",
        "25. Исследуйте поведение $ z $-статистики для разных типов распределений.\n",
        "26. Проверьте гипотезу о равенстве трёх или более средних с помощью ANOVA.\n",
        "27. Реализуйте процедуру проверки гипотез для параметров логнормального распределения.\n",
        "28. Исследуйте влияние неоднородности данных на точность проверки гипотез.\n",
        "29. Разработайте алгоритм автоматического выбора подходящего теста для конкретной задачи.\n",
        "30. Проверьте гипотезу о равенстве параметров двух экспоненциальных распределений.\n",
        "\n"
      ],
      "metadata": {
        "id": "ITFqrSmiwRli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**9. Практика Критериев Согласия и Независимости на Python**\n",
        "\n",
        "В этой работе  рассмотрим основные критерии согласия и независимости, которые позволяют проверять гипотезы о распределении данных и выявлять взаимосвязи между переменными. Для каждого метода мы разберем теорию, приведем примеры из реальной жизни, покажем реализацию на Python и дадим детальную интерпретацию результатов.\n",
        "\n",
        "\n",
        "\n",
        "## **1. Критерий согласия $\\chi^2$: Проверка гипотез о виде распределения**\n",
        "\n",
        "### **Что это такое?**\n",
        "Критерий согласия $\\chi^2$ используется для проверки того, соответствует ли эмпирическое распределение данных заданному теоретическому распределению. Этот метод особенно полезен для категориальных переменных, когда данные можно разделить на дискретные категории.\n",
        "\n",
        "### **Теория:**\n",
        "- **Нулевая гипотеза ($H_0$):** Эмпирическое распределение соответствует заданному теоретическому распределению.\n",
        "- **Альтернативная гипотеза ($H_1$):** Эмпирическое распределение не соответствует заданному теоретическому распределению.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "\\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i - E_i)^2}{E_i}\n",
        "$$\n",
        "где:\n",
        "- $ O_i $ — наблюдаемая частота в категории $ i $,\n",
        "- $ E_i $ — ожидаемая частота в категории $ i $,\n",
        "- $ k $ — количество категорий.\n",
        "\n",
        "Статистика $\\chi^2$ следует распределению хи-квадрат с числом степеней свободы $ df = k - 1 $ (где $ k $ — количество категорий).\n",
        "\n",
        "\n",
        "### **Пример из реальной жизни:**\n",
        "Вы исследуете данные о цветах глаз среди группы людей. Известно, что по теории все три цвета (голубые, карие, зелёные) должны встречаться с одинаковой вероятностью. Вы хотите проверить, соответствуют ли ваши данные этой теории.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Исходные данные\n",
        "observed = [40, 50, 10]  # Наблюдаемые частоты\n",
        "total = sum(observed)     # Общее количество наблюдений\n",
        "expected = [total / 3] * 3  # Ожидаемые частоты (равномерное распределение)\n",
        "\n",
        "# Вычисление статистики χ²\n",
        "chi2_stat = sum((np.array(observed) - np.array(expected))**2 / np.array(expected))\n",
        "\n",
        "# Число степеней свободы\n",
        "df = len(observed) - 1\n",
        "\n",
        "# Критическое значение из таблицы χ²-распределения\n",
        "alpha = 0.05\n",
        "critical_value = chi2.ppf(1 - alpha, df)\n",
        "\n",
        "# Решение\n",
        "if chi2_stat > critical_value:\n",
        "    decision = \"Отвергаем нулевую гипотезу\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу\"\n",
        "\n",
        "print(f\"Статистика χ²: {chi2_stat:.2f}, Критическое значение: {critical_value:.2f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### **Интерпретация результатов:**\n",
        "1. **Если статистика $\\chi^2$ больше критического значения:** Мы отвергаем нулевую гипотезу. Это означает, что наблюдаемые данные не соответствуют теоретическому распределению.\n",
        "2. **Если статистика $\\chi^2$ меньше или равна критическому значению:** Мы не можем отвергнуть нулевую гипотезу. Это означает, что данные могут соответствовать теоретическому распределению.\n",
        "\n",
        "\n",
        "\n",
        "## **2. Проверка независимости признаков по критерию $\\chi^2$: Анализ взаимосвязи между категориальными переменными**\n",
        "\n",
        "### **Что это такое?**\n",
        "Критерий $\\chi^2$ для проверки независимости используется для анализа взаимосвязи между двумя категориальными переменными. Этот метод позволяет определить, существует ли статистически значимая связь между переменными.\n",
        "\n",
        "### **Теория:**\n",
        "- **Нулевая гипотеза ($H_0$):** Переменные независимы.\n",
        "- **Альтернативная гипотеза ($H_1$):** Переменные зависимы.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "\\chi^2 = \\sum_{i=1}^{r} \\sum_{j=1}^{c} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
        "$$\n",
        "где:\n",
        "- $ O_{ij} $ — наблюдаемая частота в ячейке $(i, j)$,\n",
        "- $ E_{ij} $ — ожидаемая частота в ячейке $(i, j)$,\n",
        "- $ r $ — количество строк,\n",
        "- $ c $ — количество столбцов.\n",
        "\n",
        "Статистика $\\chi^2$ следует распределению хи-квадрат с числом степеней свободы $ df = (r - 1)(c - 1) $.\n",
        "\n",
        "\n",
        "\n",
        "### **Пример из реальной жизни:**\n",
        "Вы исследуете связь между полом человека и предпочтением определённого типа музыки. Данные представлены в следующей таблице:\n",
        "\n",
        "|           | Рок | Поп | Джаз |\n",
        "|-----------|-----|-----|------|\n",
        "| Мужчины   | 20  | 30  | 10   |\n",
        "| Женщины   | 15  | 25  | 15   |\n",
        "\n",
        "```python\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Исходные данные (таблица сопряженности)\n",
        "data = [[20, 30, 10], [15, 25, 15]]\n",
        "\n",
        "# Вычисление статистики χ²\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
        "\n",
        "# Уровень значимости\n",
        "alpha = 0.05\n",
        "\n",
        "# Решение\n",
        "if p_value < alpha:\n",
        "    decision = \"Отвергаем нулевую гипотезу: переменные зависимы\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу: переменные независимы\"\n",
        "\n",
        "print(f\"Статистика χ²: {chi2_stat:.2f}, P-значение: {p_value:.4f}, Степени свободы: {dof}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### **Интерпретация результатов:**\n",
        "1. **Если $ p $-значение меньше уровня значимости ($ \\alpha = 0.05 $):** Мы отвергаем нулевую гипотезу. Это означает, что переменные зависимы.\n",
        "2. **Если $ p $-значение больше или равно $ \\alpha $:** Мы не можем отвергнуть нулевую гипотезу. Это означает, что переменные независимы.\n",
        "\n",
        "\n",
        "\n",
        "## **3. Критерий Колмогорова: Проверка гипотезы о соответствии выборки заданному распределению**\n",
        "\n",
        "### **Что это такое?**\n",
        "Критерий Колмогорова используется для проверки того, соответствует ли выборка заданному теоретическому распределению. Он основан на максимальном отклонении между эмпирической функцией распределения ($ F_n(x) $) и теоретической функцией распределения ($ F(x) $).\n",
        "\n",
        "### **Теория:**\n",
        "- **Нулевая гипотеза ($H_0$):** Выборка соответствует заданному теоретическому распределению.\n",
        "- **Альтернативная гипотеза ($H_1$):** Выборка не соответствует заданному теоретическому распределению.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "D_n = \\sup_{x \\in \\mathbb{R}} |F(x) - F_n(x)|\n",
        "$$\n",
        "где:\n",
        "- $ F(x) $ — теоретическая функция распределения,\n",
        "- $ F_n(x) $ — эмпирическая функция распределения.\n",
        "\n",
        "Статистика $ D_n $ следует специфическому распределению Колмогорова-Смирнова.\n",
        "\n",
        "\n",
        "### **Пример из реальной жизни:**\n",
        "Вы хотите проверить, соответствует ли ваша выборка стандартному нормальному распределению.\n",
        "\n",
        "```python\n",
        "from scipy.stats import kstest\n",
        "import numpy as np\n",
        "\n",
        "# Исходные данные\n",
        "data = np.random.normal(loc=0, scale=1, size=50)  # Пример выборки\n",
        "\n",
        "# Проверка гипотезы о нормальности\n",
        "statistic, p_value = kstest(data, 'norm')\n",
        "\n",
        "# Уровень значимости\n",
        "alpha = 0.05\n",
        "\n",
        "# Решение\n",
        "if p_value < alpha:\n",
        "    decision = \"Отвергаем нулевую гипотезу: данные не соответствуют нормальному распределению\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу: данные могут соответствовать нормальному распределению\"\n",
        "\n",
        "print(f\"Статистика Колмогорова: {statistic:.4f}, P-значение: {p_value:.4f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "\n",
        "### **Интерпретация результатов:**\n",
        "1. **Если $ p $-значение меньше уровня значимости ($ \\alpha = 0.05 $):** Мы отвергаем нулевую гипотезу. Это означает, что данные не соответствуют нормальному распределению.\n",
        "2. **Если $ p $-значение больше или равно $ \\alpha $:** Мы не можем отвергнуть нулевую гипотезу. Это означает, что данные могут соответствовать нормальному распределению.\n",
        "\n",
        "\n",
        "## **4. Критерий Шапиро-Уилка: Проверка нормальности распределения**\n",
        "\n",
        "### **Что это такое?**\n",
        "Критерий Шапиро-Уилка является одним из самых мощных методов для проверки нормальности распределения, особенно для небольших выборок. Он основывается на линейной регрессии между упорядоченными значениями выборки и соответствующими квантилями нормального распределения.\n",
        "\n",
        "### **Теория:**\n",
        "- **Нулевая гипотеза ($H_0$):** Выборка соответствует нормальному распределению.\n",
        "- **Альтернативная гипотеза ($H_1$):** Выборка не соответствует нормальному распределению.\n",
        "\n",
        "\n",
        "\n",
        "### **Пример из реальной жизни:**\n",
        "Вы анализируете данные о росте сотрудников компании и хотите проверить, являются ли они нормально распределёнными.\n",
        "\n",
        "```python\n",
        "from scipy.stats import shapiro\n",
        "import numpy as np\n",
        "\n",
        "# Исходные данные\n",
        "data = np.random.normal(loc=0, scale=1, size=30)  # Пример выборки\n",
        "\n",
        "# Проверка нормальности\n",
        "statistic, p_value = shapiro(data)\n",
        "\n",
        "# Уровень значимости\n",
        "alpha = 0.05\n",
        "\n",
        "# Решение\n",
        "if p_value < alpha:\n",
        "    decision = \"Отвергаем нулевую гипотезу: данные не являются нормально распределёнными\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу: данные могут быть нормально распределёнными\"\n",
        "\n",
        "print(f\"Статистика Шапиро-Уилка: {statistic:.4f}, P-значение: {p_value:.4f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "\n",
        "### **Интерпретация результатов:**\n",
        "1. **Если $ p $-значение меньше уровня значимости ($ \\alpha = 0.05 $):** Мы отвергаем нулевую гипотезу. Это означает, что данные не являются нормально распределёнными.\n",
        "2. **Если $ p $-значение больше или равно $ \\alpha $:** Мы не можем отвергнуть нулевую гипотезу. Это означает, что данные могут быть нормально распределёнными.\n",
        "\n",
        "\n",
        "\n",
        "## **5. Критерий Андерсена-Дарлинга: Альтернатива критерию Колмогорова**\n",
        "\n",
        "### **Что это такое?**\n",
        "Критерий Андерсена-Дарлинга более чувствителен к хвостам распределения, чем критерий Колмогорова. Это делает его особенно полезным, когда важно учитывать особенности распределения в хвостах.\n",
        "\n",
        "### **Теория:**\n",
        "- **Нулевая гипотеза ($H_0$):** Выборка соответствует заданному теоретическому распределению.\n",
        "- **Альтернативная гипотеза ($H_1$):** Выборка не соответствует заданному теоретическому распределению.\n",
        "\n",
        "Статистика теста учитывает как центральные части распределения, так и его хвосты.\n",
        "\n",
        "\n",
        "\n",
        "### **Пример из реальной жизни:**\n",
        "Вы хотите проверить, соответствует ли выборка нормальному распределению, уделяя особое внимание хвостам распределения.\n",
        "\n",
        "```python\n",
        "from scipy.stats import anderson\n",
        "import numpy as np\n",
        "\n",
        "# Исходные данные\n",
        "data = np.random.normal(loc=0, scale=1, size=50)  # Пример выборки\n",
        "\n",
        "# Проверка нормальности\n",
        "result = anderson(data, dist='norm')\n",
        "\n",
        "# Уровень значимости\n",
        "alpha = 0.05\n",
        "\n",
        "# Решение\n",
        "if result.significance_level[2] < alpha:\n",
        "    decision = \"Отвергаем нулевую гипотезу: данные не соответствуют нормальному распределению\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу: данные могут соответствовать нормальному распределению\"\n",
        "\n",
        "print(f\"Статистика Андерсена-Дарлинга: {result.statistic:.4f}, Критические значения: {result.critical_values}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### **Интерпретация результатов:**\n",
        "1. **Если статистика теста превышает одно из критических значений:** Мы отвергаем нулевую гипотезу. Это означает, что данные не соответствуют нормальному распределению.\n",
        "2. **Если статистика теста меньше или равна всем критическим значениям:** Мы не можем отвергнуть нулевую гипотезу. Это означает, что данные могут соответствовать нормальному распределению.\n",
        "\n",
        "\n",
        "\n",
        "## **6. Сравнение Критериев Согласия**\n",
        "\n",
        "Чтобы лучше понять различия между критериями, давайте сравним их на одном примере.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy.stats import kstest, shapiro, anderson\n",
        "\n",
        "# Исходные данные\n",
        "data = np.random.normal(loc=0, scale=1, size=50)  # Пример выборки\n",
        "\n",
        "# Критерий Колмогорова\n",
        "ks_stat, ks_pvalue = kstest(data, 'norm')\n",
        "print(f\"Критерий Колмогорова: Статистика = {ks_stat:.4f}, P-значение = {ks_pvalue:.4f}\")\n",
        "\n",
        "# Критерий Шапиро-Уилка\n",
        "sw_stat, sw_pvalue = shapiro(data)\n",
        "print(f\"Критерий Шапиро-Уилка: Статистика = {sw_stat:.4f}, P-значение = {sw_pvalue:.4f}\")\n",
        "\n",
        "# Критерий Андерсена-Дарлинга\n",
        "ad_result = anderson(data, dist='norm')\n",
        "print(f\"Критерий Андерсена-Дарлинга: Статистика = {ad_result.statistic:.4f}, Критические значения = {ad_result.critical_values}\")\n",
        "```\n",
        "\n",
        "\n",
        "### **Интерпретация результатов:**\n",
        "1. **Критерий Колмогорова:** Даёт общее представление о соответствии выборки заданному распределению.\n",
        "2. **Критерий Шапиро-Уилка:** Наиболее эффективен для малых выборок.\n",
        "3. **Критерий Андерсена-Дарлинга:** Чувствителен к хвостам распределения.\n",
        "\n",
        "\n",
        "\n",
        "## **Вопросы для самопроверки**\n",
        "\n",
        "1. Что такое критерий согласия $\\chi^2$ и для чего он используется?\n",
        "2. Какая формула применяется для вычисления статистики $\\chi^2$ в тесте на соответствие распределению?\n",
        "3. Как интерпретировать результаты теста $\\chi^2$, если полученная статистика больше критического значения?\n",
        "4. Что проверяет критерий Колмогорова-Смирнова?\n",
        "5. В каких случаях рекомендуется использовать критерий Шапиро-Уилка вместо других методов проверки нормальности?\n",
        "6. Как определяются ожидаемые частоты в тесте $\\chi^2$ для проверки независимости признаков?\n",
        "7. Какие предположения делаются о данных при использовании критерия $\\chi^2$?\n",
        "8. Что такое степень свободы в контексте теста $\\chi^2$?\n",
        "9. Как влияет размер выборки на точность результатов теста $\\chi^2$?\n",
        "10. Как интерпретировать $p$-значение в тестах на соответствие распределению?\n",
        "11. Какой метод более чувствителен к хвостам распределения: критерий Колмогорова или критерий Андерсена-Дарлинга?\n",
        "12. Для каких типов данных используется тест $\\chi^2$ на независимость?\n",
        "13. Что такое эмпирическая функция распределения?\n",
        "14. Какую роль играет гипотетическое распределение в тесте Колмогорова-Смирнова?\n",
        "15. Как определить количество степеней свободы для теста $\\chi^2$ с категориальными данными?\n",
        "16. Какие альтернативные методы существуют для проверки нормальности распределения помимо критерия Шапиро-Уилка?\n",
        "17. Какие ограничения есть у теста $\\chi^2$ для малых выборок?\n",
        "18. Почему важно проверять предположение о независимости наблюдений перед применением теста $\\chi^2$?\n",
        "19. Как интерпретировать результаты теста $\\chi^2$, если $p$-значение меньше заданного уровня значимости?\n",
        "20. Какие практические применения имеют критерии согласия в реальной жизни?\n",
        "21. Какой модуль Python можно использовать для реализации теста $\\chi^2$?\n",
        "22. Какой модуль Python помогает выполнять тест Колмогорова-Смирнова?\n",
        "23. Какой модуль Python используется для теста Шапиро-Уилка?\n",
        "24. Какие данные подходят для анализа с помощью теста $\\chi^2$ на независимость?\n",
        "25. Как влияет количество категорий на результаты теста $\\chi^2$?\n",
        "26. Какие проблемы могут возникнуть при использовании теста $\\chi^2$ для небольших выборок?\n",
        "27. Как интерпретировать критические значения в тесте Колмогорова-Смирнова?\n",
        "28. Какие параметры можно оценить с помощью теста $\\chi^2$?\n",
        "29. Как выбрать подходящий метод проверки соответствия распределению для конкретной задачи?\n",
        "30. Какие современные инструменты Python помогают выполнять критерии согласия?\n",
        "\n",
        "\n",
        "\n",
        "## **Задачи для самостоятельной работы**\n",
        "\n",
        "1. Проверьте гипотезу о том, что распределение цветов глаз (голубые, карие, зелёные) в выборке из 100 человек соответствует равномерному распределению ($H_0$: все три цвета встречаются с одинаковой вероятностью).\n",
        "2. Исследуйте связь между полом человека и предпочтением музыкальных жанров (рок, поп, джаз) с помощью теста $\\chi^2$ на независимость.\n",
        "3. Сгенерируйте выборку из стандартного нормального распределения и проверьте её на нормальность с помощью теста Колмогорова-Смирнова.\n",
        "4. Реализуйте процедуру проверки нормальности выборки с помощью критерия Шапиро-Уилка.\n",
        "5. Используя тест $\\chi^2$, проверьте гипотезу о том, что распределение баллов студентов по трём экзаменам соответствует нормальному распределению.\n",
        "6. Исследуйте зависимость между возрастом и уровнем дохода с помощью теста $\\chi^2$ на независимость.\n",
        "7. Проверьте гипотезу о том, что выборка из экспоненциального распределения действительно соответствует этому распределению с помощью теста Колмогорова-Смирнова.\n",
        "8. Оцените нормальность распределения данных о росте людей с помощью критерия Андерсена-Дарлинга.\n",
        "9. Постройте таблицу сопряженности для двух категориальных переменных и выполните тест $\\chi^2$ на независимость.\n",
        "10. Сравните результаты тестов Колмогорова-Смирнова, Шапиро-Уилка и Андерсена-Дарлинга для одной и той же выборки.\n",
        "11. Исследуйте влияние изменения размера выборки на результаты теста $\\chi^2$.\n",
        "12. Проверьте гипотезу о том, что распределение времени выполнения задачи соответствует нормальному распределению.\n",
        "13. Реализуйте алгоритм автоматического выбора подходящего теста для проверки соответствия распределению.\n",
        "14. Исследуйте влияние выбросов в данных на результаты теста $\\chi^2$.\n",
        "15. Проверьте гипотезу о том, что распределение ответов на анкету соответствует заданному теоретическому распределению.\n",
        "16. Реализуйте процедуру проверки нормальности выборки с использованием нескольких методов.\n",
        "17. Исследуйте зависимость между двумя категориальными переменными с помощью теста $\\chi^2$ на независимость.\n",
        "18. Проверьте гипотезу о том, что выборка из равномерного распределения действительно соответствует этому распределению.\n",
        "19. Реализуйте процедуру корректировки $p$-значений для множественных сравнений с использованием метода Бонферрони.\n",
        "20. Исследуйте влияние формы распределения данных на результаты теста Колмогорова-Смирнова.\n",
        "21. Проверьте гипотезу о том, что распределение баллов студентов по курсу соответствует нормальному распределению.\n",
        "22. Реализуйте процедуру проверки нормальности выборки с использованием критерия Лиллифорса.\n",
        "23. Исследуйте зависимость между двумя количественными переменными с помощью теста $\\chi^2$ на независимость после их дискретизации.\n",
        "24. Проверьте гипотезу о том, что распределение времени обслуживания клиентов соответствует экспоненциальному распределению.\n",
        "25. Реализуйте процедуру проверки нормальности выборки с использованием графического метода QQ-plot.\n",
        "26. Исследуйте влияние неоднородности данных на результаты теста $\\chi^2$.\n",
        "27. Проверьте гипотезу о том, что распределение температур воздуха соответствует нормальному распределению.\n",
        "28. Реализуйте процедуру автоматического выбора подходящего теста для проверки независимости между переменными.\n",
        "29. Исследуйте влияние изменения числа категорий на результаты теста $\\chi^2$.\n",
        "30. Разработайте алгоритм сравнения результатов различных критериев согласия для одной и той же выборки.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-YWokXUk6yCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10. Практика Однофакторной Линейной Регрессии на Python**\n",
        "\n",
        "## **1. Однофакторная линейная регрессия: Модель и Оценка Параметров**\n",
        "\n",
        "### **Что такое линейная регрессия?**\n",
        "Линейная регрессия — это метод статистического анализа, который помогает найти зависимость между двумя переменными. Этот метод широко используется для прогнозирования значений одной переменной (зависимой) на основе другой переменной (независимой). Например, мы можем использовать его для того, чтобы понять, как количество часов учебы влияет на результат экзамена.\n",
        "\n",
        "#### **Основные термины:**\n",
        "- **Независимая переменная ($x$):** Переменная, которая предположительно оказывает влияние на другую переменную. Например, количество часов, потраченных на подготовку к экзамену.\n",
        "- **Зависимая переменная ($Y$):** Переменная, значение которой мы хотим предсказать или объяснить. Например, оценка за экзамен.\n",
        "- **Модель:** Линейная регрессия строится в виде прямой линии, которая наилучшим образом описывает взаимосвязь между $x$ и $Y$.\n",
        "\n",
        "### **Математическая модель:**\n",
        "Математически однофакторная линейная регрессия описывается следующим уравнением:\n",
        "$$\n",
        "Y = \\theta_0 + \\theta_1 x + \\varepsilon,\n",
        "$$\n",
        "где:\n",
        "- $Y$ — зависимая переменная (например, оценка за экзамен),\n",
        "- $x$ — независимая переменная (например, количество часов учебы),\n",
        "- $\\theta_0$ — свободный член (пересечение прямой с осью $Y$, показывает базовое значение $Y$, когда $x = 0$),\n",
        "- $\\theta_1$ — коэффициент наклона (показывает, насколько изменяется $Y$ при единичном изменении $x$),\n",
        "- $\\varepsilon$ — случайная ошибка (учитывает всё, что модель не может объяснить).\n",
        "\n",
        "#### **Пример:**\n",
        "Предположим, что вы хотите узнать, как количество часов учебы ($x$) влияет на результат экзамена ($Y$). Если $\\theta_1 = 0.8$, это означает, что каждое дополнительное час учебы увеличивает ожидаемый результат экзамена на 0.8 балла. Если $\\theta_0 = 1.2$, то даже без учебы ($x = 0$) можно ожидать начальный результат в 1.2 балла.\n",
        "\n",
        "\n",
        "### **Как находятся параметры модели?**\n",
        "Для определения параметров $\\theta_0$ и $\\theta_1$ используется **метод наименьших квадратов (МНК)**. Этот метод минимизирует сумму квадратов ошибок между реальными значениями $y_i$ и предсказанными значениями $\\hat{y}_i = \\theta_0 + \\theta_1 x_i$.\n",
        "\n",
        "#### **Формулы для оценки параметров:**\n",
        "1. Коэффициент наклона ($\\hat{\\theta}_1$):\n",
        "$$\n",
        "\\hat{\\theta}_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2},\n",
        "$$\n",
        "где:\n",
        "- $x_i$ и $y_i$ — конкретные наблюдения,\n",
        "- $\\bar{x}$ и $\\bar{y}$ — средние значения переменных $x$ и $y$ соответственно.\n",
        "\n",
        "2. Свободный член ($\\hat{\\theta}_0$):\n",
        "$$\n",
        "\\hat{\\theta}_0 = \\bar{y} - \\hat{\\theta}_1 \\bar{x}.\n",
        "$$\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Исходные данные\n",
        "x = np.array([1, 2, 3, 4, 5])  # Независимая переменная (часы учебы)\n",
        "y = np.array([2, 4, 5, 4, 6])  # Зависимая переменная (оценка за экзамен)\n",
        "\n",
        "# Вычисление средних значений\n",
        "x_mean = np.mean(x)\n",
        "y_mean = np.mean(y)\n",
        "\n",
        "# Вычисление коэффициентов\n",
        "numerator = np.sum((x - x_mean) * (y - y_mean))  # Числитель для θ_1\n",
        "denominator = np.sum((x - x_mean)**2)            # Знаменатель для θ_1\n",
        "theta_1 = numerator / denominator  # Коэффициент наклона\n",
        "theta_0 = y_mean - theta_1 * x_mean  # Свободный член\n",
        "\n",
        "print(f\"Оценка θ_0 (свободный член): {theta_0:.4f}\")\n",
        "print(f\"Оценка θ_1 (коэффициент наклона): {theta_1:.4f}\")\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Если $\\theta_1 = 0.8$, это означает, что при увеличении количества часов учебы на 1 час, оценка за экзамен увеличивается в среднем на 0.8 балла.\n",
        "- Если $\\theta_0 = 1.2$, это означает, что при нулевом количестве часов учебы ожидаемая оценка составляет 1.2 балла.\n",
        "\n",
        "\n",
        "\n",
        "## **2. Статистические свойства оценок $\\hat{\\theta}_0$ и $\\hat{\\theta}_1$**\n",
        "\n",
        "### **Несмещенность:**\n",
        "Оценки $\\hat{\\theta}_0$ и $\\hat{\\theta}_1$, полученные методом наименьших квадратов, являются **несмещенными**, что означает, что их математическое ожидание равно истинным значениям параметров:\n",
        "$$\n",
        "E(\\hat{\\theta}_0) = \\theta_0, \\quad E(\\hat{\\theta}_1) = \\theta_1.\n",
        "$$\n",
        "Это важное свойство гарантирует, что наши оценки не систематически завышают или занижают истинные значения параметров.\n",
        "\n",
        "### **Распределение оценок:**\n",
        "Если ошибки $\\varepsilon$ распределены нормально, то оценки $\\hat{\\theta}_0$ и $\\hat{\\theta}_1$ также имеют нормальное распределение. Это позволяет нам использовать статистические тесты для проверки гипотез.\n",
        "\n",
        "#### **Распределение коэффициента наклона ($\\hat{\\theta}_1$):**\n",
        "$$\n",
        "\\hat{\\theta}_1 \\sim N\\left(\\theta_1, \\frac{\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\\right),\n",
        "$$\n",
        "где:\n",
        "- $\\sigma^2$ — дисперсия ошибок,\n",
        "- $\\sum_{i=1}^n (x_i - \\bar{x})^2$ — сумма квадратов отклонений $x_i$ от среднего значения.\n",
        "\n",
        "#### **Распределение свободного члена ($\\hat{\\theta}_0$):**\n",
        "$$\n",
        "\\hat{\\theta}_0 \\sim N\\left(\\theta_0, \\sigma^2 \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\\right)\\right).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## **3. Проверка гипотезы о значимости коэффициента регрессии ($\\theta_1 = 0$)**\n",
        "\n",
        "### **Зачем проверять гипотезу?**\n",
        "Цель проверки заключается в том, чтобы определить, действительно ли независимая переменная ($x$) оказывает значимое влияние на зависимую переменную ($Y$). Для этого мы тестируем следующие гипотезы:\n",
        "- $H_0: \\theta_1 = 0$ (переменная $x$ не влияет на $Y$),\n",
        "- $H_1: \\theta_1 \\neq 0$ (переменная $x$ влияет на $Y$).\n",
        "\n",
        "Если мы отвергаем нулевую гипотезу, это значит, что существует статистически значимая связь между $x$ и $Y$.\n",
        "\n",
        "### **Статистика теста:**\n",
        "Для проверки гипотезы используется $t$-статистика:\n",
        "$$\n",
        "t = \\frac{\\hat{\\theta}_1}{\\text{SE}(\\hat{\\theta}_1)},\n",
        "$$\n",
        "где:\n",
        "- $\\hat{\\theta}_1$ — оценка коэффициента наклона,\n",
        "- $\\text{SE}(\\hat{\\theta}_1)$ — стандартная ошибка коэффициента наклона.\n",
        "\n",
        "#### **Вычисление стандартной ошибки ($\\text{SE}(\\hat{\\theta}_1)$):**\n",
        "$$\n",
        "\\text{SE}(\\hat{\\theta}_1) = \\sqrt{\\frac{\\text{RSS}}{n-2} \\cdot \\frac{1}{\\sum_{i=1}^n (x_i - \\bar{x})^2}},\n",
        "$$\n",
        "где:\n",
        "- $\\text{RSS} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$ — остаточная сумма квадратов,\n",
        "- $n$ — количество наблюдений.\n",
        "\n",
        "$t$-статистика следует распределению Стьюдента с $n-2$ степенями свободы.\n",
        "\n",
        "\n",
        "### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import t\n",
        "\n",
        "# Вычисление RSS\n",
        "y_pred = theta_0 + theta_1 * x\n",
        "rss = np.sum((y - y_pred)**2)\n",
        "\n",
        "# Вычисление стандартной ошибки для θ_1\n",
        "se_theta_1 = np.sqrt(rss / (len(x) - 2) / np.sum((x - x_mean)**2))\n",
        "\n",
        "# Вычисление t-статистики\n",
        "t_stat = theta_1 / se_theta_1\n",
        "\n",
        "# Критическое значение t\n",
        "alpha = 0.05\n",
        "df = len(x) - 2\n",
        "critical_value = t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "# Решение\n",
        "if abs(t_stat) > critical_value:\n",
        "    decision = \"Отвергаем нулевую гипотезу: коэффициент значим\"\n",
        "else:\n",
        "    decision = \"Не отвергаем нулевую гипотезу: коэффициент не значим\"\n",
        "\n",
        "print(f\"T-статистика: {t_stat:.4f}, Критическое значение: {critical_value:.4f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "\n",
        "### **Интерпретация результата:**\n",
        "- Если $|t|$ больше критического значения, мы отвергаем нулевую гипотезу и делаем вывод, что переменная $x$ имеет значимое влияние на $Y$.\n",
        "- Если $|t|$ меньше критического значения, мы не можем отвергнуть нулевую гипотезу, что указывает на отсутствие статистически значимой связи.\n",
        "\n",
        "\n",
        "## **4. Коэффициент детерминации ($ R^2 $): Измерение качества модели**\n",
        "\n",
        "### **Что такое $ R^2 $?**\n",
        "Коэффициент детерминации $ R^2 $ — это ключевой показатель, который позволяет оценить, насколько хорошо модель линейной регрессии объясняет вариацию зависимой переменной ($ Y $). Он показывает долю общей дисперсии данных, которая объяснена моделью.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}},\n",
        "$$\n",
        "где:\n",
        "- $ \\text{RSS} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $ — остаточная сумма квадратов (показывает ошибку модели),\n",
        "- $ \\text{TSS} = \\sum_{i=1}^n (y_i - \\bar{y})^2 $ — общая сумма квадратов (показывает общую вариацию данных).\n",
        "\n",
        "#### **Интерпретация:**\n",
        "- Если $ R^2 = 1 $, модель идеально объясняет данные.\n",
        "- Если $ R^2 = 0 $, модель не объясняет данные лучше, чем среднее значение $ Y $.\n",
        "- Значения между 0 и 1 показывают, какую часть вариации данных объясняет модель.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "# Вычисление TSS\n",
        "tss = np.sum((y - y_mean)**2)\n",
        "\n",
        "# Вычисление RSS\n",
        "rss = np.sum((y - y_pred)**2)\n",
        "\n",
        "# Вычисление R^2\n",
        "r_squared = 1 - rss / tss\n",
        "\n",
        "print(f\"Коэффициент детерминации (R^2): {r_squared:.4f}\")\n",
        "```\n",
        "\n",
        "#### **Практическая интерпретация:**\n",
        "Например, если $ R^2 = 0.85 $, это означает, что модель объясняет 85% вариации в данных. Чем ближе $ R^2 $ к 1, тем лучше модель подходит для данных.\n",
        "\n",
        "\n",
        "## **5. Диагностика Модели**\n",
        "\n",
        "### **Зачем нужна диагностика?**\n",
        "Диагностика модели помогает проверить, соответствуют ли данные предположениям линейной регрессии. Это важно для обеспечения корректности выводов и надежности прогнозов.\n",
        "\n",
        "#### **Основные предположения:**\n",
        "1. **Линейность:** Отношение между независимой переменной ($ x $) и зависимой переменной ($ Y $) должно быть линейным.\n",
        "2. **Гомоскедастичность:** Остатки должны иметь постоянную дисперсию (не зависеть от значений $ x $).\n",
        "3. **Нормальность:** Остатки должны быть нормально распределены.\n",
        "4. **Отсутствие автокорреляции:** Остатки не должны быть взаимосвязаны.\n",
        "\n",
        "#### **Графический анализ:**\n",
        "1. **График остатков vs предсказанных значений:**\n",
        "   Этот график помогает проверить гомоскедастичность. Если остатки равномерно распределены вокруг нуля без видимых шаблонов, предположение выполняется.\n",
        "\n",
        "   ```python\n",
        "   import matplotlib.pyplot as plt\n",
        "\n",
        "   # Остатки\n",
        "   residuals = y - y_pred\n",
        "\n",
        "   # График остатков vs предсказанных значений\n",
        "   plt.scatter(y_pred, residuals)\n",
        "   plt.axhline(0, color='red', linestyle='--')\n",
        "   plt.xlabel(\"Предсказанные значения\")\n",
        "   plt.ylabel(\"Остатки\")\n",
        "   plt.title(\"Анализ гомоскедастичности\")\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "2. **Q-Q график для проверки нормальности:**\n",
        "   Q-Q график сравнивает распределение остатков с нормальным распределением. Если точки лежат близко к прямой, остатки нормально распределены.\n",
        "\n",
        "   ```python\n",
        "   from scipy.stats import probplot\n",
        "\n",
        "   # Q-Q график для остатков\n",
        "   probplot(residuals, plot=plt)\n",
        "   plt.title(\"Q-Q график для остатков\")\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "#### **Статистические тесты:**\n",
        "- Для проверки гомоскедастичности можно использовать тест Бреуша-Пагана или тест Уайта.\n",
        "- Для проверки нормальности можно использовать тест Шапиро-Уилка или тест Колмогорова-Смирнова.\n",
        "\n",
        "\n",
        "## **6. Прогнозирование с Доверительными Интервалами**\n",
        "\n",
        "### **Как сделать прогноз?**\n",
        "После построения модели мы можем использовать её для прогнозирования новых значений. Для нового значения $ x_{\\text{new}} $ предсказанное значение $ \\hat{y}_{\\text{new}} $ вычисляется по формуле:\n",
        "$$\n",
        "\\hat{y}_{\\text{new}} = \\hat{\\theta}_0 + \\hat{\\theta}_1 x_{\\text{new}}.\n",
        "$$\n",
        "\n",
        "### **Доверительный интервал:**\n",
        "Доверительный интервал показывает диапазон, в котором с заданной вероятностью (например, 95%) находится истинное значение $ Y $. Он учитывает как ошибку модели, так и изменчивость данных.\n",
        "\n",
        "#### **Формула доверительного интервала:**\n",
        "$$\n",
        "\\hat{y}_{\\text{new}} \\pm t_{\\alpha/2, n-2} \\cdot \\text{SE}_{\\text{pred}},\n",
        "$$\n",
        "где:\n",
        "- $ \\text{SE}_{\\text{pred}} = \\sqrt{\\text{MSE} \\cdot \\left(1 + \\frac{1}{n} + \\frac{(x_{\\text{new}} - \\bar{x})^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\\right)} $,\n",
        "- $ \\text{MSE} = \\frac{\\text{RSS}}{n-2} $ — средняя квадратическая ошибка,\n",
        "- $ t_{\\alpha/2, n-2} $ — критическое значение из распределения Стьюдента с $ n-2 $ степенями свободы.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "# Новое значение x\n",
        "x_new = 3\n",
        "\n",
        "# Предсказание\n",
        "y_new_pred = theta_0 + theta_1 * x_new\n",
        "\n",
        "# Вычисление стандартной ошибки для прогноза\n",
        "mse = rss / (len(x) - 2)\n",
        "se_pred = np.sqrt(mse * (1 + 1/len(x) + ((x_new - x_mean)**2 / np.sum((x - x_mean)**2))))\n",
        "\n",
        "# Доверительный интервал\n",
        "confidence_level = 0.95\n",
        "df = len(x) - 2\n",
        "t_critical = t.ppf(1 - (1 - confidence_level) / 2, df)\n",
        "\n",
        "lower_bound = y_new_pred - t_critical * se_pred\n",
        "upper_bound = y_new_pred + t_critical * se_pred\n",
        "\n",
        "print(f\"Прогноз для x={x_new}: {y_new_pred:.4f}\")\n",
        "print(f\"Доверительный интервал ({confidence_level*100}%): [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
        "```\n",
        "\n",
        "#### **Интерпретация результата:**\n",
        "Например, если прогноз для $ x = 3 $ равен 5.2, а 95%-ый доверительный интервал составляет [4.8, 5.6], это означает, что с вероятностью 95% истинное значение $ Y $ для $ x = 3 $ лежит в этом диапазоне.\n",
        "\n",
        "\n",
        "## **Вопросы для самопроверки**\n",
        "\n",
        "1. Что такое линейная регрессия, и как она используется в статистике?\n",
        "2. Какие основные компоненты входят в уравнение линейной регрессии?\n",
        "3. Что обозначают параметры $\\theta_0$ и $\\theta_1$ в модели линейной регрессии?\n",
        "4. Какой метод используется для нахождения оптимальных значений параметров $\\theta_0$ и $\\theta_1$?\n",
        "5. Что такое метод наименьших квадратов (МНК), и как он применяется в линейной регрессии?\n",
        "6. Как вычисляется коэффициент наклона ($\\hat{\\theta}_1$) в модели линейной регрессии?\n",
        "7. Как вычисляется свободный член ($\\hat{\\theta}_0$) в модели линейной регрессии?\n",
        "8. Что такое несмещенность оценок $\\hat{\\theta}_0$ и $\\hat{\\theta}_1$, и почему это свойство важно?\n",
        "9. Какое распределение имеют оценки $\\hat{\\theta}_0$ и $\\hat{\\theta}_1$, если ошибки нормально распределены?\n",
        "10. Для чего используется $t$-статистика при проверке гипотезы о значимости коэффициента регрессии?\n",
        "11. Как интерпретировать результаты проверки гипотезы $H_0: \\theta_1 = 0$?\n",
        "12. Что такое коэффициент детерминации ($R^2$), и как его можно интерпретировать?\n",
        "13. Какие предположения делает модель линейной регрессии о данных?\n",
        "14. Что такое гомоскедастичность, и как её проверить?\n",
        "15. Какие графические инструменты используются для диагностики модели линейной регрессии?\n",
        "16. Что показывает Q-Q график в контексте анализа остатков?\n",
        "17. Какие статистические тесты могут быть использованы для проверки нормальности остатков?\n",
        "18. Что такое доверительный интервал для прогноза в линейной регрессии?\n",
        "19. Как влияет размер выборки на точность оценок параметров в линейной регрессии?\n",
        "20. Какую роль играет стандартная ошибка ($SE$) в построении доверительных интервалов?\n",
        "21. Как интерпретировать значение $R^2 = 0.9$ в модели линейной регрессии?\n",
        "22. Что делать, если предположение о линейности не выполняется?\n",
        "23. Какие проблемы могут возникнуть при нарушении предположения о гомоскедастичности?\n",
        "24. Какие альтернативные методы существуют для оценивания параметров регрессии помимо МНК?\n",
        "25. Как влияет наличие выбросов на результаты линейной регрессии?\n",
        "26. Что такое автокорреляция остатков, и как её можно обнаружить?\n",
        "27. Какие практические применения имеет линейная регрессия в реальной жизни?\n",
        "28. Какие ограничения есть у модели линейной регрессии?\n",
        "29. Какие современные инструменты Python помогают выполнять анализ линейной регрессии?\n",
        "30. Как выбрать подходящий уровень значимости ($\\alpha$) для проверки гипотез в регрессионном анализе?\n",
        "\n",
        "\n",
        "## **Задачи для самостоятельной работы**\n",
        "\n",
        "1. Используя данные о количестве часов учебы ($x$) и результатах экзамена ($Y$), постройте модель линейной регрессии и найдите значения параметров $\\hat{\\theta}_0$ и $\\hat{\\theta}_1$.\n",
        "2. Проверьте гипотезу о значимости коэффициента регрессии ($H_0: \\theta_1 = 0$) для данных из задачи 1.\n",
        "3. Вычислите коэффициент детерминации ($R^2$) для модели из задачи 1 и интерпретируйте результат.\n",
        "4. Постройте график остатков vs предсказанных значений для модели из задачи 1 и проверьте гомоскедастичность.\n",
        "5. Создайте Q-Q график для остатков модели из задачи 1 и проверьте их нормальность.\n",
        "6. Сгенерируйте синтетические данные для линейной регрессии и постройте соответствующую модель.\n",
        "7. Добавьте выбросы в данные из задачи 6 и проанализируйте их влияние на результаты модели.\n",
        "8. Постройте доверительный интервал для прогноза нового значения $Y$ при заданном $x_{\\text{new}}$.\n",
        "9. Исследуйте влияние изменения размера выборки на точность оценок параметров модели.\n",
        "10. Реализуйте процедуру проверки гомоскедастичности с помощью теста Бреуша-Пагана.\n",
        "11. Проверьте нормальность остатков с помощью теста Шапиро-Уилка.\n",
        "12. Постройте модель линейной регрессии для реальных данных (например, оценки за экзамен в зависимости от времени подготовки).\n",
        "13. Исследуйте зависимость между двумя переменными с помощью линейной регрессии и проинтерпретируйте результаты.\n",
        "14. Реализуйте алгоритм МНК \"с нуля\" на Python для оценки параметров модели.\n",
        "15. Постройте несколько моделей линейной регрессии для разных наборов данных и сравните их $R^2$.\n",
        "16. Исследуйте влияние масштабирования данных на результаты модели линейной регрессии.\n",
        "17. Постройте модель линейной регрессии для данных с нелинейной зависимостью и проанализируйте ошибки.\n",
        "18. Реализуйте процедуру автоматического выбора подходящего уровня значимости ($\\alpha$) для проверки гипотез.\n",
        "19. Исследуйте влияние добавления дополнительных переменных на качество модели линейной регрессии.\n",
        "20. Постройте доверительные интервалы для параметров модели линейной регрессии.\n",
        "21. Реализуйте процедуру проверки автокорреляции остатков с помощью теста Дарбина-Уотсона.\n",
        "22. Исследуйте влияние различных уровней шума в данных на результаты модели линейной регрессии.\n",
        "23. Постройте модель линейной регрессии для многомерных данных и проанализируйте результаты.\n",
        "24. Реализуйте процедуру кросс-валидации для оценки качества модели линейной регрессии.\n",
        "25. Исследуйте влияние удаления выбросов на результаты модели линейной регрессии.\n",
        "26. Постройте модель линейной регрессии для данных с явным нарушением предположения о линейности и предложите способы исправления.\n",
        "27. Реализуйте процедуру построения нескольких моделей линейной регрессии и сравните их качество с помощью критериев AIC и BIC.\n",
        "28. Исследуйте влияние коррелированных переменных на результаты модели линейной регрессии.\n",
        "29. Постройте модель линейной регрессии для данных с неоднородной дисперсией и предложите способы исправления.\n",
        "30. Разработайте алгоритм автоматического выбора лучших параметров модели линейной регрессии для конкретной задачи.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MKwuCSfZMBWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **11. Практика Множественной Линейной Регрессии на Python**\n",
        "\n",
        "### **1. Модель множественной линейной регрессии**\n",
        "\n",
        "#### **Что такое множественная линейная регрессия?**\n",
        "Множественная линейная регрессия — это расширение однофакторной линейной регрессии, которое позволяет учитывать влияние нескольких независимых переменных ($x_1, x_2, \\dots, x_d$) на одну зависимую переменную ($y$). Этот метод особенно полезен, когда результат зависит от нескольких факторов, например:\n",
        "- Цена дома может зависеть от площади, количества спален, возраста дома и местоположения.\n",
        "- Продажи товара могут зависеть от цены, рекламного бюджета и сезона.\n",
        "\n",
        "Модель стремится найти оптимальные коэффициенты ($w_0, w_1, \\dots, w_d$), которые минимизируют ошибку между предсказанными и реальными значениями $y$.\n",
        "\n",
        "#### **Формула модели:**\n",
        "$$\n",
        "y = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_d x_d + \\varepsilon,\n",
        "$$\n",
        "где:\n",
        "- $y$ — зависимая переменная (например, цена дома),\n",
        "- $x_1, x_2, \\dots, x_d$ — независимые переменные (например, площадь дома, количество спален, возраст дома),\n",
        "- $w_0, w_1, \\dots, w_d$ — параметры модели (коэффициенты),\n",
        "- $\\varepsilon$ — случайная ошибка (учитывает всё, что модель не смогла объяснить).\n",
        "\n",
        "#### **Задача:**\n",
        "Наша цель — найти такие параметры $w_0, w_1, \\dots, w_d$, чтобы минимизировать разницу между предсказанными ($\\hat{y}$) и реальными ($y$) значениями.\n",
        "\n",
        "\n",
        "\n",
        "### **2. Метод Наименьших Квадратов**\n",
        "\n",
        "#### **Идея метода:**\n",
        "Метод наименьших квадратов (МНК) — это классический подход для оценки параметров модели. Он находит такие значения параметров, при которых сумма квадратов ошибок минимальна:\n",
        "$$\n",
        "\\text{RSS} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2,\n",
        "$$\n",
        "где:\n",
        "- $y_i$ — реальное значение,\n",
        "- $\\hat{y}_i = w_0 + w_1 x_{i1} + w_2 x_{i2} + \\dots + w_d x_{id}$ — предсказанное значение.\n",
        "\n",
        "Минимизация этой функции приводит к следующей формуле для параметров:\n",
        "$$\n",
        "\\hat{w} = (X^T X)^{-1} X^T Y,\n",
        "$$\n",
        "где:\n",
        "- $X$ — матрица размера $n \\times (d+1)$, где $n$ — количество наблюдений, $d$ — количество независимых переменных, а первый столбец содержит единицы (для свободного члена $w_0$),\n",
        "- $Y$ — вектор размера $n$, содержащий значения зависимой переменной.\n",
        "\n",
        "#### **Шаги реализации:**\n",
        "1. **Подготовка данных:** Сформируйте матрицу $X$, добавив столбец из единиц для свободного члена $w_0$.\n",
        "2. **Вычисление параметров:** Используйте формулу $(X^T X)^{-1} X^T Y$ для получения оценок параметров.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Исходные данные\n",
        "X = np.array([[1, 1, 1], [1, 2, 3], [1, 4, 5], [1, 6, 7]])  # Матрица признаков (включая столбец из единиц)\n",
        "Y = np.array([2, 3, 5, 7])  # Зависимая переменная\n",
        "\n",
        "# Вычисление параметров через МНК\n",
        "XT = X.T  # Транспонирование матрицы\n",
        "w = np.linalg.inv(XT @ X) @ XT @ Y  # Формула (X^T X)^{-1} X^T Y\n",
        "\n",
        "print(f\"Оценки параметров: {w}\")\n",
        "```\n",
        "\n",
        "#### **Результат:**\n",
        "После выполнения кода вы получите массив параметров $w = [w_0, w_1, w_2]$, которые можно интерпретировать как:\n",
        "- $w_0$: базовое значение $y$, когда все независимые переменные равны нулю,\n",
        "- $w_1, w_2$: коэффициенты, показывающие влияние каждой независимой переменной на $y$.\n",
        "\n",
        "\n",
        "\n",
        "### **3. Качество Модели**\n",
        "\n",
        "#### **Коэффициент детерминации ($R^2$):**\n",
        "Коэффициент детерминации ($R^2$) измеряет долю вариации зависимой переменной ($Y$), объясненную моделью. Чем ближе $R^2$ к 1, тем лучше модель объясняет данные.\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}},\n",
        "$$\n",
        "где:\n",
        "- $\\text{RSS} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$ — остаточная сумма квадратов (показывает ошибку модели),\n",
        "- $\\text{TSS} = \\sum_{i=1}^n (y_i - \\bar{y})^2$ — общая сумма квадратов (показывает общую вариацию данных).\n",
        "\n",
        "#### **Анализ остатков:**\n",
        "Для проверки качества модели важно анализировать остатки ($e_i = y_i - \\hat{y}_i$):\n",
        "1. **Гомоскедастичность:** Остатки должны иметь постоянную дисперсию. Если дисперсия меняется с ростом предсказанных значений, это указывает на проблему гетероскедастичности.\n",
        "2. **Нормальность:** Остатки должны быть нормально распределены. Это можно проверить с помощью Q-Q графика или статистических тестов (например, тест Шапиро-Уилка).\n",
        "3. **Отсутствие автокорреляции:** Остатки не должны быть взаимосвязаны. Это особенно важно для временных рядов.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import probplot\n",
        "\n",
        "# Предсказанные значения\n",
        "y_pred = X @ w\n",
        "\n",
        "# Остатки\n",
        "residuals = Y - y_pred\n",
        "\n",
        "# График остатков vs предсказанных значений\n",
        "plt.scatter(y_pred, residuals)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel(\"Предсказанные значения\")\n",
        "plt.ylabel(\"Остатки\")\n",
        "plt.title(\"Анализ гомоскедастичности\")\n",
        "plt.show()\n",
        "\n",
        "# Q-Q график для проверки нормальности\n",
        "probplot(residuals, plot=plt)\n",
        "plt.title(\"Q-Q график для остатков\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация:**\n",
        "- Если точки на Q-Q графике лежат близко к прямой, остатки нормально распределены.\n",
        "- Если остатки равномерно распределены вокруг нуля без видимых шаблонов, предположение гомоскедастичности выполняется.\n",
        "\n",
        "\n",
        "\n",
        "### **4. Мультиколлинеарность**\n",
        "\n",
        "#### **Что такое мультиколлинеарность?**\n",
        "Мультиколлинеарность возникает, когда независимые переменные сильно коррелируют друг с другом. Это может привести к следующим проблемам:\n",
        "1. **Нестабильность параметров:** Небольшие изменения в данных могут существенно менять оценки параметров.\n",
        "2. **Сложности в интерпретации:** Коэффициенты могут быть некорректно интерпретированы, так как влияние одной переменной смешивается с другой.\n",
        "\n",
        "#### **Способы диагностики:**\n",
        "1. **Матрица корреляций:** Вычислите корреляцию между всеми парами независимых переменных. Если коэффициент корреляции близок к 1 или -1, это указывает на высокую корреляцию.\n",
        "2. **VIF (Variance Inflation Factor):** VIF измеряет степень мультиколлинеарности для каждой переменной. Если VIF > 10, это указывает на наличие проблемы.\n",
        "\n",
        "#### **Формула VIF:**\n",
        "$$\n",
        "\\text{VIF}_j = \\frac{1}{1 - R_j^2},\n",
        "$$\n",
        "где $R_j^2$ — коэффициент детерминации регрессии переменной $x_j$ на остальные независимые переменные.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pandas as pd\n",
        "\n",
        "# Создание DataFrame для удобства\n",
        "df = pd.DataFrame(X[:, 1:], columns=['x1', 'x2'])\n",
        "\n",
        "# Вычисление VIF для каждой переменной\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = df.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
        "\n",
        "print(vif_data)\n",
        "```\n",
        "\n",
        "#### **Способы устранения мультиколлинеарности:**\n",
        "1. **Удаление переменных:** Удалите одну из сильно коррелирующих переменных. Например, если площадь дома и количество комнат сильно коррелируют, можно оставить только одну из них.\n",
        "2. **Объединение переменных:** Создайте новую переменную как комбинацию коррелирующих переменных. Например, вместо площади и количества комнат используйте среднюю площадь на комнату.\n",
        "3. **Регуляризация:** Используйте методы Lasso или Ridge регрессии, которые добавляют штраф за большие значения параметров. Это помогает снизить влияние мультиколлинеарности.\n",
        "\n",
        "\n",
        "### **5. Регуляризация в Множественной Линейной Регрессии**\n",
        "\n",
        "Регуляризация - это техника, которая помогает предотвратить переобучение модели и справиться с проблемами мультиколлинеарности путем добавления штрафного термина к функции потерь.\n",
        "\n",
        "#### **5.1 Ridge-регрессия (L2-регуляризация)**\n",
        "\n",
        "Ridge-регрессия добавляет к функции потерь сумму квадратов коэффициентов, умноженную на константу λ (lambda):\n",
        "\n",
        "$$\n",
        "\\text{Loss} = \\text{RSS} + \\lambda \\sum_{j=1}^d w_j^2\n",
        "$$\n",
        "\n",
        "Где:\n",
        "- $w_j$ - коэффициенты модели\n",
        "- $\\lambda$ - гиперпараметр, контролирующий силу регуляризации\n",
        "\n",
        "Особенности Ridge-регрессии:\n",
        "- Сжимает значения коэффициентов к нулю, но не обнуляет их полностью\n",
        "- Хорошо работает при presence множественных коррелирующих признаков\n",
        "- Все признаки остаются в модели\n",
        "\n",
        "#### **5.2 Lasso-регрессия (L1-регуляризация)**\n",
        "\n",
        "Lasso-регрессия добавляет к функции потерь сумму модулей коэффициентов, умноженную на константу λ:\n",
        "\n",
        "$$\n",
        "\\text{Loss} = \\text{RSS} + \\lambda \\sum_{j=1}^d |w_j|\n",
        "$$\n",
        "\n",
        "Особенности Lasso-регрессии:\n",
        "- Может полностью обнулить некоторые коэффициенты, что приводит к отбору признаков\n",
        "- Полезна когда число признаков велико или когда многие из них бесполезны\n",
        "- Может создать более интерпретируемую модель за счет исключения лишних признаков\n",
        "\n",
        "#### **5.3 Сравнение Ridge и Lasso**\n",
        "\n",
        "| Функция | Ridge | Lasso |\n",
        "|---------|-------|-------|\n",
        "| Штрафной термин | $\\sum w_j^2$ | $\\sum |w_j|$ |\n",
        "| Обнуление коэффициентов | Нет | Да |\n",
        "| Отбор признаков | Нет | Да |\n",
        "| При коррелирующих признаках | Усредняет их влияние | Выбирает один |\n",
        "\n",
        "#### **5.4 Реализация на Python**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ridge-регрессия\n",
        "ridge = Ridge(alpha=1.0) # alpha соответствует lambda\n",
        "ridge.fit(X_train, y_train)\n",
        "y_pred_ridge = ridge.predict(X_test)\n",
        "print(\"Ridge MSE:\", mean_squared_error(y_test, y_pred_ridge))\n",
        "\n",
        "# Lasso-регрессия\n",
        "lasso = Lasso(alpha=1.0)\n",
        "lasso.fit(X_train, y_train)\n",
        "y_pred_lasso = lasso.predict(X_test)\n",
        "print(\"Lasso MSE:\", mean_squared_error(y_test, y_pred_lasso))\n",
        "```\n",
        "\n",
        "#### **5.5 Выбор между Ridge и Lasso**\n",
        "\n",
        "- Используйте Ridge, если:\n",
        "  - Предполагается, что все признаки важны\n",
        "  - Присутствует мультиколлинеарность\n",
        "- Используйте Lasso, если:\n",
        "  - Ожидается, что только некоторые признаки важны\n",
        "  - Необходима автоматическая выборка признаков\n",
        "  - Требуется более простая модель\n",
        "\n",
        "#### **5.6 Elastic Net - Комбинированный подход**\n",
        "\n",
        "Elastic Net объединяет L1 и L2 регуляризацию:\n",
        "\n",
        "$$\n",
        "\\text{Loss} = \\text{RSS} + \\lambda_1 \\sum_{j=1}^d |w_j| + \\lambda_2 \\sum_{j=1}^d w_j^2\n",
        "$$\n",
        "\n",
        "Это позволяет получить преимущества обоих методов:\n",
        "- Возможность отбора признаков как в Lasso\n",
        "- Стабильность при коррелирующих признаках как в Ridge\n",
        "\n",
        "На практике Elastic Net часто показывает лучшие результаты, чем чистый Ridge или Lasso.\n",
        "\n",
        "### Вопросы для самопроверки\n",
        "\n",
        "1. Что такое множественная линейная регрессия?\n",
        "2. Какая формула описывает модель множественной линейной регрессии?\n",
        "3. Что представляют собой коэффициенты $w_0, w_1, \\dots, w_d$ в модели множественной линейной регрессии?\n",
        "4. Что такое случайная ошибка ($\\varepsilon$) в модели множественной линейной регрессии?\n",
        "5. Какую задачу решает метод наименьших квадратов (МНК)?\n",
        "6. Как вычисляются параметры модели с помощью МНК?\n",
        "7. Что такое сумма квадратов ошибок (RSS)?\n",
        "8. Как строится матрица $X$ для применения МНК?\n",
        "9. Для чего добавляется столбец из единиц в матрицу $X$?\n",
        "10. Как интерпретировать коэффициент $w_0$ в модели?\n",
        "11. Что показывают коэффициенты $w_1, w_2, \\dots, w_d$?\n",
        "12. Какой инструмент используется для проверки качества модели множественной линейной регрессии?\n",
        "13. Что такое коэффициент детерминации ($R^2$)?\n",
        "14. Как интерпретировать значение $R^2 = 0.8$?\n",
        "15. Что такое остатки ($e_i$) в контексте регрессионного анализа?\n",
        "16. Какие свойства должны иметь остатки идеальной модели?\n",
        "17. Что такое гомоскедастичность? Как её проверить?\n",
        "18. Что такое нормальность остатков? Как её проверить?\n",
        "19. Как анализируется автокорреляция остатков?\n",
        "20. Что такое мультиколлинеарность?\n",
        "21. Какие проблемы может вызывать мультиколлинеарность?\n",
        "22. Как диагностировать мультиколлинеарность с помощью матрицы корреляций?\n",
        "23. Что такое VIF (Variance Inflation Factor)? Как его интерпретировать?\n",
        "24. Какие способы устранения мультиколлинеарности существуют?\n",
        "25. Что такое регуляризация в контексте множественной линейной регрессии?\n",
        "26. Какие методы регуляризации можно использовать для устранения мультиколлинеарности?\n",
        "27. Что такое Lasso-регрессия? В чём её отличие от Ridge-регрессии?\n",
        "28. Как влияет размер выборки на качество модели множественной линейной регрессии?\n",
        "29. Какие предположения делаются при построении модели множественной линейной регрессии?\n",
        "30. Как выбрать наиболее значимые переменные для включения в модель?\n",
        "\n",
        "\n",
        "### Задачи для самостоятельной работы\n",
        "\n",
        "1. Даны данные: $X = \\begin{bmatrix} 1 & 2 \\\\ 1 & 4 \\\\ 1 & 6 \\end{bmatrix}$, $Y = \\begin{bmatrix} 3 \\\\ 7 \\\\ 11 \\end{bmatrix}$. Найдите параметры модели с помощью МНК.\n",
        "2. Реализуйте метод наименьших квадратов на Python для данных из задачи 1.\n",
        "3. Постройте модель множественной линейной регрессии для следующих данных:\n",
        "   - $X = \\begin{bmatrix} 1 & 1 & 2 \\\\ 1 & 2 & 3 \\\\ 1 & 3 & 4 \\end{bmatrix}$,\n",
        "   - $Y = \\begin{bmatrix} 4 \\\\ 7 \\\\ 10 \\end{bmatrix}$.\n",
        "4. Вычислите коэффициент детерминации ($R^2$) для модели из задачи 3.\n",
        "5. Проверьте гомоскедастичность остатков модели из задачи 3.\n",
        "6. Проверьте нормальность остатков модели из задачи 3.\n",
        "7. Создайте искусственный датасет с высокой мультиколлинеарностью между двумя независимыми переменными.\n",
        "8. Диагностируйте мультиколлинеарность в датасете из задачи 7 с помощью матрицы корреляций.\n",
        "9. Вычислите VIF для каждой переменной в датасете из задачи 7.\n",
        "10. Удалите одну из сильно коррелирующих переменных из датасета из задачи 7 и перестройте модель.\n",
        "\n",
        "11. Загрузите датасет `Boston Housing` из библиотеки `sklearn`. Постройте модель множественной линейной регрессии для предсказания цены дома.\n",
        "12. Вычислите коэффициент детерминации ($R^2$) для модели из задачи 11.\n",
        "13. Проанализируйте остатки модели из задачи 11. Есть ли признаки гетероскедастичности или автокорреляции?\n",
        "14. Проверьте наличие мультиколлинеарности в датасете `Boston Housing` с помощью VIF.\n",
        "15. Примените метод Lasso-регрессии к датасету `Boston Housing` и сравните результаты с обычной множественной линейной регрессией.\n",
        "16. Примените метод Ridge-регрессии к датасету `Boston Housing` и сравните результаты с обычной множественной линейной регрессией.\n",
        "17. Создайте новый признак как комбинацию двух других признаков в датасете `Boston Housing` и перестройте модель.\n",
        "18. Постройте Q-Q график для остатков модели из задачи 17.\n",
        "19. Используйте тест Шапиро-Уилка для проверки нормальности остатков модели из задачи 17.\n",
        "20. Определите самые значимые переменные в модели из задачи 17.\n",
        "\n",
        "21. Соберите датасет, содержащий информацию о ценах автомобилей и их характеристиках (например, мощность двигателя, пробег, возраст). Постройте модель множественной линейной регрессии для предсказания цены автомобиля.\n",
        "22. Выберите оптимальный набор переменных для модели из задачи 21, используя метод отбора признаков.\n",
        "23. Постройте модель для предсказания продаж товара на основе рекламного бюджета, цены и сезона.\n",
        "24. Оцените качество модели из задачи 23 с помощью метрик $R^2$, MAE и RMSE.\n",
        "25. Добавьте новые переменные в модель из задачи 23 и проанализируйте изменение качества модели.\n",
        "26. Проверьте наличие мультиколлинеарности в модели из задачи 23 и примите меры для её устранения.\n",
        "27. Сравните результаты обычной множественной линейной регрессии с Lasso-регрессией для датасета из задачи 23.\n",
        "28. Постройте модель для предсказания стоимости недвижимости на основе площади, количества комнат, возраста дома и местоположения.\n",
        "29. Оцените влияние каждого фактора на цену недвижимости в модели из задачи 28.\n",
        "30. Сформулируйте рекомендации по улучшению качества модели из задачи 28.\n"
      ],
      "metadata": {
        "id": "pwwPGskVVgri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **12. Практика Нелинейной Регрессии и Линеаризации на Python**\n",
        "\n",
        "### **1. Нелинейная Регрессия**\n",
        "\n",
        "#### **Что такое нелинейная регрессия?**\n",
        "Нелинейная регрессия — это метод, который используется для моделирования зависимостей, которые не могут быть выражены в виде линейной комбинации параметров. В отличие от линейной регрессии, здесь функциональная форма зависимости может быть произвольной, например, экспоненциальной, степенной, логистической или другой.\n",
        "\n",
        "Основная задача нелинейной регрессии заключается в подборе параметров модели таким образом, чтобы минимизировать ошибку между предсказанными и реальными значениями.\n",
        "\n",
        "#### **Примеры нелинейных моделей:**\n",
        "1. **Экспоненциальная модель:** $ y = a e^{bx} $\n",
        "   - Используется для описания процессов экспоненциального роста или убывания (например, рост популяций, радиоактивный распад).\n",
        "2. **Степенная модель:** $ y = a x^b $\n",
        "   - Применяется для описания зависимостей, где одна переменная пропорциональна степени другой.\n",
        "3. **Логистическая модель:** $ y = \\frac{L}{1 + e^{-k(x - x_0)}} $\n",
        "   - Описывает ограниченный рост, например, рост населения при ограниченных ресурсах.\n",
        "4. **Гиперболическая модель:** $ y = \\frac{a}{x} + b $\n",
        "   - Используется для описания обратной зависимости (например, закон Кулона).\n",
        "\n",
        "#### **Линеаризация:**\n",
        "Многие нелинейные модели можно преобразовать в линейные с помощью математических преобразований (например, логарифмирования). Это позволяет использовать метод наименьших квадратов для оценки параметров.\n",
        "\n",
        "\n",
        "\n",
        "### **2. Полиномиальная Регрессия**\n",
        "\n",
        "#### **Что такое полиномиальная регрессия?**\n",
        "Полиномиальная регрессия — это обобщение линейной регрессии, где зависимая переменная ($y$) аппроксимируется многочленом степени $d$:\n",
        "$$\n",
        "y = a_0 + a_1 x + a_2 x^2 + \\dots + a_d x^d + \\varepsilon,\n",
        "$$\n",
        "где:\n",
        "- $a_0, a_1, \\dots, a_d$ — коэффициенты многочлена,\n",
        "- $\\varepsilon$ — случайная ошибка.\n",
        "\n",
        "Полиномиальная регрессия особенно полезна, когда зависимость между переменными не является строго линейной, но имеет некоторую кривизну.\n",
        "\n",
        "#### **Метод наименьших квадратов для полиномов:**\n",
        "Для оценки параметров полиномиальной модели можно использовать метод наименьших квадратов. Для этого нужно создать матрицу признаков, содержащую степени независимой переменной ($x, x^2, \\dots, x^d$).\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Исходные данные\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1.1, 1.9, 3.1, 4.2, 5.1])\n",
        "\n",
        "# Создание матрицы признаков для полинома второй степени\n",
        "X = np.vstack([x**0, x**1, x**2]).T  # [1, x, x^2]\n",
        "\n",
        "# Оценка параметров через МНК\n",
        "XT = X.T\n",
        "coefficients = np.linalg.inv(XT @ X) @ XT @ y\n",
        "\n",
        "print(f\"Оценки коэффициентов: {coefficients}\")\n",
        "\n",
        "# Предсказанные значения\n",
        "y_pred = X @ coefficients\n",
        "\n",
        "# График\n",
        "plt.scatter(x, y, label=\"Данные\")\n",
        "plt.plot(x, y_pred, color='red', label=\"Полиномиальная регрессия\")\n",
        "plt.title(\"Полиномиальная регрессия второй степени\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Коэффициенты $a_0, a_1, a_2$ показывают влияние каждой степени $x$ на значение $y$.\n",
        "- Чем выше степень полинома, тем лучше он может аппроксимировать сложные зависимости, но есть риск переобучения.\n",
        "\n",
        "\n",
        "\n",
        "### **3. Экспоненциальная Регрессия**\n",
        "\n",
        "#### **Что такое экспоненциальная регрессия?**\n",
        "Экспоненциальная регрессия используется для моделирования данных, где зависимая переменная растет или убывает экспоненциально:\n",
        "$$\n",
        "y = a e^{bx}.\n",
        "$$\n",
        "\n",
        "Эта модель часто применяется в экономике, биологии, физике и других областях для описания процессов, таких как рост популяций, радиоактивный распад или компаундирование капитала.\n",
        "\n",
        "#### **Логарифмическое преобразование:**\n",
        "Чтобы применить метод наименьших квадратов, выполните логарифмическое преобразование:\n",
        "$$\n",
        "\\ln(y) = \\ln(a) + bx.\n",
        "$$\n",
        "После преобразования модель становится линейной, и можно оценить параметры $\\ln(a)$ и $b$.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Исходные данные\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2.7, 7.4, 20.1, 54.6, 148.4])\n",
        "\n",
        "# Логарифмическое преобразование\n",
        "log_y = np.log(y)\n",
        "\n",
        "# Матрица признаков\n",
        "X = np.vstack([np.ones_like(x), x]).T  # [1, x]\n",
        "\n",
        "# Оценка параметров через МНК\n",
        "XT = X.T\n",
        "coefficients = np.linalg.inv(XT @ X) @ XT @ log_y\n",
        "\n",
        "# Вычисление исходных параметров\n",
        "ln_a = coefficients[0]\n",
        "b = coefficients[1]\n",
        "a = np.exp(ln_a)\n",
        "\n",
        "print(f\"Оценки параметров: a = {a:.4f}, b = {b:.4f}\")\n",
        "\n",
        "# Предсказанные значения\n",
        "y_pred = a * np.exp(b * x)\n",
        "\n",
        "# График\n",
        "plt.scatter(x, y, label=\"Данные\")\n",
        "plt.plot(x, y_pred, color='red', label=\"Экспоненциальная регрессия\")\n",
        "plt.title(\"Экспоненциальная регрессия\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Параметр $a$ определяет начальное значение ($y$ при $x = 0$),\n",
        "- Параметр $b$ определяет скорость роста/убывания.\n",
        "\n",
        "\n",
        "\n",
        "### **4. Степенная Регрессия**\n",
        "\n",
        "#### **Что такое степенная регрессия?**\n",
        "Степенная регрессия используется для моделирования данных, где зависимая переменная пропорциональна степени независимой переменной:\n",
        "$$\n",
        "y = a x^b.\n",
        "$$\n",
        "\n",
        "Эта модель часто применяется в физике, инженерии и экономике для описания пропорциональных зависимостей.\n",
        "\n",
        "#### **Логарифмическая линеаризация:**\n",
        "Чтобы применить метод наименьших квадратов, выполните двойное логарифмирование:\n",
        "$$\n",
        "\\ln(y) = \\ln(a) + b \\ln(x).\n",
        "$$\n",
        "После преобразования модель становится линейной, и можно оценить параметры $\\ln(a)$ и $b$.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Исходные данные\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1.1, 2.2, 3.3, 4.4, 5.5])\n",
        "\n",
        "# Логарифмическое преобразование\n",
        "log_x = np.log(x)\n",
        "log_y = np.log(y)\n",
        "\n",
        "# Матрица признаков\n",
        "X = np.vstack([np.ones_like(log_x), log_x]).T  # [1, ln(x)]\n",
        "\n",
        "# Оценка параметров через МНК\n",
        "XT = X.T\n",
        "coefficients = np.linalg.inv(XT @ X) @ XT @ log_y\n",
        "\n",
        "# Вычисление исходных параметров\n",
        "ln_a = coefficients[0]\n",
        "b = coefficients[1]\n",
        "a = np.exp(ln_a)\n",
        "\n",
        "print(f\"Оценки параметров: a = {a:.4f}, b = {b:.4f}\")\n",
        "\n",
        "# Предсказанные значения\n",
        "y_pred = a * (x**b)\n",
        "\n",
        "# График\n",
        "plt.scatter(x, y, label=\"Данные\")\n",
        "plt.plot(x, y_pred, color='red', label=\"Степенная регрессия\")\n",
        "plt.title(\"Степенная регрессия\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Параметр $a$ определяет масштаб,\n",
        "- Параметр $b$ определяет степень зависимости.\n",
        "\n",
        "\n",
        "\n",
        "### **5. Другие Модели**\n",
        "\n",
        "#### **Логистическая регрессия:**\n",
        "Логистическая регрессия используется для моделирования ограниченного роста:\n",
        "$$\n",
        "y = \\frac{L}{1 + e^{-k(x - x_0)}}.\n",
        "$$\n",
        "Здесь:\n",
        "- $L$ — максимальное значение,\n",
        "- $k$ — скорость роста,\n",
        "- $x_0$ — точка инфлексции.\n",
        "\n",
        "#### **Гиперболическая регрессия:**\n",
        "Гиперболическая регрессия используется для моделирования обратной зависимости:\n",
        "$$\n",
        "y = \\frac{a}{x} + b.\n",
        "$$\n",
        "\n",
        "#### **Дробно-линейная регрессия:**\n",
        "Дробно-линейная регрессия используется для моделирования отношений:\n",
        "$$\n",
        "y = \\frac{a x + b}{c x + d}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **6. Нелинейная Оптимизация**\n",
        "\n",
        "### **Что такое нелинейная оптимизация?**\n",
        "Нелинейная оптимизация — это процесс поиска параметров модели, которые минимизируют ошибку между предсказанными и реальными значениями в случае, когда модель имеет сложную (нелинейную) функциональную форму. В отличие от линейной регрессии, где параметры находятся аналитически через метод наименьших квадратов, для нелинейных моделей используется численный подход.\n",
        "\n",
        "Основная задача нелинейной оптимизации заключается в минимизации функции потерь (например, суммы квадратов ошибок):\n",
        "$$\n",
        "\\text{RSS} = \\sum_{i=1}^n \\left( y_i - f(x_i; \\theta) \\right)^2,\n",
        "$$\n",
        "где:\n",
        "- $y_i$ — реальное значение,\n",
        "- $f(x_i; \\theta)$ — предсказанное значение, зависящее от параметров $\\theta$,\n",
        "- $x_i$ — независимая переменная.\n",
        "\n",
        "Параметры $\\theta$ находятся таким образом, чтобы минимизировать эту функцию.\n",
        "\n",
        "\n",
        "\n",
        "### **Методы Нелинейной Оптимизации**\n",
        "\n",
        "#### **1. Метод Градиентного Спуска**\n",
        "Градиентный спуск — это итеративный метод, который использует производные функции потерь для обновления параметров модели. На каждом шаге параметры корректируются в направлении противоположном градиенту функции потерь:\n",
        "$$\n",
        "\\theta_{k+1} = \\theta_k - \\alpha \\nabla_\\theta \\text{RSS},\n",
        "$$\n",
        "где:\n",
        "- $\\theta_k$ — текущие параметры,\n",
        "- $\\alpha$ — скорость обучения (шаг),\n",
        "- $\\nabla_\\theta \\text{RSS}$ — градиент функции потерь по параметрам.\n",
        "\n",
        "Преимущества:\n",
        "- Простота реализации.\n",
        "- Подходит для больших наборов данных.\n",
        "\n",
        "Недостатки:\n",
        "- Может застрять в локальных минимумах.\n",
        "- Требует выбора скорости обучения.\n",
        "\n",
        "\n",
        "\n",
        "#### **2. Метод Левенберга-Марквардта**\n",
        "Метод Левенберга-Марквардта — это гибридный алгоритм, сочетающий градиентный спуск и метод наименьших квадратов. Он особенно эффективен для задач нелинейной регрессии, так как учитывает как информацию о градиенте, так и информацию о вторых производных (матрицу Гессе).\n",
        "\n",
        "Основная идея метода:\n",
        "- Если градиент большой, алгоритм работает как градиентный спуск.\n",
        "- Если градиент малый, алгоритм работает как метод наименьших квадратов.\n",
        "\n",
        "Формула обновления параметров:\n",
        "$$\n",
        "\\Delta \\theta = \\left( J^T J + \\lambda \\text{diag}(J^T J) \\right)^{-1} J^T r,\n",
        "$$\n",
        "где:\n",
        "- $J$ — матрица Якоби (производные модели по параметрам),\n",
        "- $r$ — вектор остатков ($r_i = y_i - f(x_i; \\theta)$),\n",
        "- $\\lambda$ — параметр, контролирующий баланс между градиентным спуском и методом наименьших квадратов.\n",
        "\n",
        "Преимущества:\n",
        "- Быстрая сходимость.\n",
        "- Устойчивость к плохой начальной инициализации.\n",
        "\n",
        "Недостатки:\n",
        "- Высокая вычислительная сложность для больших моделей.\n",
        "\n",
        "\n",
        "\n",
        "#### **3. Метод Нелдера-Мида**\n",
        "Метод Нелдера-Мида — это безградиентный метод оптимизации, который не требует вычисления производных. Он основывается на построении симплекса (многогранника) в пространстве параметров и его последовательной модификации для приближения к оптимальному решению.\n",
        "\n",
        "Преимущества:\n",
        "- Не требует вычисления градиента.\n",
        "- Прост в реализации.\n",
        "\n",
        "Недостатки:\n",
        "- Медленная сходимость для сложных моделей.\n",
        "- Может быть менее точным, чем другие методы.\n",
        "\n",
        "\n",
        "\n",
        "### **Реализация Нелинейной Оптимизации на Python**\n",
        "\n",
        "#### **Пример 1: Использование `scipy.optimize.curve_fit`**\n",
        "Библиотека `scipy` предоставляет удобный инструмент `curve_fit`, который автоматически подбирает параметры нелинейной модели с использованием метода Левенберга-Марквардта.\n",
        "\n",
        "```python\n",
        "from scipy.optimize import curve_fit\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Исходные данные\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1.1, 1.9, 3.1, 4.2, 5.1])\n",
        "\n",
        "# Нелинейная модель\n",
        "def nonlinear_model(x, a, b, c):\n",
        "    return a * np.exp(-b * x) + c\n",
        "\n",
        "# Оценка параметров через curve_fit\n",
        "popt, pcov = curve_fit(nonlinear_model, x, y, p0=[1, 0.1, 0])  # p0 — начальная инициализация параметров\n",
        "\n",
        "print(f\"Оценки параметров: a = {popt[0]:.4f}, b = {popt[1]:.4f}, c = {popt[2]:.4f}\")\n",
        "\n",
        "# Предсказанные значения\n",
        "y_pred = nonlinear_model(x, *popt)\n",
        "\n",
        "# График\n",
        "plt.scatter(x, y, label=\"Данные\")\n",
        "plt.plot(x, y_pred, color='red', label=\"Нелинейная регрессия\")\n",
        "plt.title(\"Нелинейная оптимизация с помощью curve_fit\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Объяснение кода:**\n",
        "1. Функция `nonlinear_model` определяет нелинейную зависимость между $x$ и $y$.\n",
        "2. Метод `curve_fit` автоматически подбирает параметры $a$, $b$ и $c$, минимизируя сумму квадратов ошибок.\n",
        "3. Результаты выводятся в виде графика, показывающего исходные данные и предсказанные значения.\n",
        "\n",
        "\n",
        "\n",
        "#### **Пример 2: Использование `scipy.optimize.minimize`**\n",
        "Если нужно больше контроля над процессом оптимизации, можно использовать функцию `minimize` из `scipy.optimize`. Этот метод позволяет выбрать конкретный алгоритм оптимизации (например, Левенберг-Марквардт или Нелдер-Мид).\n",
        "\n",
        "```python\n",
        "from scipy.optimize import minimize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Исходные данные\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1.1, 1.9, 3.1, 4.2, 5.1])\n",
        "\n",
        "# Нелинейная модель\n",
        "def nonlinear_model(params, x):\n",
        "    a, b, c = params\n",
        "    return a * np.exp(-b * x) + c\n",
        "\n",
        "# Функция потерь (сумма квадратов ошибок)\n",
        "def loss_function(params, x, y):\n",
        "    predictions = nonlinear_model(params, x)\n",
        "    residuals = y - predictions\n",
        "    return np.sum(residuals**2)\n",
        "\n",
        "# Начальная инициализация параметров\n",
        "initial_params = [1, 0.1, 0]\n",
        "\n",
        "# Минимизация функции потерь\n",
        "result = minimize(loss_function, initial_params, args=(x, y), method='L-BFGS-B')\n",
        "\n",
        "# Оптимальные параметры\n",
        "optimal_params = result.x\n",
        "print(f\"Оптимальные параметры: a = {optimal_params[0]:.4f}, b = {optimal_params[1]:.4f}, c = {optimal_params[2]:.4f}\")\n",
        "\n",
        "# Предсказанные значения\n",
        "y_pred = nonlinear_model(optimal_params, x)\n",
        "\n",
        "# График\n",
        "plt.scatter(x, y, label=\"Данные\")\n",
        "plt.plot(x, y_pred, color='red', label=\"Нелинейная регрессия\")\n",
        "plt.title(\"Нелинейная оптимизация с помощью minimize\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Объяснение кода:**\n",
        "1. Функция `loss_function` вычисляет сумму квадратов ошибок между реальными и предсказанными значениями.\n",
        "2. Метод `minimize` выполняет оптимизацию с использованием выбранного алгоритма (здесь используется L-BFGS-B).\n",
        "3. Результаты выводятся в виде графика.\n",
        "\n",
        "\n",
        "\n",
        "### **Выбор Алгоритма**\n",
        "При выборе алгоритма оптимизации следует учитывать следующие факторы:\n",
        "1. **Сложность модели:** Для простых моделей достаточно использовать `curve_fit`.\n",
        "2. **Требования к точности:** Если нужна высокая точность, лучше использовать метод Левенберга-Марквардта.\n",
        "3. **Вычислительные ресурсы:** Для больших наборов данных рекомендуется использовать более эффективные алгоритмы, такие как L-BFGS-B.\n",
        "\n",
        "### Вопросы для самопроверки\n",
        "\n",
        "1. Что такое нелинейная регрессия?\n",
        "2. Как отличается нелинейная регрессия от линейной?\n",
        "3. Приведите примеры типичных нелинейных моделей.\n",
        "4. Что означает линеаризация в контексте нелинейной регрессии?\n",
        "5. Какие преобразования используются для линеаризации экспоненциальной модели?\n",
        "6. Какую модель описывает формула $y = a e^{bx}$?\n",
        "7. Для каких процессов используется степенная модель $y = a x^b$?\n",
        "8. Что представляет собой логистическая модель $y = \\frac{L}{1 + e^{-k(x - x_0)}}$?\n",
        "9. Какие процессы лучше всего описываются гиперболической моделью $y = \\frac{a}{x} + b$?\n",
        "10. Что такое полиномиальная регрессия?\n",
        "11. Какая формула описывает полиномиальную регрессию?\n",
        "12. Как влияет степень многочлена на сложность модели?\n",
        "13. Какие риски возникают при использовании многочленов высокой степени?\n",
        "14. Что такое метод наименьших квадратов в контексте полиномиальной регрессии?\n",
        "15. Какие шаги необходимы для реализации полиномиальной регрессии на Python?\n",
        "16. Что такое экспоненциальная регрессия?\n",
        "17. Как логарифмическое преобразование помогает в экспоненциальной регрессии?\n",
        "18. Как интерпретировать параметры $a$ и $b$ в модели $y = a e^{bx}$?\n",
        "19. Что такое степенная регрессия?\n",
        "20. Какое преобразование используется для линеаризации степенной модели?\n",
        "21. Как интерпретировать параметры $a$ и $b$ в модели $y = a x^b$?\n",
        "22. Что такое логистическая регрессия, и для каких задач она используется?\n",
        "23. Какие параметры определяют форму логистической кривой?\n",
        "24. Что такое гиперболическая регрессия?\n",
        "25. Какие реальные процессы могут быть описаны гиперболической моделью?\n",
        "26. Что такое нелинейная оптимизация?\n",
        "27. Какую функцию минимизируют при нелинейной оптимизации?\n",
        "28. Назовите основные методы нелинейной оптимизации.\n",
        "29. Что такое метод градиентного спуска?\n",
        "30. В чем преимущества и недостатки метода Левенберга-Марквардта?\n",
        "\n",
        "\n",
        "### Задачи для самостоятельной работы\n",
        "\n",
        "#### Задачи по теории и реализации моделей\n",
        "1. Постройте полиномиальную регрессию второй степени для данных:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [1.1, 1.9, 3.1, 4.2, 5.1]$.\n",
        "2. Вычислите коэффициенты полиномиальной регрессии третьей степени для данных из задачи 1.\n",
        "3. Реализуйте экспоненциальную регрессию для данных:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [2.7, 7.4, 20.1, 54.6, 148.4]$.\n",
        "4. Постройте степенную регрессию для данных:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [1.1, 2.2, 3.3, 4.4, 5.5]$.\n",
        "5. Используя данные из задачи 4, проверьте качество модели с помощью коэффициента детерминации ($R^2$).\n",
        "6. Постройте логистическую регрессию для данных о росте популяции:  \n",
        "   $x = [0, 1, 2, 3, 4]$, $y = [10, 20, 50, 80, 90]$.\n",
        "7. Оцените параметры гиперболической модели для данных:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [5, 2.5, 1.67, 1.25, 1]$.\n",
        "8. Сравните результаты полиномиальной и степенной регрессий для данных из задачи 4.\n",
        "9. Постройте модель дробно-линейной регрессии для данных:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [1.1, 1.2, 1.3, 1.4, 1.5]$.\n",
        "10. Проверьте устойчивость модели из задачи 9 к изменению начальных параметров.\n",
        "\n",
        "\n",
        "11. Загрузите датасет `Boston Housing` и постройте полиномиальную регрессию для предсказания цены дома.\n",
        "12. Вычислите коэффициент детерминации ($R^2$) для модели из задачи 11.\n",
        "13. Постройте экспоненциальную регрессию для моделирования роста населения города.\n",
        "14. Сравните результаты экспоненциальной и логистической регрессий для данных о росте населения.\n",
        "15. Постройте модель для предсказания продаж товара с использованием полиномиальной регрессии.\n",
        "16. Оцените влияние каждой степени переменной на результат в модели из задачи 15.\n",
        "17. Постройте степенную регрессию для данных о зависимости скорости автомобиля от его мощности.\n",
        "18. Проверьте нормальность остатков модели из задачи 17.\n",
        "19. Постройте логистическую регрессию для моделирования ограниченного роста бактерий.\n",
        "20. Сравните качество модели из задачи 19 с помощью различных метрик (MSE, MAE).\n",
        "\n",
        "21. Используйте метод `curve_fit` из библиотеки `scipy` для подбора параметров нелинейной модели:  \n",
        "    $y = a \\cdot e^{-b \\cdot x} + c$ для данных:  \n",
        "    $x = [1, 2, 3, 4, 5]$, $y = [1.1, 1.9, 3.1, 4.2, 5.1]$.\n",
        "22. Реализуйте метод Левенберга-Марквардта для задачи из задачи 21.\n",
        "23. Сравните результаты методов `curve_fit` и Левенберга-Марквардта для задачи из задачи 21.\n",
        "24. Используйте метод Нелдера-Мида для подбора параметров модели:  \n",
        "    $y = \\frac{a}{x} + b$ для данных:  \n",
        "    $x = [1, 2, 3, 4, 5]$, $y = [5, 2.5, 1.67, 1.25, 1]$.\n",
        "25. Реализуйте метод градиентного спуска для минимизации функции потерь в задаче из задачи 24.\n",
        "26. Сравните скорость сходимости методов Левенберга-Марквардта и градиентного спуска.\n",
        "27. Постройте модель для данных о радиоактивном распаде с использованием нелинейной оптимизации.\n",
        "28. Оцените чувствительность модели из задачи 27 к изменениям начальных параметров.\n",
        "29. Постройте модель для данных о температурной зависимости реакции с использованием нелинейной регрессии.\n",
        "30. Сформулируйте рекомендации по выбору алгоритма нелинейной оптимизации для разных типов задач."
      ],
      "metadata": {
        "id": "hbENKZhCWtK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **13. Практика Коэффициента Корреляции и Проверки Гипотез на Python**\n",
        "\n",
        "\n",
        "\n",
        "## **1. Коэффициент Корреляции**\n",
        "\n",
        "#### **Что такое коэффициент корреляции?**\n",
        "Коэффициент корреляции ($r$) — это статистическая мера, которая показывает силу и направление линейной связи между двумя числовыми переменными. Он принимает значения в диапазоне от $-1$ до $1$:\n",
        "- Если $r = 1$, то между переменными существует полная положительная линейная зависимость: при увеличении одной переменной другая также увеличивается пропорционально.\n",
        "- Если $r = -1$, то между переменными существует полная отрицательная линейная зависимость: при увеличении одной переменной другая уменьшается пропорционально.\n",
        "- Если $r = 0$, то между переменными нет линейной зависимости, хотя могут существовать другие типы связей (например, нелинейные).\n",
        "\n",
        "#### **Формула для вычисления коэффициента корреляции:**\n",
        "$$\n",
        "r = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2 \\cdot \\sum_{i=1}^n (y_i - \\bar{y})^2}},\n",
        "$$\n",
        "где:\n",
        "- $x_i, y_i$ — наблюдаемые значения двух переменных,\n",
        "- $\\bar{x}, \\bar{y}$ — средние значения этих переменных.\n",
        "\n",
        "#### **Статистическая оценка коэффициента корреляции для выборки:**\n",
        "Коэффициент корреляции, вычисленный по выборке, является оценкой истинного параметра популяции ($\\rho$). Его точность зависит от размера выборки и распределения данных. Чем больше выборка, тем более надежной является оценка.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Исходные данные\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "# Вычисление коэффициента корреляции\n",
        "correlation = np.corrcoef(x, y)[0, 1]\n",
        "print(f\"Коэффициент корреляции: {correlation:.4f}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "Если коэффициент корреляции равен $r = 1$, это означает, что между переменными существует идеальная положительная линейная зависимость. Например, если $x$ увеличивается на единицу, то $y$ увеличивается пропорционально. В данном случае переменные $x$ и $y$ полностью связаны линейной функцией.\n",
        "\n",
        "#### **Визуализация линейной зависимости**\n",
        "Мы можем построить график рассеяния (scatter plot) для данных и добавить линию регрессии, чтобы визуально оценить силу и направление корреляции.\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x, y, color='blue', label='Наблюдения')\n",
        "plt.plot(x, np.poly1d(np.polyfit(x, y, 1))(x), color='red', label='Линия регрессии')\n",
        "plt.title(f\"Коэффициент корреляции: {correlation:.4f}\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "\n",
        "## **2. Проверка Гипотезы о Равенстве Нулю Коэффициента Корреляции**\n",
        "\n",
        "#### **Задача:**\n",
        "Цель проверки гипотезы — определить, существует ли значимая линейная связь между двумя переменными в популяции. Для этого используется тест на равенство коэффициента корреляции нулю.\n",
        "\n",
        "#### **Гипотезы:**\n",
        "- Нулевая гипотеза ($H_0$): в популяции нет линейной связи ($\\rho = 0$).\n",
        "- Альтернативная гипотеза ($H_1$): в популяции существует линейная связь ($\\rho \\neq 0$).\n",
        "\n",
        "#### **Статистика теста:**\n",
        "Если нулевая гипотеза верна, то статистика:\n",
        "$$\n",
        "t = r \\sqrt{\\frac{n-2}{1-r^2}}\n",
        "$$\n",
        "следует распределению Стьюдента с $n-2$ степенями свободы, где:\n",
        "- $r$ — коэффициент корреляции,\n",
        "- $n$ — количество наблюдений.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import t\n",
        "\n",
        "# Исходные данные\n",
        "n = len(x)\n",
        "r = np.corrcoef(x, y)[0, 1]\n",
        "\n",
        "# Вычисление статистики t\n",
        "t_stat = r * np.sqrt((n - 2) / (1 - r**2))\n",
        "\n",
        "# Критическое значение t\n",
        "alpha = 0.05\n",
        "df = n - 2\n",
        "critical_value = t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "# Решение\n",
        "if abs(t_stat) > critical_value:\n",
        "    decision = \"Отвергаем H0: есть значимая корреляция\"\n",
        "else:\n",
        "    decision = \"Не отвергаем H0: корреляция не значима\"\n",
        "\n",
        "print(f\"T-статистика: {t_stat:.4f}, Критическое значение: {critical_value:.4f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если модуль $t$-статистики больше критического значения ($|t| > t_{крит}$), то нулевая гипотеза отвергается, и можно заключить, что существует значимая линейная связь между переменными.\n",
        "- Если модуль $t$-статистики меньше или равен критическому значению ($|t| \\leq t_{крит}$), то нулевая гипотеза не отвергается, и данных недостаточно для утверждения о наличии линейной связи.\n",
        "\n",
        "#### **Визуализация распределения t-статистики**\n",
        "Мы можем построить распределение Стьюдента с соответствующими степенями свободы и отметить на нем вычисленное значение $t$-статистики.\n",
        "\n",
        "```python\n",
        "# Визуализация распределения t\n",
        "x_vals = np.linspace(t.ppf(0.001, df), t.ppf(0.999, df), 100)\n",
        "pdf = t.pdf(x_vals, df)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(x_vals, pdf, label=f\"t-распределение (df={df})\")\n",
        "plt.axvline(t_stat, color='red', linestyle='--', label=f\"T-статистика: {t_stat:.4f}\")\n",
        "plt.axvline(critical_value, color='green', linestyle='--', label=f\"Критическое значение: {critical_value:.4f}\")\n",
        "plt.axvline(-critical_value, color='green', linestyle='--')\n",
        "plt.fill_between(x_vals, pdf, where=(x_vals > critical_value), color='orange', alpha=0.3, label=\"Критическая область\")\n",
        "plt.fill_between(x_vals, pdf, where=(x_vals < -critical_value), color='orange', alpha=0.3)\n",
        "plt.title(\"T-тест для коэффициента корреляции\")\n",
        "plt.xlabel(\"Значение t\")\n",
        "plt.ylabel(\"Плотность вероятности\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "\n",
        "## **3. Проверка Независимости Величин по Критерию $\\chi^2$**\n",
        "\n",
        "#### **Что такое критерий $\\chi^2$?**\n",
        "Критерий $\\chi^2$ (хи-квадрат) используется для проверки независимости двух категориальных переменных. Этот метод основывается на сравнении наблюдаемых частот с ожидаемыми частотами под предположением независимости переменных.\n",
        "\n",
        "#### **Гипотезы:**\n",
        "- Нулевая гипотеза ($H_0$): две категориальные переменные независимы.\n",
        "- Альтернативная гипотеза ($H_1$): две категориальные переменные зависимы.\n",
        "\n",
        "#### **Формула статистики $\\chi^2$:**\n",
        "$$\n",
        "\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i},\n",
        "$$\n",
        "где:\n",
        "- $O_i$ — наблюдаемая частота,\n",
        "- $E_i$ — ожидаемая частота под предположением независимости.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Таблица сопряженности\n",
        "observed = np.array([[10, 20], [15, 25]])\n",
        "\n",
        "# Вычисление статистики χ²\n",
        "chi2, p_value, dof, expected = chi2_contingency(observed)\n",
        "\n",
        "# Решение\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    decision = \"Отвергаем H0: переменные зависимы\"\n",
        "else:\n",
        "    decision = \"Не отвергаем H0: переменные независимы\"\n",
        "\n",
        "print(f\"χ²-статистика: {chi2:.4f}, P-значение: {p_value:.4f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "- Если $p$-значение меньше уровня значимости ($p < \\alpha$), то нулевая гипотеза отвергается, и можно заключить, что переменные зависимы.\n",
        "- Если $p$-значение больше или равно уровню значимости ($p \\geq \\alpha$), то нулевая гипотеза не отвергается, и данных недостаточно для утверждения о зависимости переменных.\n",
        "\n",
        "#### **Визуализация таблицы сопряженности**\n",
        "Мы можем построить тепловую карту (heatmap) для таблицы сопряженности, чтобы визуализировать наблюдаемые частоты.\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(observed, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Таблица сопряженности\")\n",
        "plt.xlabel(\"Переменная 2\")\n",
        "plt.ylabel(\"Переменная 1\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Интерпретация графика:**\n",
        "- Тепловая карта показывает наблюдаемые частоты в каждой ячейке таблицы.\n",
        "- Чем больше разница между наблюдаемыми и ожидаемыми частотами, тем выше вероятность отклонения нулевой гипотезы.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **4. Критерий Знаков**\n",
        "\n",
        "#### **Что такое критерий знаков?**\n",
        "Критерий знаков — это непараметрический статистический тест, который используется для проверки гипотез о медианной разнице между двумя связанными выборками или для анализа данных, которые не соответствуют предположениям о нормальности распределения. Он основывается на количестве положительных и отрицательных разностей между парами значений.\n",
        "\n",
        "#### **Гипотезы:**\n",
        "- Нулевая гипотеза ($H_0$): медиана разностей равна нулю (нет систематической разницы между парами).\n",
        "- Альтернативная гипотеза ($H_1$): медиана разностей отлична от нуля (существует систематическая разница).\n",
        "\n",
        "#### **Методика расчета:**\n",
        "1. Вычислить разности между парами значений.\n",
        "2. Подсчитать количество положительных ($N_+$) и отрицательных ($N_-$) разностей.\n",
        "3. Если количество наблюдений мало ($N \\leq 25$), использовать таблицы биномиальных вероятностей для определения $p$-значения.\n",
        "4. Для большого количества наблюдений ($N > 25$) можно использовать нормальное приближение:\n",
        "   $$\n",
        "   Z = \\frac{|N_+ - N_-| - 1}{\\sqrt{N}},\n",
        "   $$\n",
        "   где:\n",
        "   - $N_+$ — количество положительных разностей,\n",
        "   - $N_-$ — количество отрицательных разностей,\n",
        "   - $N = N_+ + N_-$ — общее количество пар.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import binom_test\n",
        "import numpy as np\n",
        "\n",
        "# Разности между парами значений\n",
        "differences = np.array([1, -2, 3, -4, 5, -6, 7, -8])\n",
        "\n",
        "# Подсчет положительных и отрицательных разностей\n",
        "N_plus = np.sum(differences > 0)\n",
        "N_minus = np.sum(differences < 0)\n",
        "\n",
        "# Биномиальный тест\n",
        "p_value = binom_test(min(N_plus, N_minus), n=len(differences), p=0.5)\n",
        "\n",
        "# Решение\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    decision = \"Отвергаем H0: медианы различны\"\n",
        "else:\n",
        "    decision = \"Не отвергаем H0: медианы равны\"\n",
        "\n",
        "print(f\"P-значение: {p_value:.4f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "#### **Визуализация разностей**\n",
        "Мы можем построить гистограмму разностей, чтобы визуально оценить распределение значений.\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Визуализация разностей\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(differences, bins=10, color='blue', edgecolor='black', alpha=0.7)\n",
        "plt.axvline(0, color='red', linestyle='--', label=\"Нулевая отметка\")\n",
        "plt.title(\"Гистограмма разностей\")\n",
        "plt.xlabel(\"Значение разности\")\n",
        "plt.ylabel(\"Частота\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Интерпретация графика:**\n",
        "- Гистограмма показывает распределение разностей между парами значений.\n",
        "- Если большинство значений сосредоточено вокруг нуля, это может указывать на отсутствие систематической разницы.\n",
        "- Если значения смещены в одну сторону, это может указывать на наличие систематической разницы.\n",
        "\n",
        "\n",
        "## **5. Частичная Корреляция**\n",
        "\n",
        "#### **Что такое частичная корреляция?**\n",
        "Частичная корреляция измеряет связь между двумя переменными, исключая влияние одной или нескольких других переменных. Это позволяет выявить \"чистую\" зависимость между переменными без учета внешних факторов.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "r_{xy.z} = \\frac{r_{xy} - r_{xz} r_{yz}}{\\sqrt{(1 - r_{xz}^2)(1 - r_{yz}^2)}},\n",
        "$$\n",
        "где:\n",
        "- $r_{xy.z}$ — частичная корреляция между $x$ и $y$, контролируя $z$,\n",
        "- $r_{xy}, r_{xz}, r_{yz}$ — коэффициенты корреляции между соответствующими парами переменных.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from pingouin import partial_corr\n",
        "import pandas as pd\n",
        "\n",
        "# Исходные данные\n",
        "data = {\n",
        "    'x': [1, 2, 3, 4, 5],\n",
        "    'y': [2, 4, 6, 8, 10],\n",
        "    'z': [5, 6, 7, 8, 9]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Вычисление частичной корреляции\n",
        "result = partial_corr(data=df, x='x', y='y', covar='z')\n",
        "print(result[['r', 'p-val']])\n",
        "```\n",
        "\n",
        "#### **Визуализация взаимосвязей**\n",
        "Мы можем построить матрицу корреляций, чтобы визуально оценить связи между переменными.\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "\n",
        "# Матрица корреляций\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Матрица корреляций\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Интерпретация графика:**\n",
        "- Матрица корреляций показывает коэффициенты корреляции между всеми парами переменных.\n",
        "- Частичная корреляция помогает оценить связь между $x$ и $y$, исключая влияние $z$.\n",
        "\n",
        "\n",
        "## **6. Корреляция Спирмена**\n",
        "\n",
        "#### **Что такое корреляция Спирмена?**\n",
        "Корреляция Спирмена ($\\rho$) — это непараметрический метод, который измеряет силу монотонной (не обязательно линейной) связи между двумя переменными. Она основана на рангах данных, что делает ее устойчивой к выбросам и нелинейным зависимостям.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "\\rho = 1 - \\frac{6 \\sum d_i^2}{n(n^2 - 1)},\n",
        "$$\n",
        "где:\n",
        "- $d_i$ — разность между рангами двух переменных для каждого наблюдения,\n",
        "- $n$ — количество наблюдений.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Исходные данные\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([5, 4, 3, 2, 1])\n",
        "\n",
        "# Корреляция Спирмена\n",
        "spearman_corr, spearman_pval = spearmanr(x, y)\n",
        "print(f\"Корреляция Спирмена: {spearman_corr:.4f}, P-значение: {spearman_pval:.4f}\")\n",
        "```\n",
        "\n",
        "#### **Визуализация рангов**\n",
        "Мы можем построить график рассеяния с рангами для визуального анализа монотонной зависимости.\n",
        "\n",
        "```python\n",
        "# Ранги переменных\n",
        "rank_x = spearmanr(x, y).correlation * x.rank()\n",
        "rank_y = spearmanr(x, y).correlation * y.rank()\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(rank_x, rank_y, color='blue', label='Ранги')\n",
        "plt.plot(np.linspace(0, max(rank_x), 100), np.linspace(0, max(rank_y), 100), color='red', linestyle='--', label='Линия регрессии')\n",
        "plt.title(\"График рангов для корреляции Спирмена\")\n",
        "plt.xlabel(\"Ранг X\")\n",
        "plt.ylabel(\"Ранг Y\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Интерпретация графика:**\n",
        "- График показывает связь между рангами переменных.\n",
        "- Если точки следуют за линией регрессии, это указывает на монотонную зависимость.\n",
        "\n",
        "\n",
        "\n",
        "## **7. Корреляция Кендалла**\n",
        "\n",
        "#### **Что такое корреляция Кендалла?**\n",
        "Корреляция Кендалла ($\\tau$) также измеряет монотонную связь между двумя переменными, но она основана на количестве согласованных и несогласованных пар в данных. Этот метод менее чувствителен к размеру выборки по сравнению с корреляцией Спирмена.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "\\tau = \\frac{C - D}{\\binom{n}{2}},\n",
        "$$\n",
        "где:\n",
        "- $C$ — количество согласованных пар,\n",
        "- $D$ — количество несогласованных пар,\n",
        "- $\\binom{n}{2}$ — общее количество пар.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import kendalltau\n",
        "\n",
        "# Исходные данные\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([5, 4, 3, 2, 1])\n",
        "\n",
        "# Корреляция Кендалла\n",
        "kendall_corr, kendall_pval = kendalltau(x, y)\n",
        "print(f\"Корреляция Кендалла: {kendall_corr:.4f}, P-значение: {kendall_pval:.4f}\")\n",
        "```\n",
        "\n",
        "#### **Визуализация согласованных и несогласованных пар**\n",
        "Мы можем построить график рассеяния и отметить согласованные/несогласованные пары.\n",
        "\n",
        "```python\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x, y, color='blue', label='Пары')\n",
        "for i in range(len(x)):\n",
        "    for j in range(i + 1, len(x)):\n",
        "        if (x[i] < x[j] and y[i] < y[j]) or (x[i] > x[j] and y[i] > y[j]):\n",
        "            plt.plot([x[i], x[j]], [y[i], y[j]], color='green', alpha=0.5)  # Согласованные пары\n",
        "        else:\n",
        "            plt.plot([x[i], x[j]], [y[i], y[j]], color='red', alpha=0.5)  # Несогласованные пары\n",
        "\n",
        "plt.title(\"Согласованные и несогласованные пары\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Интерпретация графика:**\n",
        "- Зеленые линии обозначают согласованные пары, а красные — несогласованные.\n",
        "- Чем больше зеленых линий, тем выше корреляция Кендалла.\n",
        "\n",
        "### Вопросы для самопроверки\n",
        "\n",
        "1. Что такое коэффициент корреляции ($r$)?\n",
        "2. Какой диапазон значений может принимать коэффициент корреляции?\n",
        "3. Что означает значение $r = 1$ в контексте корреляции?\n",
        "4. Что означает значение $r = -1$ в контексте корреляции?\n",
        "5. Как интерпретировать значение $r = 0$?\n",
        "6. Какую формулу используют для вычисления коэффициента корреляции между двумя переменными?\n",
        "7. Что такое выборочный коэффициент корреляции, и как он соотносится с истинным параметром популяции ($\\rho$)?\n",
        "8. Как влияет размер выборки на точность оценки коэффициента корреляции?\n",
        "9. Что такое тест на равенство коэффициента корреляции нулю?\n",
        "10. Какую статистику используют для проверки гипотезы о равенстве коэффициента корреляции нулю?\n",
        "11. Что такое критерий $\\chi^2$, и для каких задач его применяют?\n",
        "12. Какую формулу используют для расчета статистики $\\chi^2$?\n",
        "13. Что означает отклонение наблюдаемых частот от ожидаемых в критерии $\\chi^2$?\n",
        "14. Что такое критерий знаков, и для каких данных его используют?\n",
        "15. Как рассчитывают статистику $Z$ в критерии знаков?\n",
        "16. Когда используется нормальное приближение в критерии знаков?\n",
        "17. Что такое частичная корреляция?\n",
        "18. Какую формулу используют для вычисления частичной корреляции?\n",
        "19. Для чего применяется корреляция Спирмена?\n",
        "20. Как отличается корреляция Спирмена от обычного коэффициента корреляции Пирсона?\n",
        "21. Какую формулу используют для вычисления коэффициента корреляции Спирмена?\n",
        "22. Что такое корреляция Кендалла, и чем она отличается от корреляции Спирмена?\n",
        "23. Какую формулу используют для вычисления коэффициента корреляции Кендалла?\n",
        "24. Что означают согласованные и несогласованные пары в контексте корреляции Кендалла?\n",
        "25. Как интерпретировать результаты теста на равенство коэффициента корреляции нулю?\n",
        "26. Что такое $p$-значение, и как его использовать для принятия решения по гипотезам?\n",
        "27. Как строится график рассеяния для визуализации корреляции между двумя переменными?\n",
        "28. Что показывает тепловая карта (heatmap) в анализе таблицы сопряженности?\n",
        "29. Какие преимущества имеет непараметрический метод корреляции (например, Спирмена или Кендалла)?\n",
        "30. В каких случаях целесообразно использовать частичную корреляцию?\n",
        "\n",
        "\n",
        "### Задачи для самостоятельной работы\n",
        "\n",
        "\n",
        "1. Вычислите коэффициент корреляции между следующими данными:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [2, 4, 6, 8, 10]$.\n",
        "2. Постройте график рассеяния для данных из задачи 1 и добавьте линию регрессии.\n",
        "3. Проверьте гипотезу о равенстве коэффициента корреляции нулю для данных из задачи 1 при уровне значимости $\\alpha = 0.05$.\n",
        "4. Вычислите коэффициент корреляции для следующих данных:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [5, 4, 3, 2, 1]$.\n",
        "5. Интерпретируйте результаты из задачи 4.\n",
        "6. Постройте график рассеяния для данных из задачи 4 и добавьте линию регрессии.\n",
        "7. Проверьте гипотезу о равенстве коэффициента корреляции нулю для данных из задачи 4 при уровне значимости $\\alpha = 0.05$.\n",
        "\n",
        "8. Даны следующие данные в таблице сопряженности:  \n",
        "   |       | Группа A | Группа B |\n",
        "   |-------|----------|----------|\n",
        "   | Успех | 10       | 20       |\n",
        "   | Неудача | 15      | 25       |  \n",
        "   Проверьте независимость переменных при уровне значимости $\\alpha = 0.05$.\n",
        "9. Постройте тепловую карту для данных из задачи 8.\n",
        "10. Интерпретируйте результаты теста из задачи 8.\n",
        "\n",
        "11. Даны разности между парами значений: $[1, -2, 3, -4, 5, -6, 7, -8]$. Проверьте гипотезу о равенстве медиан нулю при уровне значимости $\\alpha = 0.05$.\n",
        "12. Постройте гистограмму разностей для данных из задачи 11.\n",
        "13. Интерпретируйте результаты теста из задачи 11.\n",
        "\n",
        "14. Вычислите частичную корреляцию между $x$ и $y$, контролируя $z$, для следующих данных:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [2, 4, 6, 8, 10]$, $z = [5, 6, 7, 8, 9]$.\n",
        "15. Постройте матрицу корреляций для данных из задачи 14.\n",
        "16. Интерпретируйте результаты частичной корреляции из задачи 14.\n",
        "\n",
        "17. Вычислите коэффициент корреляции Спирмена для следующих данных:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [5, 4, 3, 2, 1]$.\n",
        "18. Постройте график рассеяния с рангами для данных из задачи 17.\n",
        "19. Интерпретируйте результаты корреляции Спирмена из задачи 17.\n",
        "\n",
        "20. Вычислите коэффициент корреляции Кендалла для следующих данных:  \n",
        "   $x = [1, 2, 3, 4, 5]$, $y = [5, 4, 3, 2, 1]$.\n",
        "21. Постройте график рассеяния и отметьте согласованные/несогласованные пары для данных из задачи 20.\n",
        "22. Интерпретируйте результаты корреляции Кендалла из задачи 20.\n",
        "\n",
        "23. Загрузите датасет `tips` из библиотеки `seaborn`. Вычислите коэффициент корреляции между суммой счета (`total_bill`) и чаевых (`tip`).\n",
        "24. Проверьте гипотезу о равенстве коэффициента корреляции нулю для данных из задачи 23 при уровне значимости $\\alpha = 0.05$.\n",
        "25. Вычислите частичную корреляцию между `total_bill` и `tip`, контролируя количество человек (`size`), для данных из задачи 23.\n",
        "26. Вычислите коэффициент корреляции Спирмена между `total_bill` и `tip` для данных из задачи 23.\n",
        "27. Вычислите коэффициент корреляции Кендалла между `total_bill` и `tip` для данных из задачи 23.\n",
        "28. Постройте матрицу корреляций для всех числовых переменных в датасете `tips`.\n",
        "29. Проверьте независимость категориальных переменных `sex` и `smoker` в датасете `tips` с помощью критерия $\\chi^2$.\n",
        "30. Сформулируйте выводы о взаимосвязях между переменными в датасете `tips` на основе проведенного анализа."
      ],
      "metadata": {
        "id": "peizKmclX8Cx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ### **Глава 14: Непараметрические методы**\n",
        "\n",
        "В предыдущих главах мы рассматривали параметрические статистические методы, которые предполагают, что данные следуют определенному распределению (например, нормальному). Однако в реальных задачах данные часто не соответствуют этим предположениям. В таких случаях на помощь приходят **непараметрические методы**, которые не требуют строгих предположений о распределении данных.\n",
        "\n",
        "В этой главе мы познакомимся с основными непараметрическими тестами и методами, которые помогут вам анализировать данные без жестких ограничений на их свойства. Мы также научимся использовать Python и Google Colab для выполнения этих аналитических процедур.\n",
        "\n",
        "\n",
        "## **1. Критерий Манна-Уитни**\n",
        "\n",
        "#### **Что такое критерий Манна-Уитни?**\n",
        "Критерий Манна-Уитни — это непараметрический тест, который используется для сравнения двух независимых выборок. Он позволяет определить, существует ли значимая разница между распределениями двух групп без предположений о нормальности данных.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "U_1 = n_1 \\cdot n_2 + \\frac{n_1(n_1 + 1)}{2} - R_1,\n",
        "$$\n",
        "где:\n",
        "- $n_1$ и $n_2$ — размеры первой и второй выборок,\n",
        "- $R_1$ — сумма рангов первой выборки.\n",
        "\n",
        "Статистика $U$ сравнивается с критическими значениями из таблиц или вычисляется через нормальное приближение для больших выборок.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Представьте, что вы хотите сравнить эффективность двух разных методов обучения. Для этого вы проводите эксперимент, где одна группа студентов использует метод A, а другая — метод B. После завершения курса вы собираете результаты тестов и хотите узнать, действительно ли один метод лучше другого.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import mannwhitneyu\n",
        "import numpy as np\n",
        "\n",
        "# Результаты тестов для двух групп\n",
        "group_a = np.array([85, 90, 78, 92, 88])  # Метод A\n",
        "group_b = np.array([76, 80, 74, 82, 78])  # Метод B\n",
        "\n",
        "# Выполнение теста\n",
        "stat, p_value = mannwhitneyu(group_a, group_b, alternative='two-sided')\n",
        "\n",
        "# Решение\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    decision = \"Отвергаем H0: группы различаются\"\n",
        "else:\n",
        "    decision = \"Не отвергаем H0: группы не различаются\"\n",
        "\n",
        "print(f\"Статистика U: {stat}, P-значение: {p_value:.4f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Если $p$-значение меньше уровня значимости ($p < \\alpha$), то нулевая гипотеза отвергается, и можно заключить, что распределения групп статистически значимо различаются.\n",
        "- Если $p$-значение больше или равно уровню значимости ($p \\geq \\alpha$), то нулевая гипотеза не отвергается, и данных недостаточно для утверждения о различии.\n",
        "\n",
        "\n",
        "#### **Визуализация распределений**\n",
        "Мы можем построить ящик с усами (boxplot), чтобы визуально сравнить распределения двух групп.\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Визуализация\n",
        "data = [group1, group2]\n",
        "labels = ['Группа 1', 'Группа 2']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot(data, labels=labels, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
        "plt.title(\"Сравнение распределений\")\n",
        "plt.ylabel(\"Значения\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Интерпретация графика:**\n",
        "- Ящик с усами показывает центральные тенденции и разброс значений для каждой группы.\n",
        "- Если ящики значительно перекрываются, это может указывать на отсутствие значимой разницы.\n",
        "- Если ящики не перекрываются или слабо перекрываются, это может указывать на наличие значимой разницы.\n",
        "\n",
        "\n",
        "## **2. Критерий Вилкоксона**\n",
        "\n",
        "#### **Что такое критерий Вилкоксона?**\n",
        "Критерий Вилкоксона — это непараметрический тест для сравнения двух связанных выборок. Он проверяет, существуют ли значимые различия между парами значений, используя ранги разностей.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "W = \\sum_{i=1}^n R_i,\n",
        "$$\n",
        "где:\n",
        "- $R_i$ — ранг положительных разностей (или отрицательных, в зависимости от версии теста),\n",
        "- $n$ — количество пар.\n",
        "\n",
        "Статистика $W$ сравнивается с критическими значениями из таблиц или вычисляется через нормальное приближение для больших выборок.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Вы хотите проверить, улучшилась ли успеваемость студентов после прохождения дополнительных тренировок. Для этого вы сравниваете их результаты до и после тренировок.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "# Результаты до и после тренировок\n",
        "before_training = np.array([70, 75, 80, 85, 90])\n",
        "after_training = np.array([78, 82, 88, 90, 95])\n",
        "\n",
        "# Выполнение теста\n",
        "stat, p_value = wilcoxon(before_training, after_training)\n",
        "\n",
        "# Решение\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    decision = \"Отвергаем H0: есть значимая разница\"\n",
        "else:\n",
        "    decision = \"Не отвергаем H0: нет значимой разницы\"\n",
        "\n",
        "print(f\"Статистика W: {stat}, P-значение: {p_value:.4f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Если $p$-значение меньше уровня значимости ($p < \\alpha$), то нулевая гипотеза отвергается, и можно заключить, что медиана разностей значимо отлична от нуля.\n",
        "- Если $p$-значение больше или равно уровню значимости ($p \\geq \\alpha$), то нулевая гипотеза не отвергается, и данных недостаточно для утверждения о разнице.\n",
        "\n",
        "\n",
        "#### **Визуализация разностей**\n",
        "Мы можем построить график разностей, чтобы визуально оценить их распределение.\n",
        "\n",
        "```python\n",
        "# Разности между парами\n",
        "differences = after - before\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(differences, bins=10, color='blue', edgecolor='black', alpha=0.7)\n",
        "plt.axvline(0, color='red', linestyle='--', label=\"Нулевая отметка\")\n",
        "plt.title(\"Гистограмма разностей\")\n",
        "plt.xlabel(\"Разность\")\n",
        "plt.ylabel(\"Частота\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Интерпретация графика:**\n",
        "- Гистограмма показывает распределение разностей между парами значений.\n",
        "- Если большинство значений сосредоточено вокруг нуля, это может указывать на отсутствие значимой разницы.\n",
        "- Если значения смещены в одну сторону, это может указывать на наличие значимой разницы.\n",
        "\n",
        "\n",
        "## **3. Критерий Краскела-Уоллиса**\n",
        "\n",
        "#### **Что такое критерий Краскела-Уоллиса?**\n",
        "Критерий Краскела-Уоллиса — это обобщение критерия Манна-Уитни для сравнения более чем двух независимых выборок. Он позволяет определить, существуют ли значимые различия между распределениями нескольких групп.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "H = \\frac{12}{N(N+1)} \\sum_{i=1}^k \\frac{R_i^2}{n_i} - 3(N+1),\n",
        "$$\n",
        "где:\n",
        "- $N = \\sum_{i=1}^k n_i$ — общее количество наблюдений,\n",
        "- $n_i$ — размер $i$-й выборки,\n",
        "- $R_i$ — сумма рангов $i$-й выборки,\n",
        "- $k$ — количество групп.\n",
        "\n",
        "Статистика $H$ следует распределению $\\chi^2$ с $k-1$ степенями свободы для больших выборок.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Вы исследуете влияние трех различных диет на снижение веса. Для этого собираете данные о потерянном весе участников каждой группы.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import kruskal\n",
        "\n",
        "# Потерянный вес для трех групп\n",
        "diet_a = np.array([5, 7, 6, 8, 4])  # Диета A\n",
        "diet_b = np.array([3, 2, 4, 5, 3])  # Диета B\n",
        "diet_c = np.array([9, 10, 8, 7, 11])  # Диета C\n",
        "\n",
        "# Выполнение теста\n",
        "stat, p_value = kruskal(diet_a, diet_b, diet_c)\n",
        "\n",
        "# Решение\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    decision = \"Отвергаем H0: группы различаются\"\n",
        "else:\n",
        "    decision = \"Не отвергаем H0: группы не различаются\"\n",
        "\n",
        "print(f\"Статистика H: {stat}, P-значение: {p_value:.4f}\")\n",
        "print(f\"Решение: {decision}\")\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Если $p$-значение меньше уровня значимости ($p < \\alpha$), то нулевая гипотеза отвергается, и можно заключить, что хотя бы одна группа отличается от остальных.\n",
        "- Если $p$-значение больше или равно уровню значимости ($p \\geq \\alpha$), то нулевая гипотеза не отвергается, и данных недостаточно для утверждения о различии.\n",
        "\n",
        "\n",
        "#### **Визуализация распределений**\n",
        "Мы можем построить ящик с усами для всех групп.\n",
        "\n",
        "```python\n",
        "# Визуализация\n",
        "data = [group1, group2, group3]\n",
        "labels = ['Группа 1', 'Группа 2', 'Группа 3']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot(data, labels=labels, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
        "plt.title(\"Сравнение распределений\")\n",
        "plt.ylabel(\"Значения\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Интерпретация графика:**\n",
        "- Ящик с усами показывает центральные тенденции и разброс значений для каждой группы.\n",
        "- Если ящики значительно перекрываются, это может указывать на отсутствие значимых различий.\n",
        "- Если ящики не перекрываются или слабо перекрываются, это может указывать на наличие значимых различий.\n",
        "\n",
        "\n",
        "## **4. Критерий Кендалла**\n",
        "\n",
        "#### **Что такое критерий Кендалла?**\n",
        "Критерий Кендалла ($\\tau$) — это метод для измерения монотонной связи между двумя переменными. Он основан на количестве согласованных и несогласованных пар в данных.\n",
        "\n",
        "#### **Формула:**\n",
        "$$\n",
        "\\tau = \\frac{C - D}{\\binom{n}{2}},\n",
        "$$\n",
        "где:\n",
        "- $C$ — количество согласованных пар,\n",
        "- $D$ — количество несогласованных пар,\n",
        "- $\\binom{n}{2}$ — общее количество пар.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Вы хотите проверить, существует ли связь между оценками преподавателей и отзывами студентов. Для этого вы сравниваете ранги, присвоенные каждому преподавателю.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.stats import kendalltau\n",
        "\n",
        "# Ранги оценок преподавателей и отзывов студентов\n",
        "teacher_ratings = np.array([1, 2, 3, 4, 5])  # Оценки преподавателей\n",
        "student_reviews = np.array([5, 4, 3, 2, 1])  # Отзывы студентов\n",
        "\n",
        "# Корреляция Кендалла\n",
        "kendall_corr, kendall_pval = kendalltau(teacher_ratings, student_reviews)\n",
        "\n",
        "print(f\"Корреляция Кендалла: {kendall_corr:.4f}, P-значение: {kendall_pval:.4f}\")\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Если коэффициент корреляции близок к $1$, то существует сильная положительная монотонная связь.\n",
        "- Если коэффициент корреляции близок к $-1$, то существует сильная отрицательная монотонная связь.\n",
        "- Если коэффициент корреляции близок к $0$, то монотонной связи между переменными нет.\n",
        "- Если $p$-значение меньше уровня значимости ($p < \\alpha$), то корреляция является статистически значимой.\n",
        "\n",
        "\n",
        "\n",
        "#### **Визуализация согласованных и несогласованных пар**\n",
        "Мы можем построить график рассеяния и отметить согласованные/несогласованные пары.\n",
        "\n",
        "```python\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x, y, color='blue', label='Пары')\n",
        "for i in range(len(x)):\n",
        "    for j in range(i + 1, len(x)):\n",
        "        if (x[i] < x[j] and y[i] < y[j]) or (x[i] > x[j] and y[i] > y[j]):\n",
        "            plt.plot([x[i], x[j]], [y[i], y[j]], color='green', alpha=0.5)  # Согласованные пары\n",
        "        else:\n",
        "            plt.plot([x[i], x[j]], [y[i], y[j]], color='red', alpha=0.5)  # Несогласованные пары\n",
        "\n",
        "plt.title(\"Согласованные и несогласованные пары\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Интерпретация графика:**\n",
        "- Зеленые линии обозначают согласованные пары, а красные — несогласованные.\n",
        "- Чем больше зеленых линий, тем выше корреляция Кендалла.\n",
        "\n",
        "\n",
        "\n",
        "## **5. Непараметрическая регрессия**\n",
        "\n",
        "#### **Что такое непараметрическая регрессия?**\n",
        "Непараметрическая регрессия — это метод, который не требует задания конкретной формы функциональной зависимости между переменными. Один из популярных подходов — ядерная регрессия (Kernel Regression).\n",
        "\n",
        "#### **Пример использования:**\n",
        "Вы хотите построить модель зависимости дохода от возраста, но не уверены, что эта зависимость линейная.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Исходные данные\n",
        "age = np.array([20, 25, 30, 35, 40, 45, 50]).reshape(-1, 1)  # Возраст\n",
        "income = np.array([30, 40, 50, 60, 70, 80, 90])  # Доход\n",
        "\n",
        "# Ядерная регрессия\n",
        "model = KernelRidge(alpha=0.1, kernel='rbf')\n",
        "model.fit(age, income)\n",
        "\n",
        "# Предсказание\n",
        "age_pred = np.linspace(18, 55, 100).reshape(-1, 1)\n",
        "income_pred = model.predict(age_pred)\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(age, income, color='blue', label='Данные')\n",
        "plt.plot(age_pred, income_pred, color='red', label='Ядерная регрессия')\n",
        "plt.title(\"Зависимость дохода от возраста\")\n",
        "plt.xlabel(\"Возраст\")\n",
        "plt.ylabel(\"Доход\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- График показывает нелинейную зависимость между возрастом и доходом.\n",
        "- Если модель хорошо аппроксимирует данные, это указывает на наличие сложной зависимости, которую нельзя описать линейной функцией.\n",
        "\n",
        "\n",
        "### Вопросы для самопроверки\n",
        "\n",
        "1. Что такое непараметрические методы, и чем они отличаются от параметрических?\n",
        "2. Какие предположения делают параметрические методы, которые не требуются в непараметрических?\n",
        "3. Что такое критерий Манна-Уитни, и для каких данных он используется?\n",
        "4. Как интерпретировать результаты теста Манна-Уитни?\n",
        "5. Что такое статистика $U$ в тесте Манна-Уитни?\n",
        "6. Когда лучше использовать тест Манна-Уитни вместо t-теста?\n",
        "7. Что такое критерий Вилкоксона, и для каких выборок он предназначен?\n",
        "8. Как вычисляется статистика $W$ в тесте Вилкоксона?\n",
        "9. Как интерпретировать $p$-значение в тесте Вилкоксона?\n",
        "10. В чем разница между тестами Манна-Уитни и Вилкоксона?\n",
        "11. Что такое критерий Краскела-Уоллиса, и когда его применяют?\n",
        "12. Какую формулу используют для расчета статистики $H$ в тесте Краскела-Уоллиса?\n",
        "13. Как интерпретировать результаты теста Краскела-Уоллиса?\n",
        "14. Какие графические методы можно использовать для визуализации данных при работе с тестом Краскела-Уоллиса?\n",
        "15. Что такое корреляция Кендалла, и чем она отличается от корреляции Пирсона?\n",
        "16. Как рассчитывается коэффициент $\\tau$ в корреляции Кендалла?\n",
        "17. Что означают согласованные и несогласованные пары в контексте корреляции Кендалла?\n",
        "18. Как интерпретировать значения коэффициента корреляции Кендалла?\n",
        "19. Что такое непараметрическая регрессия, и для каких задач она применяется?\n",
        "20. Какой метод используется для реализации непараметрической регрессии?\n",
        "21. Что такое ядерная регрессия, и какие типы ядер можно использовать?\n",
        "22. Как выбрать оптимальное значение гиперпараметра $\\alpha$ в ядерной регрессии?\n",
        "23. Что такое критерий знаков, и для каких данных он используется?\n",
        "24. Как вычисляется статистика $Z$ в критерии знаков?\n",
        "25. Когда лучше использовать нормальное приближение в критерии знаков?\n",
        "26. Что такое частичная корреляция, и как она помогает анализировать данные?\n",
        "27. Какую формулу используют для вычисления частичной корреляции?\n",
        "28. Что такое корреляция Спирмена, и чем она отличается от корреляции Пирсона?\n",
        "29. Как рассчитывается коэффициент $\\rho$ в корреляции Спирмена?\n",
        "30. Как интерпретировать значения коэффициента корреляции Спирмена?\n",
        "\n",
        "\n",
        "\n",
        "### Задачи для самостоятельной работы\n",
        "\n",
        "#### Задачи по критерию Манна-Уитни\n",
        "1. Даны две независимые выборки:  \n",
        "   Группа A = [10, 12, 15, 18, 20],  \n",
        "   Группа B = [8, 9, 11, 13, 14].  \n",
        "   Проверьте гипотезу о равенстве распределений двух групп при уровне значимости $\\alpha = 0.05$.\n",
        "2. Реализуйте тест Манна-Уитни на Python для данных из задачи 1.\n",
        "3. Постройте график ящиков с усами для данных из задачи 1.\n",
        "4. Сравните результаты теста Манна-Уитни с t-тестом для данных из задачи 1.\n",
        "5. Даны две связанные выборки:  \n",
        "   До тренировки = [70, 75, 80, 85, 90],  \n",
        "   После тренировки = [78, 82, 88, 90, 95].  \n",
        "   Проверьте гипотезу о наличии значимой разницы между парами значений при уровне значимости $\\alpha = 0.05$.\n",
        "6. Реализуйте тест Вилкоксона на Python для данных из задачи 5.\n",
        "7. Постройте график разностей между парами значений для данных из задачи 5.\n",
        "8. Сравните результаты теста Вилкоксона с тестом знаковых рангов для данных из задачи 5.\n",
        "9. Даны три независимые выборки:  \n",
        "   Группа A = [5, 7, 6, 8, 4],  \n",
        "   Группа B = [3, 2, 4, 5, 3],  \n",
        "   Группа C = [9, 10, 8, 7, 11].  \n",
        "   Проверьте гипотезу о равенстве распределений трех групп при уровне значимости $\\alpha = 0.05$.\n",
        "10. Реализуйте тест Краскела-Уоллиса на Python для данных из задачи 9.\n",
        "11. Постройте график ящиков с усами для данных из задачи 9.\n",
        "12. Сравните результаты теста Краскела-Уоллиса с ANOVA для данных из задачи 9.\n",
        "13. Вычислите коэффициент корреляции Кендалла для следующих данных:  \n",
        "    $x = [1, 2, 3, 4, 5]$,  \n",
        "    $y = [5, 4, 3, 2, 1]$.\n",
        "14. Реализуйте вычисление коэффициента корреляции Кендалла на Python для данных из задачи 13.\n",
        "15. Постройте график рассеяния для данных из задачи 13 и отметьте согласованные/несогласованные пары.\n",
        "16. Интерпретируйте результаты корреляции Кендалла для данных из задачи 13.\n",
        "17. Загрузите датасет `tips` из библиотеки `seaborn`. Постройте модель непараметрической регрессии зависимости суммы счета (`total_bill`) от количества человек (`size`).\n",
        "18. Оцените качество модели непaramетрической регрессии из задачи 17 с помощью метрики $R^2$.\n",
        "19. Сравните результаты непараметрической регрессии с линейной регрессией для данных из задачи 17.\n",
        "20. Постройте график предсказаний модели непараметрической регрессии для данных из задачи 17.\n",
        "21. Даны разности между парами значений: $[1, -2, 3, -4, 5, -6, 7, -8]$. Проверьте гипотезу о равенстве медиан нулю при уровне значимости $\\alpha = 0.05$.\n",
        "22. Реализуйте тест знаков на Python для данных из задачи 21.\n",
        "23. Постройте гистограмму разностей для данных из задачи 21.\n",
        "24. Сравните результаты теста знаков с тестом Вилкоксона для данных из задачи 21.\n",
        "25. Загрузите датасет `iris` из библиотеки `seaborn`. Вычислите частичную корреляцию между шириной лепестка (`petal_width`) и длиной чашелистика (`sepal_length`), контролируя ширину чашелистика (`sepal_width`).\n",
        "26. Постройте матрицу корреляций для всех числовых переменных в датасете `iris`.\n",
        "27. Интерпретируйте результаты частичной корреляции из задачи 25.\n",
        "28. Вычислите коэффициент корреляции Спирмена для следующих данных:  \n",
        "    $x = [1, 2, 3, 4, 5]$,  \n",
        "    $y = [5, 4, 3, 2, 1]$.\n",
        "29. Реализуйте вычисление коэффициента корреляции Спирмена на Python для данных из задачи 28.\n",
        "30. Постройте график рассеяния с рангами для данных из задачи 28."
      ],
      "metadata": {
        "id": "ApOadJUNdzvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **15. Байесовская статистика**\n",
        "\n",
        "### **Введение**\n",
        "Байесовская статистика представляет собой подход к анализу данных, который позволяет обновлять наши знания о параметрах модели на основе новых наблюдений. В отличие от классической (частотной) статистики, байесовский подход рассматривает параметры как случайные величины и использует вероятностные распределения для их описания. Этот метод особенно полезен, когда у нас есть предварительная информация о параметрах или данные ограничены.\n",
        "\n",
        "Основная формула, лежащая в основе байесовского подхода, называется **формулой Байеса**:\n",
        "$$\n",
        "P(\\theta | D) = \\frac{P(D | \\theta) P(\\theta)}{P(D)},\n",
        "$$\n",
        "где:\n",
        "- $P(\\theta)$ — априорное распределение параметров $\\theta$,\n",
        "- $P(D | \\theta)$ — правдоподобие данных $D$ при заданных параметрах $\\theta$,\n",
        "- $P(D)$ — нормализующий коэффициент (вероятность данных),\n",
        "- $P(\\theta | D)$ — апостериорное распределение параметров $\\theta$ после учета данных $D$.\n",
        "\n",
        "Апостериорное распределение является основным результатом байесовского анализа и показывает, как наши представления о параметрах меняются после получения новых данных.\n",
        "\n",
        "\n",
        "\n",
        "### **1. Основы байесовского подхода**\n",
        "\n",
        "#### **Априорные и апостериорные распределения**\n",
        "- **Априорное распределение ($P(\\theta)$):** Отражает наши знания о параметрах до того, как мы увидели данные. Например, если мы знаем, что параметр должен находиться в определенном диапазоне значений, мы можем выбрать соответствующее априорное распределение.\n",
        "- **Апостериорное распределение ($P(\\theta | D)$):** Объединяет информацию из априорного распределения и данных. Это финальное распределение, которое мы получаем после анализа.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Представьте, что вы хотите оценить вероятность успеха нового лекарства ($\\theta$). Перед началом эксперимента у вас есть априорное предположение о вероятности успеха (например, равномерное распределение). После проведения эксперимента с $n$ испытаниями и $k$ успехами, вы можете обновить свое представление о $\\theta$ с помощью теоремы Байеса.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import beta\n",
        "\n",
        "# Априорное распределение (Beta(1, 1) — равномерное)\n",
        "a_prior = 1\n",
        "b_prior = 1\n",
        "\n",
        "# Данные: k успехов из n испытаний\n",
        "k = 8\n",
        "n = 10\n",
        "\n",
        "# Обновление параметров априорного распределения\n",
        "a_posterior = a_prior + k\n",
        "b_posterior = b_prior + n - k\n",
        "\n",
        "# Генерация значений для графика\n",
        "x = np.linspace(0, 1, 100)\n",
        "prior_pdf = beta.pdf(x, a_prior, b_prior)\n",
        "posterior_pdf = beta.pdf(x, a_posterior, b_posterior)\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(x, prior_pdf, label='Априорное распределение', color='blue')\n",
        "plt.plot(x, posterior_pdf, label='Апостериорное распределение', color='red')\n",
        "plt.title(\"Обновление распределения с помощью теоремы Байеса\")\n",
        "plt.xlabel(\"Вероятность успеха ($\\\\theta$)\")\n",
        "plt.ylabel(\"Плотность вероятности\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Априорное распределение отражает начальные знания о параметре.\n",
        "- Апостериорное распределение показывает обновленные знания после учета данных.\n",
        "- Чем больше данных, тем уже становится апостериорное распределение, указывая на большую уверенность в оценке параметра.\n",
        "\n",
        "\n",
        "\n",
        "## **2. Байесовские методы для оценки параметров**\n",
        "\n",
        "#### **Что такое байесовская оценка параметров?**\n",
        "Байесовская оценка параметров заключается в использовании апостериорного распределения для получения точечных или интервальных оценок параметров модели. Это может быть сделано через среднее значение, медиану или наиболее вероятное значение (мода) апостериорного распределения.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Представьте, что вы хотите оценить среднее время выполнения задачи ($\\mu$) с использованием нормального распределения. У вас есть априорное предположение о возможных значениях $\\mu$, и вы собираете данные для обновления этого предположения.\n",
        "\n",
        "#### **Формула для нормального распределения:**\n",
        "Если априорное распределение параметра $\\mu$ является нормальным ($N(\\mu_0, \\sigma_0^2)$), а данные следуют нормальному распределению ($N(\\mu, \\sigma^2)$), то апостериорное распределение также будет нормальным:\n",
        "$$\n",
        "\\mu_{\\text{post}} = \\frac{\\sigma^2 \\mu_0 + n \\bar{x} \\sigma_0^2}{\\sigma^2 + n \\sigma_0^2},\n",
        "$$\n",
        "$$\n",
        "\\sigma_{\\text{post}}^2 = \\left(\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}\\right)^{-1}.\n",
        "$$\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Априорные параметры\n",
        "mu_prior = 5\n",
        "sigma_prior = 2\n",
        "\n",
        "# Данные\n",
        "data = np.array([4, 5, 6, 7, 8])\n",
        "n = len(data)\n",
        "mean_data = np.mean(data)\n",
        "sigma_data = 1  # Стандартное отклонение данных\n",
        "\n",
        "# Обновление параметров\n",
        "mu_post = (sigma_data**2 * mu_prior + n * mean_data * sigma_prior**2) / (sigma_data**2 + n * sigma_prior**2)\n",
        "sigma_post = ((1 / sigma_prior**2) + (n / sigma_data**2))**(-0.5)\n",
        "\n",
        "# Генерация значений для графика\n",
        "x = np.linspace(0, 10, 100)\n",
        "prior_pdf = norm.pdf(x, mu_prior, sigma_prior)\n",
        "posterior_pdf = norm.pdf(x, mu_post, sigma_post)\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(x, prior_pdf, label='Априорное распределение', color='blue')\n",
        "plt.plot(x, posterior_pdf, label='Апостериорное распределение', color='red')\n",
        "plt.title(\"Оценка параметра с помощью байесовского подхода\")\n",
        "plt.xlabel(\"Среднее время выполнения ($\\\\mu$)\")\n",
        "plt.ylabel(\"Плотность вероятности\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Априорное распределение отражает начальные знания о среднем времени выполнения задачи.\n",
        "- Апостериорное распределение показывает обновленные знания после учета данных.\n",
        "- Точечная оценка параметра может быть получена как среднее или мода апостериорного распределения.\n",
        "\n",
        "\n",
        "\n",
        "## **3. Метод Метropolis-Hastings**\n",
        "\n",
        "#### **Что такое метод Метropolis-Hastings?**\n",
        "Метод Метropolis-Hastings — это алгоритм Монте-Карло для приближенного вычисления сложных апостериорных распределений, когда их аналитическая форма неизвестна. Он используется для генерации выборок из апостериорного распределения.\n",
        "\n",
        "#### **Алгоритм:**\n",
        "1. Начните с произвольной точки $\\theta^{(0)}$.\n",
        "2. На каждой итерации:\n",
        "   - Предложите новое значение $\\theta^*$ из предложенного распределения $q(\\theta^* | \\theta^{(t)})$.\n",
        "   - Вычислите отношение принятия:\n",
        "     $$\n",
        "     \\alpha = \\min\\left(1, \\frac{P(\\theta^* | D) q(\\theta^{(t)} | \\theta^*)}{P(\\theta^{(t)} | D) q(\\theta^* | \\theta^{(t)})}\\right).\n",
        "     $$\n",
        "   - С вероятностью $\\alpha$ примите новое значение ($\\theta^{(t+1)} = \\theta^*$), иначе останьтесь на старом ($\\theta^{(t+1)} = \\theta^{(t)}$).\n",
        "3. Повторите шаги 2 много раз.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Вы хотите оценить апостериорное распределение параметра $\\theta$ для модели с известным правдоподобием $P(D | \\theta)$ и априорным распределением $P(\\theta)$.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Функция плотности апостериорного распределения\n",
        "def posterior(theta):\n",
        "    likelihood = np.exp(-((theta - 5)**2) / 2)  # Пример правдоподобия\n",
        "    prior = np.exp(-((theta - 4)**2) / 4)       # Пример априорного распределения\n",
        "    return likelihood * prior\n",
        "\n",
        "# Метод Метropolis-Hastings\n",
        "np.random.seed(42)\n",
        "theta = 0  # Начальное значение\n",
        "samples = []\n",
        "num_samples = 10000\n",
        "\n",
        "for _ in range(num_samples):\n",
        "    theta_star = np.random.normal(theta, 1)  # Предложенное значение\n",
        "    alpha = min(1, posterior(theta_star) / posterior(theta))\n",
        "    if np.random.rand() < alpha:\n",
        "        theta = theta_star\n",
        "    samples.append(theta)\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(samples, bins=50, density=True, alpha=0.7, color='blue', label='Выборка MH')\n",
        "x = np.linspace(0, 10, 100)\n",
        "plt.plot(x, posterior(x), color='red', label='Апостериорное распределение')\n",
        "plt.title(\"Метод Метropolis-Hastings\")\n",
        "plt.xlabel(\"$\\\\theta$\")\n",
        "plt.ylabel(\"Плотность вероятности\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Алгоритм генерирует выборку из апостериорного распределения.\n",
        "- Гистограмма выборки приближенно воспроизводит форму апостериорного распределения.\n",
        "- Этот метод особенно полезен для сложных моделей, где аналитическое решение невозможно.\n",
        "\n",
        "\n",
        "### Вопросы для самопроверки\n",
        "\n",
        "1. Что такое байесовская статистика?\n",
        "2. Какая формула лежит в основе байесовского подхода?\n",
        "3. Что представляет собой априорное распределение ($P(\\theta)$)?\n",
        "4. Что означает апостериорное распределение ($P(\\theta | D)$)?\n",
        "5. Как интерпретировать нормализующий коэффициент $P(D)$ в формуле Байеса?\n",
        "6. Какой основной вывод можно сделать из байесовского анализа?\n",
        "7. Почему байесовский подход полезен при работе с ограниченными данными?\n",
        "8. Что такое равномерное априорное распределение? Когда его используют?\n",
        "9. Как изменяется апостериорное распределение при увеличении объема данных?\n",
        "10. Что такое правдоподобие ($P(D | \\theta)$) и как оно используется в байесовском анализе?\n",
        "11. Как вычислить точечную оценку параметра на основе апостериорного распределения?\n",
        "12. Какие методы можно использовать для получения интервальной оценки параметра?\n",
        "13. Что такое мода апостериорного распределения и как ее найти?\n",
        "14. Как влияет выбор априорного распределения на результат байесовского анализа?\n",
        "15. Что такое информативное априорное распределение? Приведите пример.\n",
        "16. Что такое неинформативное априорное распределение? Когда его применяют?\n",
        "17. Как обновляются параметры априорного распределения после получения новых данных?\n",
        "18. Что такое бета-распределение и почему оно часто используется в байесовских моделях?\n",
        "19. Какое распределение получается в результате байесовского анализа, если данные следуют нормальному распределению?\n",
        "20. Как меняется среднее значение апостериорного распределения при использовании нормального распределения для параметров?\n",
        "21. Что такое метод Метropolis-Hastings?\n",
        "22. Для чего используется метод Метropolis-Hastings в байесовской статистике?\n",
        "23. Как генерируются выборки в методе Метropolis-Hastings?\n",
        "24. Что такое отношение принятия ($\\alpha$) в методе Метropolis-Hastings?\n",
        "25. Как определить, что выборка, сгенерированная методом Метropolis-Hastings, достаточно хорошо аппроксимирует апостериорное распределение?\n",
        "26. Какую роль играет предложенное распределение ($q(\\theta^* | \\theta^{(t)})$) в методе Метropolis-Hastings?\n",
        "27. Как проверить сходимость алгоритма Метropolis-Hastings?\n",
        "28. Какие преимущества имеет байесовский подход по сравнению с частотным подходом?\n",
        "29. Какие ограничения есть у байесовского подхода?\n",
        "30. Приведите пример практического применения байесовской статистики.\n",
        "\n",
        "### Задачи для самостоятельной работы\n",
        "\n",
        "#### **Задачи по основам байесовского подхода:**\n",
        "1. Пусть априорное распределение параметра $\\theta$ является равномерным на отрезке [0, 1]. После проведения эксперимента с $n = 10$ испытаниями и $k = 7$ успехами, найдите апостериорное распределение $\\theta$.\n",
        "2. Дана модель с априорным распределением $\\theta \\sim Beta(2, 3)$. После получения данных с $n = 15$ испытаниями и $k = 9$ успехами, найдите параметры апостериорного распределения.\n",
        "3. Постройте график апостериорного распределения для задачи 2.\n",
        "4. Пусть априорное распределение параметра $\\mu$ — нормальное с параметрами $\\mu_0 = 5$, $\\sigma_0 = 2$. После сбора данных с $n = 10$, $\\bar{x} = 6$, $\\sigma = 1$, найдите параметры апостериорного распределения.\n",
        "5. Найдите медиану апостериорного распределения для задачи 4.\n",
        "6. Используя метод максимального правдоподобия, оцените параметр $\\theta$ для модели с функцией правдоподобия $L(\\theta) = \\theta^k (1 - \\theta)^{n-k}$, где $n = 10$, $k = 3$.\n",
        "7. Сравните результат задачи 6 с байесовской оценкой параметра $\\theta$, используя априорное распределение $\\theta \\sim Beta(1, 1)$.\n",
        "8. Пусть априорное распределение параметра $\\lambda$ экспоненциального распределения — $\\lambda \\sim Gamma(2, 3)$. После наблюдения $n = 5$ событий с временем между ними $t_1, t_2, ..., t_5$, найдите апостериорное распределение $\\lambda$.\n",
        "9. Найдите моду апостериорного распределения для задачи 8.\n",
        "10. Постройте график апостериорного распределения для задачи 8.\n",
        "11. Реализуйте метод Метropolis-Hastings для модели с апостериорным распределением $P(\\theta | D) \\propto e^{-\\theta^2 / 2}$. Сгенерируйте 10,000 выборок.\n",
        "12. Проверьте сходимость алгоритма Метropolis-Hastings для задачи 11, построив графики трендов и автокорреляции.\n",
        "13. Измените параметры предложенного распределения в задаче 11 и проанализируйте влияние на эффективность алгоритма.\n",
        "14. Пусть апостериорное распределение задано как $P(\\theta | D) \\propto \\theta^{k-1} (1-\\theta)^{n-k}$, где $n = 20$, $k = 12$. Используйте метод Метropolis-Hastings для генерации выборки размером 5,000.\n",
        "15. Постройте гистограмму выборки из задачи 14 и сравните ее с теоретическим распределением.\n",
        "16. Исследователь провел эксперимент, чтобы оценить вероятность успеха нового лекарства. После 20 испытаний было зафиксировано 15 успехов. Используя байесовский подход с равномерным априорным распределением, найдите апостериорное распределение вероятности успеха.\n",
        "17. Анализируя данные о времени выполнения задач, исследователь предполагает, что среднее время выполнения $\\mu$ имеет нормальное априорное распределение с параметрами $\\mu_0 = 5$, $\\sigma_0 = 1$. После сбора данных с $n = 20$, $\\bar{x} = 6$, $\\sigma = 0.5$, найдите апостериорное распределение $\\mu$.\n",
        "18. Реализуйте программу для расчета апостериорного распределения параметра $\\theta$ для модели с биномиальным правдоподобием и бета-априорным распределением.\n",
        "19. Постройте графики априорного и апостериорного распределений для задачи 18.\n",
        "20. Пусть параметр $\\lambda$ пуассоновского распределения имеет гамма-априорное распределение с параметрами $a = 2$, $b = 3$. После наблюдения $n = 10$ событий, найдите апостериорное распределение $\\lambda$.\n",
        "21. Реализуйте метод Метropolis-Hastings для модели с двумя параметрами ($\\theta_1, \\theta_2$).\n",
        "22. Проверьте, как изменяется форма апостериорного распределения при использовании различных априорных распределений для одного и тех же данных.\n",
        "23. Исследуйте влияние объема данных на ширину апостериорного распределения.\n",
        "24. Сравните результаты байесовского анализа с результатами классического частотного подхода для одной и той же задачи.\n",
        "25. Реализуйте байесовскую модель для оценки параметров линейной регрессии.\n",
        "26. Постройте графики апостериорных распределений параметров в задаче 25.\n",
        "27. Пусть данные имеют нормальное распределение с неизвестным средним $\\mu$ и известной дисперсией $\\sigma^2 = 1$. Найдите апостериорное распределение $\\mu$ при использовании нормального априорного распределения.\n",
        "28. Реализуйте программу для расчета доверительных интервалов для параметра $\\theta$ на основе апостериорного распределения.\n",
        "29. Исследуйте, как меняется форма апостериорного распределения при использовании различных предложенных распределений в методе Метropolis-Hastings.\n",
        "30. Разработайте собственную модель для байесовского анализа и проведите численный эксперимент для ее проверки."
      ],
      "metadata": {
        "id": "FZtixDeTiKiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **16. Многомерный анализ данных**\n",
        "\n",
        "### **1. Метод Главных Компонент (PCA)**\n",
        "\n",
        "#### **Что такое PCA?**\n",
        "Метод главных компонент (PCA) — это техника снижения размерности данных, которая преобразует исходные переменные в новый набор независимых переменных (главных компонент), упорядоченных по их способности объяснять дисперсию данных.\n",
        "\n",
        "#### **Формула:**\n",
        "PCA выполняет сингулярное разложение матрицы данных $X$:\n",
        "$$\n",
        "X = U \\Sigma V^T,\n",
        "$$\n",
        "где:\n",
        "- $U$ — матрица левых сингулярных векторов,\n",
        "- $\\Sigma$ — диагональная матрица сингулярных значений,\n",
        "- $V$ — матрица правых сингулярных векторов.\n",
        "\n",
        "Главные компоненты вычисляются как линейные комбинации исходных переменных:\n",
        "$$\n",
        "Z = X V,\n",
        "$$\n",
        "где $Z$ — матрица главных компонент.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Представьте, что у вас есть набор данных с несколькими признаками, и вы хотите снизить размерность данных для визуализации или улучшения производительности модели.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Загрузка данных\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# PCA для снижения размерности до 2 компонент\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolor='k')\n",
        "plt.title(\"PCA: Снижение размерности до 2 компонент\")\n",
        "plt.xlabel(\"Первая главная компонента\")\n",
        "plt.ylabel(\"Вторая главная компонента\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Объясненная дисперсия\n",
        "print(f\"Объясненная дисперсия: {pca.explained_variance_ratio_}\")\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Первые две главные компоненты сохраняют большую часть информации из исходных данных.\n",
        "- График показывает распределение данных в новом пространстве главных компонент.\n",
        "- Объясненная дисперсия указывает, какую долю вариации данных объясняет каждая компонента.\n",
        "\n",
        "\n",
        "\n",
        "## **2. Кластерный анализ**\n",
        "\n",
        "#### **Что такое кластерный анализ?**\n",
        "Кластерный анализ — это метод группировки объектов в кластеры таким образом, чтобы объекты внутри одного кластера были более похожи друг на друга, чем на объекты из других кластеров.\n",
        "\n",
        "#### **Метод k-средних:**\n",
        "Метод k-средних делит данные на $k$ кластеров, минимизируя сумму квадратов расстояний от точек до центроидов своих кластеров.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Вы хотите сегментировать клиентов на основе их покупательского поведения.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Пример данных\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 2)\n",
        "\n",
        "# Кластеризация методом k-средних\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "clusters = kmeans.fit_predict(X)\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', edgecolor='k')\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], s=200, c='red', marker='X', label='Центроиды')\n",
        "plt.title(\"Метод k-средних\")\n",
        "plt.xlabel(\"Признак 1\")\n",
        "plt.ylabel(\"Признак 2\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Каждый объект присвоен одному из трех кластеров.\n",
        "- Центроиды представляют собой средние значения точек в каждом кластере.\n",
        "\n",
        "#### **Иерархическая кластеризация:**\n",
        "Иерархическая кластеризация строит дерево кластеров (дендрограмму), которое показывает структуру связей между объектами.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "\n",
        "# Иерархическая кластеризация\n",
        "Z = linkage(X, method='ward')\n",
        "\n",
        "# Построение дендрограммы\n",
        "plt.figure(figsize=(10, 6))\n",
        "dendrogram(Z)\n",
        "plt.title(\"Дендрограмма\")\n",
        "plt.xlabel(\"Объекты\")\n",
        "plt.ylabel(\"Расстояние\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Дендрограмма показывает, как объекты объединяются в кластеры на разных уровнях расстояния.\n",
        "- Вы можете выбрать количество кластеров, сделав горизонтальный разрез по дендрограмме.\n",
        "\n",
        "\n",
        "## **3. MANOVA (Многомерный дисперсионный анализ)**\n",
        "\n",
        "#### **Что такое MANOVA?**\n",
        "MANOVA — это обобщение ANOVA для случая нескольких зависимых переменных. Он позволяет проверить, существуют ли значимые различия между группами по совокупности зависимых переменных.\n",
        "\n",
        "#### **Гипотезы:**\n",
        "- Нулевая гипотеза ($H_0$): группы не отличаются по совокупности зависимых переменных.\n",
        "- Альтернативная гипотеза ($H_1$): группы отличаются по хотя бы одной из зависимых переменных.\n",
        "\n",
        "#### **Пример использования:**\n",
        "Вы хотите проверить, существует ли влияние типа диеты на несколько параметров здоровья (например, вес, уровень сахара в крови и холестерин).\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "import pandas as pd\n",
        "from statsmodels.multivariate.manova import MANOVA\n",
        "\n",
        "# Исходные данные\n",
        "data = {\n",
        "    'Diet': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
        "    'Weight': [70, 75, 72, 65, 68, 67],\n",
        "    'Sugar': [100, 110, 98, 95, 97, 96],\n",
        "    'Cholesterol': [200, 210, 195, 180, 185, 182]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# MANOVA\n",
        "manova = MANOVA.from_formula('Weight + Sugar + Cholesterol ~ Diet', data=df)\n",
        "print(manova.mv_test())\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- MANOVA предоставляет статистику (например, Wilks' Lambda, Pillai's Trace) и соответствующие $p$-значения для каждой зависимости.\n",
        "- Если $p$-значение меньше уровня значимости ($p < \\alpha$), то нулевая гипотеза отвергается, и можно заключить, что тип диеты влияет на совокупность параметров здоровья.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **4. Multidimensional Scaling (MDS)**\n",
        "\n",
        "#### **Что такое MDS?**\n",
        "MDS — это метод снижения размерности, который пытается сохранить относительные расстояния между объектами в новом пространстве меньшей размерности. В отличие от PCA, который максимизирует объяснённую дисперсию, MDS фокусируется на минимизации ошибки воспроизведения расстояний.\n",
        "\n",
        "#### **Формула:**\n",
        "Цель MDS — найти такую конфигурацию точек $X_{\\text{new}}$ в новом пространстве, чтобы матрица расстояний $D_{\\text{new}}$ была как можно ближе к исходной матрице расстояний $D_{\\text{old}}$. Это достигается минимизацией функции стресса:\n",
        "$$\n",
        "\\text{Stress} = \\sqrt{\\sum_{i<j} (d_{ij}^{\\text{old}} - d_{ij}^{\\text{new}})^2},\n",
        "$$\n",
        "где $d_{ij}$ — расстояние между объектами $i$ и $j$.\n",
        "\n",
        "#### **Пример использования:**\n",
        "MDS полезен, когда у вас есть только информация о расстояниях между объектами, но нет самих координат объектов.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from sklearn.manifold import MDS\n",
        "import matplotlib.pyplot as plt\n",
        "# Искусственные данные\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 5)\n",
        "# MDS для снижения размерности до 2 компонент\n",
        "mds = MDS(n_components=2, random_state=42)\n",
        "X_mds = mds.fit_transform(X)\n",
        "# Визуализация\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_mds[:, 0], X_mds[:, 1], c='blue', edgecolor='k')\n",
        "plt.title(\"MDS: Снижение размерности до 2 компонент\")\n",
        "plt.xlabel(\"Координата 1\")\n",
        "plt.ylabel(\"Координата 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Расположение точек в новом пространстве отражает их относительные расстояния в исходном пространстве.\n",
        "- MDS может быть полезен для визуализации данных, где важны не линейные зависимости, а метрические характеристики.\n",
        "\n",
        "## **5. t-SNE (t-distributed Stochastic Neighbor Embedding)**\n",
        "\n",
        "#### **Что такое t-SNE?**\n",
        "t-SNE — это алгоритм для визуализации высокоразмерных данных, основанный на вероятностной модели. Он особенно эффективен для выявления сложных структур данных и группирования похожих объектов.\n",
        "\n",
        "#### **Основная идея:**\n",
        "t-SNE преобразует расстояния между точками в вероятности схожести. Затем он пытается сохранить эти вероятности в низкоразмерном пространстве, минимизируя Кульбака-Лейблера дивергенцию между двумя распределениями.\n",
        "\n",
        "#### **Преимущества:**\n",
        "- Хорошо работает с нелинейными данными.\n",
        "- Отлично подходит для визуализации данных в двух или трёх измерениях.\n",
        "\n",
        "#### **Недостатки:**\n",
        "- Чувствителен к параметрам (например, perplexity).\n",
        "- Может плохо работать с очень большим количеством объектов.\n",
        "- Не сохраняет глобальную структуру данных.\n",
        "\n",
        "#### **Пример использования:**\n",
        "t-SNE часто используется для визуализации данных в задачах машинного обучения, например, для анализа эмбеддингов слов или изображений.\n",
        "\n",
        "#### **Пример реализации на Python:**\n",
        "```python\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "# Загрузка данных\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "# t-SNE для снижения размерности до 2 компонент\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "# Визуализация\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10', edgecolor='k')\n",
        "plt.title(\"t-SNE: Визуализация набора данных цифр\")\n",
        "plt.xlabel(\"Координата 1\")\n",
        "plt.ylabel(\"Координата 2\")\n",
        "plt.colorbar(label=\"Цифры\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Интерпретация результатов:**\n",
        "- Цветовые группы соответствуют различным классам (цифрам).\n",
        "- t-SNE хорошо разделяет похожие объекты, но может \"складывать\" удалённые группы.\n",
        "\n",
        "\n",
        "\n",
        "### **Сравнение PCA, MDS и t-SNE**\n",
        "\n",
        "| Метод       | Основная цель                     | Преимущества                              | Недостатки                                |\n",
        "|-------------|-----------------------------------|-------------------------------------------|-------------------------------------------|\n",
        "| **PCA**     | Максимизация объяснённой дисперсии | Быстрый, линейный, сохраняет глобальную структуру | Неэффективен для нелинейных зависимостей |\n",
        "| **MDS**     | Сохранение расстояний             | Работает с матрицами расстояний           | Может быть медленным                      |\n",
        "| **t-SNE**   | Визуализация локальных структур   | Отлично показывает кластеры               | Чувствителен к параметрам, теряет глобальную структуру |\n",
        "\n",
        "\n",
        "### **Вопросы для самопроверки**\n",
        "\n",
        "1. Что такое метод главных компонент (PCA)?\n",
        "2. Какие преимущества даёт снижение размерности данных с помощью PCA?\n",
        "3. Объясните, что такое объяснённая дисперсия в PCA.\n",
        "4. Как вычисляются главные компоненты в PCA?\n",
        "5. В чём заключается сингулярное разложение матрицы данных $X$?\n",
        "6. Как интерпретировать первый и второй графики после применения PCA?\n",
        "7. Как выбрать количество главных компонент при использовании PCA?\n",
        "8. Может ли PCA быть применён к категориальным данным? Почему?\n",
        "9. Что такое кластерный анализ?\n",
        "10. Опишите основную цель метода k-средних.\n",
        "11. Как определить оптимальное количество кластеров в методе k-средних?\n",
        "12. Что такое \"метод локтя\" (elbow method) в кластерном анализе?\n",
        "13. Как работает иерархическая кластеризация?\n",
        "14. Что такое дендрограмма и как её интерпретировать?\n",
        "15. Какой метод используется для построения дендрограммы: агglomerative или divisive?\n",
        "16. Чем отличается агglomerative и divisive подходы в иерархической кластеризации?\n",
        "17. Что такое MANOVA?\n",
        "18. Какие гипотезы проверяются в MANOVA?\n",
        "19. Какие статистические показатели используются в MANOVA для оценки различий между группами?\n",
        "20. Как интерпретировать результаты MANOVA?\n",
        "21. В чём отличие MANOVA от ANOVA?\n",
        "22. Можно ли использовать MANOVA для анализа одного зависимого параметра? Почему?\n",
        "23. Как влияет корреляция между зависимыми переменными на результаты MANOVA?\n",
        "24. Какие предположения делает MANOVA о данных?\n",
        "25. Какие методы можно использовать для визуализации многомерных данных помимо PCA?\n",
        "26. Какие ограничения имеет метод k-средних?\n",
        "27. Что такое silhouette score и как его использовать для оценки качества кластеризации?\n",
        "28. Какие алгоритмы кластеризации существуют помимо k-средних и иерархической кластеризации?\n",
        "29. В чём заключается основная идея t-SNE и как она отличается от PCA?\n",
        "30. Какие практические задачи можно решать с помощью многомерного анализа данных?\n",
        "\n",
        "\n",
        "\n",
        "### **Задачи для самостоятельной работы**\n",
        "\n",
        "#### **Метод Главных Компонент (PCA)**\n",
        "1. Дан набор данных с 10 признаками. Примените PCA для снижения размерности до 2 компонент и постройте график распределения данных.\n",
        "2. Используя данные из предыдущей задачи, рассчитайте объяснённую дисперсию для каждой главной компоненты.\n",
        "3. Загрузите набор данных Iris и выполните PCA для визуализации данных в двумерном пространстве.\n",
        "4. Создайте искусственный набор данных с высокой корреляцией между признаками и примените PCA. Проанализируйте результаты.\n",
        "5. Постройте график зависимости объяснённой дисперсии от количества главных компонент для набора данных Wine.\n",
        "6. Используйте метод k-средних для кластеризации данных о покупательском поведении клиентов. Выберите оптимальное количество кластеров с помощью метода локтя.\n",
        "7. Примените иерархическую кластеризацию к тому же набору данных и сравните результаты с методом k-средних.\n",
        "8. Постройте дендрограмму для набора данных с пятью объектами и четырьмя признаками.\n",
        "9. Рассчитайте silhouette score для различных значений $k$ в методе k-средних и выберите оптимальное значение.\n",
        "10. Сравните результаты кластеризации методами k-средних и DBSCAN на одном и том же наборе данных.\n",
        "11. Загрузите набор данных о трёх группах пациентов с тремя зависимыми переменными (вес, уровень сахара, холестерин). Проведите MANOVA и проверьте наличие значимых различий между группами.\n",
        "12. Анализируйте влияние типа диеты на несколько параметров здоровья с помощью MANOVA.\n",
        "13. Интерпретируйте результаты MANOVA, если Wilks' Lambda равна 0.45, а $p$-значение равно 0.03.\n",
        "14. Сравните MANOVA с ANOVA на примере одного зависимого параметра.\n",
        "15. Проверьте гипотезу о том, что три группы студентов не различаются по результатам тестов по математике, физике и химии.\n",
        "16. Создайте искусственный набор данных с тремя кластерами и применив PCA, проанализируйте, как изменится их расположение в новом пространстве.\n",
        "17. Используйте t-SNE для визуализации данных, которые плохо отделяются с помощью PCA.\n",
        "18. Проведите сравнительный анализ PCA и MDS (Multidimensional Scaling) на одном и том же наборе данных.\n",
        "19. Примените различные методы кластеризации (k-средних, иерархическую, DBSCAN) к одному набору данных и сравните результаты.\n",
        "20. Создайте модель, которая использует PCA для предварительной обработки данных перед обучением классификатора.\n",
        "21. Оцените влияние шума на качество кластеризации методом k-средних.\n",
        "22. Постройте график зависимости времени выполнения метода k-средних от размера набора данных.\n",
        "23. Исследуйте влияние масштабирования данных на результаты PCA и кластеризации.\n",
        "24. Постройте графики распределения данных до и после применения PCA.\n",
        "25. Сравните MANOVA с множественным ANOVA на примере конкретного набора данных.\n",
        "26. Разработайте алгоритм для автоматического выбора оптимального числа кластеров с использованием нескольких метрик.\n",
        "27. Проведите эксперимент с добавлением новых признаков к набору данных и проанализируйте, как это влияет на результаты PCA и кластеризации.\n",
        "28. Реализуйте функцию для вычисления silhouette score для произвольного набора данных.\n",
        "29. Постройте график зависимости silhouette score от количества кластеров для метода k-средних.\n",
        "30. Спроектируйте исследование, где нужно будет применить все три метода (PCA, кластерный анализ, MANOVA) для анализа одного набора данных.\n"
      ],
      "metadata": {
        "id": "0cbxqa2-kbXd"
      }
    }
  ]
}